{"idx": 0, "target": 0, "func": "public static void initializeClass(Class<?> theClass) {\n        // ***HACK*** We ask the VM to create an instance\n        // by voluntarily providing illegal arguments to force\n        // the VM to run the class' static initializer, while\n        // at the same time not running a valid constructor.\n\n        final Constructor<?>[] cons = theClass.getDeclaredConstructors();\n        //At least one constructor is guaranteed to be there, but check anyway.\n        if (cons != null) {\n            if (cons.length > 0 && cons[0] != null) {\n                final String[] strs = new String[NUMBER_OF_STRINGS];\n                try {\n                    cons[0].newInstance((Object[]) strs);\n                    // Expecting an exception to be thrown by this call:\n                    // IllegalArgumentException: wrong number of Arguments\n                } catch (Exception e) {\n                    // Ignore - we are interested only in the side\n                    // effect - that of getting the static initializers\n                    // invoked.  As we do not want to call a valid\n                    // constructor to get this side effect, an\n                    // attempt is made to call a hopefully\n                    // invalid constructor - come on, nobody\n                    // would have a constructor that takes in\n                    // 256 String arguments ;-)\n                    // (In fact, they can't - according to JVM spec\n                    // section 4.10, the number of method parameters is limited\n                    // to 255 by the definition of a method descriptor.\n                    // Constructors count as methods here.)\n                }\n            }\n        }\n    }"}
{"idx": 1, "target": 0, "func": "public static AntClassLoader newAntClassLoader(ClassLoader parent,\n                                                   Project project,\n                                                   Path path,\n                                                   boolean parentFirst) {\n        if (subClassToLoad != null) {\n            return (AntClassLoader)\n                ReflectUtil.newInstance(subClassToLoad,\n                                        CONSTRUCTOR_ARGS,\n                                        new Object[] {\n                                            parent, project, path,\n                                            Boolean.valueOf(parentFirst)\n                                        });\n        }\n        return new AntClassLoader(parent, project, path, parentFirst);\n    }"}
{"idx": 2, "target": 1, "func": "public void startTest(Test t) {\n        testStarts.put(t, new Long(System.currentTimeMillis()));\n    }"}
{"idx": 3, "target": 0, "func": "private void formatError(String type, Test test, Throwable t) {\n        if (test != null) {\n            endTest(test);\n            failedTests.put(test, test);\n        }\n\n        Element nested = doc.createElement(type);\n        Element currentTest = null;\n        if (test != null) {\n            currentTest = (Element) testElements.get(test);\n        } else {\n            currentTest = rootElement;\n        }\n\n        currentTest.appendChild(nested);\n\n        String message = t.getMessage();\n        if (message != null && message.length() > 0) {\n            nested.setAttribute(ATTR_MESSAGE, t.getMessage());\n        }\n        nested.setAttribute(ATTR_TYPE, t.getClass().getName());\n\n        String strace = JUnitTestRunner.getFilteredTrace(t);\n        Text trace = doc.createTextNode(strace);\n        nested.appendChild(trace);\n    }"}
{"idx": 4, "target": 0, "func": "public void endTest(Test test) {\n        // Fix for bug #5637 - if a junit.extensions.TestSetup is\n        // used and throws an exception during setUp then startTest\n        // would never have been called\n        if (!testStarts.containsKey(test)) {\n            startTest(test);\n        }\n\n        Element currentTest = null;\n        if (!failedTests.containsKey(test)) {\n            currentTest = doc.createElement(TESTCASE);\n            String n = JUnitVersionHelper.getTestCaseName(test);\n            currentTest.setAttribute(ATTR_NAME,\n                                     n == null ? UNKNOWN : n);\n            // a TestSuite can contain Tests from multiple classes,\n            // even tests with the same name - disambiguate them.\n            currentTest.setAttribute(ATTR_CLASSNAME,\n                    JUnitVersionHelper.getTestCaseClassName(test));\n            rootElement.appendChild(currentTest);\n            testElements.put(test, currentTest);\n        } else {\n            currentTest = (Element) testElements.get(test);\n        }\n\n        Long l = (Long) testStarts.get(test);\n        currentTest.setAttribute(ATTR_TIME,\n            \"\" + ((System.currentTimeMillis()\n                   - l.longValue()) / ONE_SECOND));\n    }"}
{"idx": 5, "target": 1, "func": "public SSTableReader write(Set<String> keys) throws IOException\n        {\n            Map<String, ColumnFamily> map = new HashMap<String, ColumnFamily>();\n            for (String key : keys)\n            {\n                ColumnFamily cf = ColumnFamily.create(ksname, cfname);\n                cf.addColumn(new Column(ByteBufferUtil.bytes(key), ByteBufferUtil.bytes(key), 0));\n                map.put(key, cf);\n            }\n            return write(map);\n        }"}
{"idx": 6, "target": 0, "func": "@Test\n    public void testReadAndWrite() throws Exception\n    {\n        SequentialWriter w = createTempFile(\"braf\");\n\n        // writting string of data to the file\n        byte[] data = \"Hello\".getBytes();\n        w.write(data);\n        assertEquals(data.length, w.length());\n        assertEquals(data.length, w.getFilePointer());\n\n        w.sync();\n\n        // reading small amount of data from file, this is handled by initial buffer\n        RandomAccessReader r = RandomAccessReader.open(w);\n\n        byte[] buffer = new byte[data.length];\n        assertEquals(data.length, r.read(buffer));\n        assertTrue(Arrays.equals(buffer, data)); // we read exactly what we wrote\n        assertEquals(r.read(), -1); // nothing more to read EOF\n        assert r.bytesRemaining() == 0 && r.isEOF();\n\n        r.close();\n\n        // writing buffer bigger than page size, which will trigger reBuffer()\n        byte[] bigData = new byte[RandomAccessReader.DEFAULT_BUFFER_SIZE + 10];\n\n        for (int i = 0; i < bigData.length; i++)\n            bigData[i] = 'd';\n\n        long initialPosition = w.getFilePointer();\n        w.write(bigData); // writing data\n        assertEquals(w.getFilePointer(), initialPosition + bigData.length);\n        assertEquals(w.length(), initialPosition + bigData.length); // file size should equals to last position\n\n        w.sync();\n\n        r = RandomAccessReader.open(w); // re-opening file in read-only mode\n\n        // reading written buffer\n        r.seek(initialPosition); // back to initial (before write) position\n        data = new byte[bigData.length];\n        long sizeRead = 0;\n        for (int i = 0; i < data.length; i++)\n        {\n            data[i] = (byte) r.read();\n            sizeRead++;\n        }\n\n        assertEquals(sizeRead, data.length); // read exactly data.length bytes\n        assertEquals(r.getFilePointer(), initialPosition + data.length);\n        assertEquals(r.length(), initialPosition + bigData.length);\n        assertTrue(Arrays.equals(bigData, data));\n        assertTrue(r.bytesRemaining() == 0 && r.isEOF()); // we are at the of the file\n\n        // test readBytes(int) method\n        r.seek(0);\n        ByteBuffer fileContent = r.readBytes((int) w.length());\n        assertEquals(fileContent.limit(), w.length());\n        assert ByteBufferUtil.string(fileContent).equals(\"Hello\" + new String(bigData));\n\n        // read the same buffer but using readFully(int)\n        data = new byte[bigData.length];\n        r.seek(initialPosition);\n        r.readFully(data);\n        assert r.bytesRemaining() == 0 && r.isEOF(); // we should be at EOF\n        assertTrue(Arrays.equals(bigData, data));\n\n        // try to read past mark (all methods should return -1)\n        data = new byte[10];\n        assertEquals(r.read(), -1);\n        assertEquals(r.read(data), -1);\n        assertEquals(r.read(data, 0, data.length), -1);\n\n        // test read(byte[], int, int)\n        r.seek(0);\n        data = new byte[20];\n        assertEquals(15, r.read(data, 0, 15));\n        assertTrue(new String(data).contains(\"Hellodddddddddd\"));\n        for (int i = 16; i < data.length; i++)\n        {\n            assert data[i] == 0;\n        }\n\n        w.close();\n        r.close();\n    }"}
{"idx": 7, "target": 1, "func": "public int compareTo(login_args other) {\n      if (!getClass().equals(other.getClass())) {\n        return getClass().getName().compareTo(other.getClass().getName());\n      }\n\n      int lastComparison = 0;\n      login_args typedOther = (login_args)other;\n\n      lastComparison = Boolean.valueOf(isSetAuth_request()).compareTo(typedOther.isSetAuth_request());\n      if (lastComparison != 0) {\n        return lastComparison;\n      }\n      if (isSetAuth_request()) {\n        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.auth_request, typedOther.auth_request);\n        if (lastComparison != 0) {\n          return lastComparison;\n        }\n      }\n      return 0;\n    }"}
{"idx": 8, "target": 0, "func": "public void setFieldValue(_Fields field, Object value) {\n      switch (field) {\n      case AUTH_REQUEST:\n        if (value == null) {\n          unsetAuth_request();\n        } else {\n          setAuth_request((AuthenticationRequest)value);\n        }\n        break;\n\n      }\n    }"}
{"idx": 9, "target": 1, "func": "public int compareTo(SchemaDisagreementException other) {\n    if (!getClass().equals(other.getClass())) {\n      return getClass().getName().compareTo(other.getClass().getName());\n    }\n\n    int lastComparison = 0;\n    SchemaDisagreementException typedOther = (SchemaDisagreementException)other;\n\n    return 0;\n  }"}
{"idx": 10, "target": 0, "func": "public void setFieldValue(_Fields field, Object value) {\n    switch (field) {\n    }\n  }"}
{"idx": 11, "target": 1, "func": "public void applyStateTransition(Message.Type requestType, Message.Type responseType)\n    {\n        switch (state)\n        {\n            case UNINITIALIZED:\n                if (requestType == Message.Type.STARTUP)\n                {\n                    if (responseType == Message.Type.AUTHENTICATE)\n                        state = State.AUTHENTICATION;\n                    else if (responseType == Message.Type.READY)\n                        state = State.READY;\n                }\n                break;\n            case AUTHENTICATION:\n                assert requestType == Message.Type.CREDENTIALS;\n                if (responseType == Message.Type.READY)\n                    state = State.READY;\n            case READY:\n                break;\n            default:\n                throw new AssertionError();\n        }\n    }"}
{"idx": 12, "target": 0, "func": "public ChannelBuffer encode(ErrorMessage msg)\n        {\n            ChannelBuffer ccb = CBUtil.intToCB(msg.error.code().value);\n            ChannelBuffer mcb = CBUtil.stringToCB(msg.error.getMessage());\n\n            ChannelBuffer acb = ChannelBuffers.EMPTY_BUFFER;\n            switch (msg.error.code())\n            {\n                case UNAVAILABLE:\n                    UnavailableException ue = (UnavailableException)msg.error;\n                    ChannelBuffer ueCl = CBUtil.consistencyLevelToCB(ue.consistency);\n                    acb = ChannelBuffers.buffer(ueCl.readableBytes() + 8);\n                    acb.writeBytes(ueCl);\n                    acb.writeInt(ue.required);\n                    acb.writeInt(ue.alive);\n                    break;\n                case WRITE_TIMEOUT:\n                case READ_TIMEOUT:\n                    RequestTimeoutException rte = (RequestTimeoutException)msg.error;\n                    boolean isWrite = msg.error.code() == ExceptionCode.WRITE_TIMEOUT;\n\n                    ChannelBuffer rteCl = CBUtil.consistencyLevelToCB(rte.consistency);\n                    ByteBuffer writeType = isWrite\n                                         ? ByteBufferUtil.bytes(((WriteTimeoutException)rte).writeType.toString())\n                                         : null;\n\n                    int extraSize = isWrite  ? 2 + writeType.remaining() : 1;\n                    acb = ChannelBuffers.buffer(rteCl.readableBytes() + 8 + extraSize);\n\n                    acb.writeBytes(rteCl);\n                    acb.writeInt(rte.received);\n                    acb.writeInt(rte.blockFor);\n                    if (isWrite)\n                    {\n                        acb.writeShort((short)writeType.remaining());\n                        acb.writeBytes(writeType);\n                    }\n                    else\n                    {\n                        acb.writeByte((byte)(((ReadTimeoutException)rte).dataPresent ? 1 : 0));\n                    }\n                    break;\n                case UNPREPARED:\n                    PreparedQueryNotFoundException pqnfe = (PreparedQueryNotFoundException)msg.error;\n                    acb = CBUtil.bytesToCB(pqnfe.id.bytes);\n                    break;\n                case ALREADY_EXISTS:\n                    AlreadyExistsException aee = (AlreadyExistsException)msg.error;\n                    acb = ChannelBuffers.wrappedBuffer(CBUtil.stringToCB(aee.ksName),\n                                                       CBUtil.stringToCB(aee.cfName));\n                    break;\n            }\n            return ChannelBuffers.wrappedBuffer(ccb, mcb, acb);\n        }"}
{"idx": 13, "target": 0, "func": "public Message.Response execute(QueryState state)\n    {\n        try\n        {\n            CQLStatement statement = QueryProcessor.getPrepared(statementId);\n\n            if (statement == null)\n                throw new PreparedQueryNotFoundException(statementId);\n\n            UUID tracingId = null;\n            if (isTracingRequested())\n            {\n                tracingId = UUIDGen.getTimeUUID();\n                state.prepareTracingSession(tracingId);\n            }\n\n            if (state.traceNextQuery())\n            {\n                state.createTracingSession();\n                // TODO we don't have [typed] access to CQL bind variables here.  CASSANDRA-4560 is open to add support.\n                Tracing.instance().begin(\"Execute CQL3 prepared query\", Collections.<String, String>emptyMap());\n            }\n\n            Message.Response response = QueryProcessor.processPrepared(statement, consistency, state, values);\n\n            if (tracingId != null)\n                response.setTracingId(tracingId);\n\n            return response;\n        }\n        catch (Exception e)\n        {\n            return ErrorMessage.fromException(e);\n        }\n        finally\n        {\n            Tracing.instance().stopSession();\n        }\n    }"}
{"idx": 14, "target": 1, "func": "public static String toString(byte[] bytes, String charsetName) throws UnsupportedEncodingException {\n        return charsetName == null ? new String(bytes) : new String(bytes, charsetName);\n    }"}
{"idx": 15, "target": 0, "func": "public static String[] splitByCharacterType(String str) {\n        return splitByCharacterType(str, false);\n    }"}
{"idx": 16, "target": 1, "func": "public String[] getReferencedColumnNames()\n\t{\n\t\treturn referencedColumnNames;\n\t}"}
{"idx": 17, "target": 1, "func": "public int[] baseColumnPositions()\n\t{\n\t\treturn baseColumnPositions;\n\t}"}
{"idx": 18, "target": 1, "func": "public boolean\t\t\tisAscending(Integer keyColumnPosition)\n\t{\n\t\tint i = keyColumnPosition.intValue() - 1;\n\t\tif (i < 0 || i >= baseColumnPositions.length)\n\t\t\treturn false;\n\t\treturn isAscending[i];\n\t}"}
{"idx": 19, "target": 1, "func": "public void\t\tsetBaseColumnPositions(int[] baseColumnPositions)\n\t{\n\t\tthis.baseColumnPositions = baseColumnPositions;\n\t}"}
{"idx": 20, "target": 1, "func": "public void\t\tsetIsAscending(boolean[] isAscending)\n\t{\n\t\tthis.isAscending = isAscending;\n\t}"}
{"idx": 21, "target": 1, "func": "public int[] getTriggerActionReferencedColumnPositions()\n\t{\n\t\treturn referencedColumnsInTriggerAction;\n\t}"}
{"idx": 22, "target": 1, "func": "public int[] getReferencedColumnPositions()\n\t{\n\t\treturn referencedColumns;\n\t}"}
{"idx": 23, "target": 1, "func": "public int[] getParameterModes() {\n\t\treturn parameterModes;\n\t}"}
{"idx": 24, "target": 1, "func": "public String[] getParameterNames() {\n\t\treturn parameterNames;\n\t}"}
{"idx": 25, "target": 1, "func": "public TypeDescriptor[] getParameterTypes() {\n\t\treturn parameterTypes;\n\t}"}
{"idx": 26, "target": 0, "func": "public String toString() {\n\n\t\tStringBuffer sb = new StringBuffer(100);\n\t\tsb.append(getMethodName());\n\t\tsb.append('(');\n\t\tfor (int i = 0; i < parameterCount; i++) {\n\t\t\tif (i != 0)\n\t\t\t\tsb.append(',');\n\n\t\t\tif (returnType == null) {\n\t\t\t// This is a PROCEDURE.  We only want to print the\n\t\t\t// parameter mode (ex. \"IN\", \"OUT\", \"INOUT\") for procedures--\n\t\t\t// we don't do it for functions since use of the \"IN\" keyword\n\t\t\t// is not part of the FUNCTION syntax.\n\t\t\t\tsb.append(RoutineAliasInfo.parameterMode(parameterModes[i]));\n\t\t\t\tsb.append(' ');\n\t\t\t}\n\t\t\tsb.append(IdUtil.normalToDelimited(parameterNames[i]));\n\t\t\tsb.append(' ');\n\t\t\tsb.append(parameterTypes[i].getSQLstring());\n\t\t}\n        if ( hasVarargs() ) { sb.append( \" ... \" ); }\n\t\tsb.append(')');\n\n\t\tif (returnType != null) {\n\t\t// this a FUNCTION, so syntax requires us to append the return type.\n\t\t\tsb.append(\" RETURNS \" + returnType.getSQLstring());\n\t\t}\n\n\t\tsb.append(\" LANGUAGE JAVA PARAMETER STYLE \" );\n\n\t\tswitch( parameterStyle )\n\t\t{\n\t\t    case PS_JAVA:    sb.append( \"JAVA \" ); break;\n\t\t    case PS_DERBY_JDBC_RESULT_SET:    sb.append( \"DERBY_JDBC_RESULT_SET \" ); break;\n\t\t    case PS_DERBY:    sb.append( \"DERBY \" ); break;\n\t\t}\n        \n        if ( isDeterministic() )\n        { sb.append( \" DETERMINISTIC \" ); }\n\n        if ( hasDefinersRights())\n        { sb.append( \" EXTERNAL SECURITY DEFINER \" ); }\n\n\t\tsb.append(RoutineAliasInfo.SQL_CONTROL[getSQLAllowed()]);\n\t\tif ((returnType == null) &&\n\t\t\t(dynamicResultSets != 0))\n\t\t{ // Only print dynamic result sets if this is a PROCEDURE\n\t\t  // because it's not valid syntax for FUNCTIONs.\n\t\t\tsb.append(\" DYNAMIC RESULT SETS \");\n\t\t\tsb.append(dynamicResultSets);\n\t\t}\n\n\t\tif (returnType != null) {\n\t\t// this a FUNCTION, so append the syntax telling what to\n\t\t// do with a null parameter.\n\t\t\tsb.append(calledOnNullInput ? \" CALLED \" : \" RETURNS NULL \");\n\t\t\tsb.append(\"ON NULL INPUT\");\n\t\t}\n\t\t\n\t\treturn sb.toString();\n\t}"}
{"idx": 27, "target": 1, "func": "public  String[]    getColumnNames()    { return _columnNames; }"}
{"idx": 28, "target": 1, "func": "public  TypeDescriptor[]    getTypes() { return _types; }"}
{"idx": 29, "target": 0, "func": "public boolean equals(Object object)\n\t{\n\t\tTypeDescriptor typeDescriptor = (TypeDescriptor)object;\n\n\t\tif(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||\n\t\t   this.precision != typeDescriptor.getPrecision() ||\n\t\t   this.scale != typeDescriptor.getScale() ||\n\t\t   this.isNullable != typeDescriptor.isNullable() ||\n\t\t   this.maximumWidth != typeDescriptor.getMaximumWidth())\n\t\t   return false;\n\t    else\n\t    {\n\t\t\tswitch (typeId.getJDBCTypeId()) {\n\t\t\tcase Types.CHAR:\n\t\t\tcase Types.VARCHAR:\n\t\t\tcase Types.LONGVARCHAR:\n\t\t\tcase Types.CLOB:\n\t\t\t\t//if we are dealing with character types, then we should \n\t\t\t\t//also compare the collation information on them.\n\t\t\t\tif(this.collationType != typeDescriptor.getCollationType())\n\t\t\t\t\treturn false;\n\t\t\t\telse\n\t\t\t\t\treturn true;\n\t\t\tdefault:\n\t\t\t\t//no collation checking required if we are dealing with \n\t\t\t\t//non-char datatypes.\n\t\t\t\treturn true;\n\t\t\t}\n\t    }\n\t}"}
{"idx": 30, "target": 0, "func": "public TypeDescriptor[] getRowTypes() {\n        if (!isRowMultiSet())\n            return null;\n\n        return ((RowMultiSetImpl) typeId).getTypes();\n    }"}
{"idx": 31, "target": 0, "func": "public String[] getRowColumnNames() {\n        if (!isRowMultiSet())\n            return null;\n\n        return ((RowMultiSetImpl) typeId).getColumnNames();\n    }"}
{"idx": 32, "target": 0, "func": "public boolean equals(Object object)\n\t{\n\t\tTypeDescriptor typeDescriptor = (TypeDescriptor)object;\n\n\t\tif(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||\n\t\t   this.precision != typeDescriptor.getPrecision() ||\n\t\t   this.scale != typeDescriptor.getScale() ||\n\t\t   this.isNullable != typeDescriptor.isNullable() ||\n\t\t   this.maximumWidth != typeDescriptor.getMaximumWidth())\n\t\t   return false;\n\t    else\n\t    {\n\t\t\tswitch (typeId.getJDBCTypeId()) {\n\t\t\tcase Types.CHAR:\n\t\t\tcase Types.VARCHAR:\n\t\t\tcase Types.LONGVARCHAR:\n\t\t\tcase Types.CLOB:\n\t\t\t\t//if we are dealing with character types, then we should \n\t\t\t\t//also compare the collation information on them.\n\t\t\t\tif(this.collationType != typeDescriptor.getCollationType())\n\t\t\t\t\treturn false;\n\t\t\t\telse\n\t\t\t\t\treturn true;\n\t\t\tdefault:\n\t\t\t\t//no collation checking required if we are dealing with \n\t\t\t\t//non-char datatypes.\n\t\t\t\treturn true;\n\t\t\t}\n\t    }\n\t}"}
{"idx": 33, "target": 0, "func": "public boolean equals(Object object)\n\t{\n\t\tTypeDescriptor typeDescriptor = (TypeDescriptor)object;\n\n\t\tif(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||\n\t\t   this.precision != typeDescriptor.getPrecision() ||\n\t\t   this.scale != typeDescriptor.getScale() ||\n\t\t   this.isNullable != typeDescriptor.isNullable() ||\n\t\t   this.maximumWidth != typeDescriptor.getMaximumWidth())\n\t\t   return false;\n\t    else\n\t    {\n\t\t\tswitch (typeId.getJDBCTypeId()) {\n\t\t\tcase Types.CHAR:\n\t\t\tcase Types.VARCHAR:\n\t\t\tcase Types.LONGVARCHAR:\n\t\t\tcase Types.CLOB:\n\t\t\t\t//if we are dealing with character types, then we should \n\t\t\t\t//also compare the collation information on them.\n\t\t\t\tif(this.collationType != typeDescriptor.getCollationType())\n\t\t\t\t\treturn false;\n\t\t\t\telse\n\t\t\t\t\treturn true;\n\t\t\tdefault:\n\t\t\t\t//no collation checking required if we are dealing with \n\t\t\t\t//non-char datatypes.\n\t\t\t\treturn true;\n\t\t\t}\n\t    }\n\t}"}
{"idx": 34, "target": 0, "func": "public TypeDescriptor[] getRowTypes() {\n        if (!isRowMultiSet())\n            return null;\n\n        return ((RowMultiSetImpl) typeId).getTypes();\n    }"}
{"idx": 35, "target": 0, "func": "public String[] getRowColumnNames() {\n        if (!isRowMultiSet())\n            return null;\n\n        return ((RowMultiSetImpl) typeId).getColumnNames();\n    }"}
{"idx": 36, "target": 0, "func": "public void readExternal( ObjectInput in )\n\t\t throws IOException, ClassNotFoundException\n\t{\n        // as the persistent form evolves, switch on this value\n        int oldVersion = in.readInt();\n\t}"}
{"idx": 37, "target": 1, "func": "public boolean equals(Object obj) {\n        return org.apache.derby.client.net.NetXAResource.xidsEqual(this, (javax.transaction.xa.Xid) obj);\n    }"}
{"idx": 38, "target": 1, "func": "public byte[] getData() {\n        return data_;\n    }"}
{"idx": 39, "target": 0, "func": "public void setFormatID(int formatID) {\n        formatID_ = formatID;\n        return;\n    }"}
{"idx": 40, "target": 0, "func": "private byte[] nextArray() {\n        if (arrayIndex >= arrays.size()) {\n            return null;\n        }\n        byte[] tmp = (byte[])arrays.get(arrayIndex);\n        arrays.set(arrayIndex++, null);\n        off = 0;\n        return tmp;\n    }"}
{"idx": 41, "target": 0, "func": "public final void allocateCharBuffer() {\n        // compute the maximum char length\n        int maxCharLength = 0;\n        for (int i = 0; i < columns_; i++) {\n            switch (jdbcTypes_[i]) {\n            case Types.CHAR:\n            case Types.VARCHAR:\n            case Types.LONGVARCHAR:\n                if (fdocaLength_[i] > maxCharLength) {\n                    maxCharLength = fdocaLength_[i];\n                }\n            }\n        }\n\n        // allocate char buffer to accomodate largest result column\n        charBuffer_ = new char[maxCharLength];\n    }"}
{"idx": 42, "target": 0, "func": "public static Properties makeProperties(String name, String value) {\n    Properties p = new Properties();\n        if (name != null || value != null)\n            p.setProperty(name, value);\n    return p;\n    }"}
{"idx": 43, "target": 1, "func": "public byte[] getPKGNAMCBytes() {\n        return PKGNAMCBytes;\n    }"}
{"idx": 44, "target": 1, "func": "public void setPKGNAMCBytes(byte[] b) {\n        if (isGenerated) {\n            PKGNAMCBytes = b;\n        } else {\n            agent_.sectionManager_.setPKGNAMCBytes(b, resultSetHoldability_);\n        }\n    }"}
{"idx": 45, "target": 0, "func": "public static MessageUtil getMessageUtil() {\n        if ( msgutil_ == null ) {\n            msgutil_ = new MessageUtil(CLIENT_MESSAGE_RESOURCE_NAME);\n        }\n        \n        return msgutil_;\n    }"}
{"idx": 46, "target": 0, "func": "public SQLWarning getSQLWarning()\n    {\n        if (wrappedException_ != null) {\n            return (SQLWarning) wrappedException_;\n        }\n\n        SQLWarning sqlw = new SQLWarning(getMessage(), getSQLState(), \n            getErrorCode());\n\n        sqlw.initCause(this);\n\n        // Set up the nextException chain\n        if ( nextWarning_ != null )\n        {\n            // The exception chain gets constructed automatically through \n            // the beautiful power of recursion\n            //\n            // We have to use the right method to convert the next exception\n            // depending upon its type.  Luckily with all the other subclasses\n            // of SQLException we don't have to make our own matching \n            // subclasses because \n            sqlw.setNextException(\n                nextException_ instanceof SqlWarning ?\n                    ((SqlWarning)nextException_).getSQLWarning() :\n                    nextException_.getSQLException());\n        }\n        \n        return sqlw;\n        \n    }"}
{"idx": 47, "target": 0, "func": "public int[] getSqlErrd() {\n        if (sqlErrd_ != null) {\n            return sqlErrd_;\n        }\n\n        sqlErrd_ = new int[6]; // create an int array.\n        return sqlErrd_;\n    }"}
{"idx": 48, "target": 0, "func": "synchronized public char[] getSqlWarn() {\n        if (sqlWarn_ != null) {\n            return sqlWarn_;\n        }\n\n        try {\n            if (sqlWarnBytes_ == null) {\n                sqlWarn_ = new char[]{' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}; // 11 blank.\n            } else {\n                sqlWarn_ = bytes2String(sqlWarnBytes_, 0, sqlWarnBytes_.length).toCharArray();\n            }\n            return sqlWarn_;\n        } catch (java.io.UnsupportedEncodingException e) {\n            sqlWarn_ = new char[]{' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}; // 11 blank.\n            return sqlWarn_;\n        }\n    }"}
{"idx": 49, "target": 1, "func": "public void resetRowsetSqlca(org.apache.derby.client.am.Connection connection,\n                                 int sqlCode,\n                                 String sqlState,\n                                 byte[] sqlErrpBytes) {\n        connection_ = connection;\n        sqlCode_ = sqlCode;\n        sqlState_ = sqlState;\n        sqlErrpBytes_ = sqlErrpBytes;\n    }"}
{"idx": 50, "target": 0, "func": "public boolean equals(Object obj) {\n        if (!(obj instanceof StatementKey)) {\n            return false;\n        }\n        final StatementKey other = (StatementKey)obj;\n        if (this.holdability != other.holdability) {\n            return false;\n        }\n        if (this.autogeneratedKeys != other.autogeneratedKeys) {\n            return false;\n        }\n        if (this.isCallableStatement != other.isCallableStatement) {\n            return false;\n        }\n        if (!this.schema.equals(other.schema)) {\n            return false;\n        }\n        if (this.sql == null && other.sql != null) {\n            return false;\n        }\n        if (!this.sql.equals(other.sql)) {\n            return false;\n        }\n        if (this.type != other.type) {\n            return false;\n        }\n        if (this.concurrency != other.concurrency) {\n            return false;\n        }\n        return true;\n    }"}
{"idx": 51, "target": 1, "func": "public ClientXAConnection newClientXAConnection(ClientBaseDataSource ds,\n        LogWriter logWriter,String user, String password) throws SQLException\n    {\n        return new ClientXAConnection((ClientXADataSource)ds,\n            (NetLogWriter)logWriter,user,password);\n    }"}
{"idx": 52, "target": 1, "func": "public ClientXAConnection newClientXAConnection(ClientBaseDataSource ds,\n        LogWriter logWriter,String user, String password) throws SQLException\n    {\n        return new ClientXAConnection((ClientXADataSource)ds,\n            (NetLogWriter)logWriter,user,password);\n    }"}
{"idx": 53, "target": 0, "func": "public static SocketFactory getSocketFactory()\n        throws java.security.NoSuchAlgorithmException,\n               java.security.KeyManagementException,\n               java.security.NoSuchProviderException,\n               java.security.KeyStoreException,\n               java.security.UnrecoverableKeyException,\n               java.security.cert.CertificateException,\n               java.io.IOException\n    {\n        if (thisManager == null) {\n            thisManager = new TrustManager [] {new NaiveTrustManager()};\n        }\n\n        SSLContext ctx = SSLContext.getInstance(\"SSL\");\n        \n        if (ctx.getProvider().getName().equals(\"SunJSSE\") &&\n            (System.getProperty(\"javax.net.ssl.keyStore\") != null) &&\n            (System.getProperty(\"javax.net.ssl.keyStorePassword\") != null)) {\n            \n            // SunJSSE does not give you a working default keystore\n            // when using your own trust manager. Since a keystore is\n            // needed on the client when the server does\n            // peerAuthentication, we have to provide one working the\n            // same way as the default one.\n\n            String keyStore = \n                System.getProperty(\"javax.net.ssl.keyStore\");\n            String keyStorePassword =\n                System.getProperty(\"javax.net.ssl.keyStorePassword\");\n            \n            KeyStore ks = KeyStore.getInstance(\"JKS\");\n            ks.load(new FileInputStream(keyStore),\n                    keyStorePassword.toCharArray());\n            \n            KeyManagerFactory kmf = \n                KeyManagerFactory.getInstance(\"SunX509\", \"SunJSSE\");\n            kmf.init(ks, keyStorePassword.toCharArray());\n\n            ctx.init(kmf.getKeyManagers(),\n                     thisManager,\n                     null); // Use default random source\n        } else {\n            ctx.init(null, // Use default key manager\n                     thisManager,\n                     null); // Use default random source\n        }\n\n        return ctx.getSocketFactory();\n     }"}
{"idx": 54, "target": 0, "func": "public static SocketFactory getSocketFactory()\n        throws java.security.NoSuchAlgorithmException,\n               java.security.KeyManagementException,\n               java.security.NoSuchProviderException,\n               java.security.KeyStoreException,\n               java.security.UnrecoverableKeyException,\n               java.security.cert.CertificateException,\n               java.io.IOException\n    {\n        if (thisManager == null) {\n            thisManager = new TrustManager [] {new NaiveTrustManager()};\n        }\n\n        SSLContext ctx = SSLContext.getInstance(\"SSL\");\n        \n        if (ctx.getProvider().getName().equals(\"SunJSSE\") &&\n            (System.getProperty(\"javax.net.ssl.keyStore\") != null) &&\n            (System.getProperty(\"javax.net.ssl.keyStorePassword\") != null)) {\n            \n            // SunJSSE does not give you a working default keystore\n            // when using your own trust manager. Since a keystore is\n            // needed on the client when the server does\n            // peerAuthentication, we have to provide one working the\n            // same way as the default one.\n\n            String keyStore = \n                System.getProperty(\"javax.net.ssl.keyStore\");\n            String keyStorePassword =\n                System.getProperty(\"javax.net.ssl.keyStorePassword\");\n            \n            KeyStore ks = KeyStore.getInstance(\"JKS\");\n            ks.load(new FileInputStream(keyStore),\n                    keyStorePassword.toCharArray());\n            \n            KeyManagerFactory kmf = \n                KeyManagerFactory.getInstance(\"SunX509\", \"SunJSSE\");\n            kmf.init(ks, keyStorePassword.toCharArray());\n\n            ctx.init(kmf.getKeyManagers(),\n                     thisManager,\n                     null); // Use default random source\n        } else {\n            ctx.init(null, // Use default key manager\n                     thisManager,\n                     null); // Use default random source\n        }\n\n        return ctx.getSocketFactory();\n     }"}
{"idx": 55, "target": 0, "func": "public static SocketFactory getSocketFactory()\n        throws java.security.NoSuchAlgorithmException,\n               java.security.KeyManagementException,\n               java.security.NoSuchProviderException,\n               java.security.KeyStoreException,\n               java.security.UnrecoverableKeyException,\n               java.security.cert.CertificateException,\n               java.io.IOException\n    {\n        if (thisManager == null) {\n            thisManager = new TrustManager [] {new NaiveTrustManager()};\n        }\n\n        SSLContext ctx = SSLContext.getInstance(\"SSL\");\n        \n        if (ctx.getProvider().getName().equals(\"SunJSSE\") &&\n            (System.getProperty(\"javax.net.ssl.keyStore\") != null) &&\n            (System.getProperty(\"javax.net.ssl.keyStorePassword\") != null)) {\n            \n            // SunJSSE does not give you a working default keystore\n            // when using your own trust manager. Since a keystore is\n            // needed on the client when the server does\n            // peerAuthentication, we have to provide one working the\n            // same way as the default one.\n\n            String keyStore = \n                System.getProperty(\"javax.net.ssl.keyStore\");\n            String keyStorePassword =\n                System.getProperty(\"javax.net.ssl.keyStorePassword\");\n            \n            KeyStore ks = KeyStore.getInstance(\"JKS\");\n            ks.load(new FileInputStream(keyStore),\n                    keyStorePassword.toCharArray());\n            \n            KeyManagerFactory kmf = \n                KeyManagerFactory.getInstance(\"SunX509\", \"SunJSSE\");\n            kmf.init(ks, keyStorePassword.toCharArray());\n\n            ctx.init(kmf.getKeyManagers(),\n                     thisManager,\n                     null); // Use default random source\n        } else {\n            ctx.init(null, // Use default key manager\n                     thisManager,\n                     null); // Use default random source\n        }\n\n        return ctx.getSocketFactory();\n     }"}
{"idx": 56, "target": 0, "func": "protected boolean flowReconnect(String password, int securityMechanism) throws SqlException {\n        constructExtnam();\n        // these calls need to be after newing up the agent\n        // because they require the ccsid manager\n        constructPrddta();  //modify this to not new up an array\n\n        checkSecmgrForSecmecSupport(securityMechanism);\n        try {\n            switch (securityMechanism) {\n            case NetConfiguration.SECMEC_USRIDPWD: // Clear text user id and password\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            case NetConfiguration.SECMEC_USRIDONL: // Clear text user, no password sent to server\n                checkUser(user_);\n                resetConnectionAtFirstSql_ = true;\n                return true;\n            case NetConfiguration.SECMEC_USRENCPWD: // Clear text user, encrypted password\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            case NetConfiguration.SECMEC_EUSRIDPWD: // Encrypted user, encrypted password\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            case NetConfiguration.SECMEC_EUSRIDDTA:\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            case NetConfiguration.SECMEC_EUSRPWDDTA:\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            case NetConfiguration.SECMEC_USRSSBPWD: // Clear text user, strong password substitute\n                checkUserPassword(user_, password);\n                resetConnectionAtFirstSql_ = true;\n                setDeferredResetPassword(password);\n                return true;\n            default:\n                throw new SqlException(agent_.logWriter_, \n                    new ClientMessageId(SQLState.SECMECH_NOT_SUPPORTED),\n                    securityMechanism);\n            }\n        } catch (SqlException sqle) {            // this may not be needed because on method up the stack\n            open_ = false;                       // all reset exceptions are caught and wrapped in disconnect exceptions\n            try {\n                if (agent_ != null) {\n                    agent_.close();\n                }\n            } catch (SqlException ignoreMe) {\n            }\n            throw sqle;\n        }\n    }"}
{"idx": 57, "target": 0, "func": "private SqlException mapSecchkcd(int secchkcd) {\n        if (secchkcd == CodePoint.SECCHKCD_00) {\n            return null;\n        }\n\n        // the net driver will not support new password at this time.\n        // Here is the message for -30082 (STATE \"08001\"):\n        //    Attempt to establish connection failed with security\n        //    reason {0} {1} +  reason-code + reason-string.\n        switch (secchkcd) {\n        case CodePoint.SECCHKCD_01:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_SECMECH_NOT_SUPPORTED));\n        case CodePoint.SECCHKCD_10:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_PASSWORD_MISSING));\n        case CodePoint.SECCHKCD_12:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_USERID_MISSING));\n        case CodePoint.SECCHKCD_13:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_USERID_OR_PASSWORD_INVALID));\n        case CodePoint.SECCHKCD_14:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_USERID_REVOKED));\n        case CodePoint.SECCHKCD_15:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_NEW_PASSWORD_INVALID));\n        case CodePoint.SECCHKCD_0A:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_SECSVC_NONRETRYABLE_ERR));\n        case CodePoint.SECCHKCD_0B:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_SECTKN_MISSING_OR_INVALID));\n        case CodePoint.SECCHKCD_0E:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_PASSWORD_EXPIRED));\n        case CodePoint.SECCHKCD_0F:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_USERID_OR_PASSWORD_INVALID));\n        default:  // ERROR SVRCOD\n            return new SqlException(agent_.logWriter_,\n                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),\n                msgutil.getTextMessage(MessageId.CONN_NOT_SPECIFIED));\n        }\n    }"}
{"idx": 58, "target": 1, "func": "public byte[] getTargetPublicKey() {\n        return targetPublicKey_;\n    }"}
{"idx": 59, "target": 0, "func": "public void setIndoubtTransactions(java.util.Hashtable indoubtTransactions) {\n        if (isXAConnection_) {\n            if (indoubtTransactions_ != null) {\n                indoubtTransactions_.clear();\n            }\n            indoubtTransactions_ = indoubtTransactions;\n        }\n    }"}
{"idx": 60, "target": 0, "func": "void doValnsprmSemantics(int codePoint, int value) throws DisconnectException {\n        doValnsprmSemantics(codePoint, Integer.toString(value));\n    }"}
{"idx": 61, "target": 1, "func": "private void parseSECCHKreply(NetConnection netConnection) throws DisconnectException {\n        if (peekCodePoint() != CodePoint.SECCHKRM) {\n            parseSecurityCheckError(netConnection);\n            return;\n        }\n\n        parseSECCHKRM(netConnection);\n        if (peekCodePoint() == CodePoint.SECTKN) {\n            // rpydta used only if the security mechanism returns\n            // a security token that must be sent back to the source system.\n            // this is only used for DCSSEC.  In the case of DCESEC,\n            // the sectkn must be returned as reply data if DCE is using\n            // mutual authentication.\n            // Need to double check what to map this to.  This is probably\n            // incorrect but consider it a conversation protocol error\n            // 0x03 - OBJDSS sent when not allowed.\n            //parseSECTKN (true);\n            boolean done = false;\n            byte[] bytes = parseSECTKN(false);\n        }\n    }"}
{"idx": 62, "target": 0, "func": "private void parseSQLCNGRP() throws DisconnectException {\n        skipBytes(18);\n        String sqlcnRDB = parseFastVCS();    // RDBNAM\n        String sqlcnClass = parseFastVCS();  // CLASS_NAME\n        String sqlcnAuthid = parseFastVCS(); // AUTHID\n    }"}
{"idx": 63, "target": 0, "func": "private void parseSQLCNGRP() throws DisconnectException {\n        skipBytes(18);\n        String sqlcnRDB = parseFastVCS();    // RDBNAM\n        String sqlcnClass = parseFastVCS();  // CLASS_NAME\n        String sqlcnAuthid = parseFastVCS(); // AUTHID\n    }"}
{"idx": 64, "target": 0, "func": "private long parseSQLDIAGSTT(Sqlca[] rowsetSqlca) throws DisconnectException {\n        if (readFastUnsignedByte() == CodePoint.NULLDATA) {\n            return 0;\n        }\n        int sqldsFcod = readFastInt(); // FUNCTION_CODE\n        int sqldsCost = readFastInt(); // COST_ESTIMATE\n        int sqldsLrow = readFastInt(); // LAST_ROW\n\n        skipFastBytes(16);\n\n        long sqldsRowc = readFastLong(); // ROW_COUNT\n\n        skipFastBytes(24);\n\n        return sqldsRowc;\n    }"}
{"idx": 65, "target": 0, "func": "private int parseSQLDCGRP(Sqlca[] rowsetSqlca, int lastRow) throws DisconnectException {\n        int sqldcCode = readFastInt(); // SQLCODE\n        String sqldcState = readFastString(5, Typdef.UTF8ENCODING); // SQLSTATE\n        int sqldcReason = readFastInt();  // REASON_CODE\n        int sqldcLinen = readFastInt(); // LINE_NUMBER\n        int sqldcRown = (int) readFastLong(); // ROW_NUMBER\n\n        // save +20237 in the 0th entry of the rowsetSqlca's.\n        // this info is going to be used when a subsequent fetch prior is issued, and if already\n        // received a +20237 then we've gone beyond the first row and there is no need to\n        // flow another fetch to the server.\n        if (sqldcCode == 20237) {\n            rowsetSqlca[0] = new NetSqlca(netAgent_.netConnection_,\n                    sqldcCode,\n                    sqldcState,\n                    null);\n        } else {\n            if (rowsetSqlca[sqldcRown] != null) {\n                rowsetSqlca[sqldcRown].resetRowsetSqlca(netAgent_.netConnection_,\n                        sqldcCode,\n                        sqldcState,\n                        null);\n            } else {\n                rowsetSqlca[sqldcRown] = new NetSqlca(netAgent_.netConnection_,\n                        sqldcCode,\n                        sqldcState,\n                        null);\n            }\n        }\n\n        // reset all entries between lastRow and sqldcRown to null\n        for (int i = lastRow + 1; i < sqldcRown; i++) {\n            rowsetSqlca[i] = null;\n        }\n\n        skipFastBytes(47);\n        String sqldcRdb = parseFastVCS(); // RDBNAM\n        // skip the tokens for now, since we already have the complete message.\n        parseSQLDCTOKS(); // MESSAGE_TOKENS\n        String sqldcMsg = parseFastNVCMorNVCS(); // MESSAGE_TEXT\n\n        // skip the following for now.\n        skipFastNVCMorNVCS();  // COLUMN_NAME\n        skipFastNVCMorNVCS();  // PARAMETER_NAME\n        skipFastNVCMorNVCS();  // EXTENDED_NAMES\n\n        parseSQLDCXGRP(); // SQLDCXGRP\n        return sqldcRown;\n    }"}
{"idx": 66, "target": 0, "func": "private int parseSQLDCGRP(Sqlca[] rowsetSqlca, int lastRow) throws DisconnectException {\n        int sqldcCode = readFastInt(); // SQLCODE\n        String sqldcState = readFastString(5, Typdef.UTF8ENCODING); // SQLSTATE\n        int sqldcReason = readFastInt();  // REASON_CODE\n        int sqldcLinen = readFastInt(); // LINE_NUMBER\n        int sqldcRown = (int) readFastLong(); // ROW_NUMBER\n\n        // save +20237 in the 0th entry of the rowsetSqlca's.\n        // this info is going to be used when a subsequent fetch prior is issued, and if already\n        // received a +20237 then we've gone beyond the first row and there is no need to\n        // flow another fetch to the server.\n        if (sqldcCode == 20237) {\n            rowsetSqlca[0] = new NetSqlca(netAgent_.netConnection_,\n                    sqldcCode,\n                    sqldcState,\n                    null);\n        } else {\n            if (rowsetSqlca[sqldcRown] != null) {\n                rowsetSqlca[sqldcRown].resetRowsetSqlca(netAgent_.netConnection_,\n                        sqldcCode,\n                        sqldcState,\n                        null);\n            } else {\n                rowsetSqlca[sqldcRown] = new NetSqlca(netAgent_.netConnection_,\n                        sqldcCode,\n                        sqldcState,\n                        null);\n            }\n        }\n\n        // reset all entries between lastRow and sqldcRown to null\n        for (int i = lastRow + 1; i < sqldcRown; i++) {\n            rowsetSqlca[i] = null;\n        }\n\n        skipFastBytes(47);\n        String sqldcRdb = parseFastVCS(); // RDBNAM\n        // skip the tokens for now, since we already have the complete message.\n        parseSQLDCTOKS(); // MESSAGE_TOKENS\n        String sqldcMsg = parseFastNVCMorNVCS(); // MESSAGE_TEXT\n\n        // skip the following for now.\n        skipFastNVCMorNVCS();  // COLUMN_NAME\n        skipFastNVCMorNVCS();  // PARAMETER_NAME\n        skipFastNVCMorNVCS();  // EXTENDED_NAMES\n\n        parseSQLDCXGRP(); // SQLDCXGRP\n        return sqldcRown;\n    }"}
{"idx": 67, "target": 0, "func": "void parseDTAMCHRM() throws DisconnectException {\n        boolean svrcodReceived = false;\n        int svrcod = CodePoint.SVRCOD_INFO;\n        boolean rdbnamReceived = false;\n        String rdbnam = null;\n\n        parseLengthAndMatchCodePoint(CodePoint.DTAMCHRM);\n        pushLengthOnCollectionStack();\n        int peekCP = peekCodePoint();\n\n        while (peekCP != Reply.END_OF_COLLECTION) {\n\n            boolean foundInPass = false;\n\n            if (peekCP == CodePoint.SVRCOD) {\n                foundInPass = true;\n                svrcodReceived = checkAndGetReceivedFlag(svrcodReceived);\n                svrcod = parseSVRCOD(CodePoint.SVRCOD_ERROR, CodePoint.SVRCOD_ERROR);\n                peekCP = peekCodePoint();\n            }\n\n            if (peekCP == CodePoint.RDBNAM) {\n                foundInPass = true;\n                rdbnamReceived = checkAndGetReceivedFlag(rdbnamReceived);\n                rdbnam = parseRDBNAM(true);\n                peekCP = peekCodePoint();\n            }\n\n            if (!foundInPass) {\n                doPrmnsprmSemantics(peekCP);\n            }\n\n        }\n        popCollectionStack();\n        checkRequiredObjects(svrcodReceived, rdbnamReceived);\n\n        netAgent_.setSvrcod(svrcod);\n        doDtamchrmSemantics();\n    }"}
{"idx": 68, "target": 1, "func": "protected java.util.Hashtable parseIndoubtList() throws DisconnectException {\n        boolean found = false;\n        int port = 0;\n        int numXid = 0;\n        String sIpAddr = null;\n        int peekCP = peekCodePoint();\n        parseLengthAndMatchCodePoint(CodePoint.PRPHRCLST);\n        peekCP = peekCodePoint();\n        if (peekCP == CodePoint.XIDCNT) {\n            found = true;\n            numXid = parseXIDCNT();\n            peekCP = peekCodePoint();\n        }\n\n        java.util.Hashtable<Xid, NetIndoubtTransaction> indoubtTransactions =\n                new java.util.Hashtable<Xid, NetIndoubtTransaction>();\n        while (peekCP == CodePoint.XID) {\n            Xid xid = parseXID();\n            indoubtTransactions.put(xid, new NetIndoubtTransaction(xid, null, null, null, sIpAddr, port));\n            peekCP = peekCodePoint();\n        }\n\n        return indoubtTransactions;\n    }"}
{"idx": 69, "target": 0, "func": "private String parseSQLSTTGRPNOCMorNOCS() throws DisconnectException {\n        int mixedNullInd = readUnsignedByte();\n        int singleNullInd = 0;\n        String sqlsttString = null;\n        int stringLength = 0;\n\n        if (mixedNullInd == CodePoint.NULLDATA) {\n            singleNullInd = readUnsignedByte();\n            if (singleNullInd == CodePoint.NULLDATA) {\n                // throw DTAMCHRM\n                doDtamchrmSemantics();\n            }\n            // read 4-byte length\n            stringLength = readInt();\n            // read sqlstt string\n            sqlsttString = readString(stringLength, netAgent_.targetTypdef_.getCcsidSbcEncoding());\n        } else {\n            // read 4-byte length\n            stringLength = readInt();\n            // read sqlstt string\n            sqlsttString = readString(stringLength, netAgent_.targetTypdef_.getCcsidMbcEncoding());\n            // read null indicator\n            singleNullInd = readUnsignedByte();\n        }\n        return sqlsttString;\n    }"}
{"idx": 70, "target": 0, "func": "int parseSYNCCRD(ConnectionCallbackInterface connection) throws DisconnectException {\n        boolean svrcodReceived = false;\n        int svrcod = CodePoint.SVRCOD_INFO;\n        int xaretval = 0;\n        int synctype = 0;\n        NetConnection conn = netAgent_.netConnection_;\n\n        parseLengthAndMatchCodePoint(CodePoint.SYNCCRD);\n        pushLengthOnCollectionStack();\n        int peekCP = peekCodePoint();\n\n        while (peekCP != Reply.END_OF_COLLECTION) {\n\n            boolean foundInPass = false;\n\n            if (peekCP == CodePoint.SVRCOD) {\n                foundInPass = true;\n                svrcodReceived = checkAndGetReceivedFlag(svrcodReceived);\n                svrcod = parseSVRCOD(CodePoint.SVRCOD_ERROR, CodePoint.SVRCOD_ERROR);\n                peekCP = peekCodePoint();\n            }\n\n            if (peekCP == CodePoint.XARETVAL) {\n                foundInPass = true;\n                xaretval = parseXARETVAL();\n                conn.xares_.callInfoArray_[conn.currXACallInfoOffset_].xaRetVal_ =\n                        xaretval;\n                peekCP = peekCodePoint();\n            }\n\n            if (peekCP == CodePoint.SYNCTYPE) {\n                foundInPass = true;\n                synctype = parseSYNCTYPE();\n                peekCP = peekCodePoint();\n            }\n\n            if (peekCP == CodePoint.PRPHRCLST) {\n                foundInPass = true;\n                conn.setIndoubtTransactions(parseIndoubtList());\n                peekCP = peekCodePoint();\n            }\n\n            if (!foundInPass) {\n                doPrmnsprmSemantics(peekCP);\n            }\n        }\n        popCollectionStack();\n\n\n        return xaretval;\n\n    }"}
{"idx": 71, "target": 0, "func": "public byte[] getBuffer() {\n        return buf;\n    }"}
{"idx": 72, "target": 1, "func": "public final Object[] getArguments()\n\t{\n\t\treturn arguments;\n\t}"}
{"idx": 73, "target": 1, "func": "public void resetCurrentContextManager(ContextManager cm) {\n\t\tThreadLocal tcl = threadContextList;\n\n\t\tif (tcl == null) {\n\t\t\t// The context service is already stopped.\n\t\t\treturn;\n\t\t}\n\n\t\tif (SanityManager.DEBUG) {\n\n\t\t\tif (Thread.currentThread() != cm.activeThread) {\n\t\t\t\tSanityManager.THROWASSERT(\"resetCurrentContextManager - mismatch threads - current\" + Thread.currentThread() + \" - cm's \" + cm.activeThread);\n\t\t\t}\n\n\t\t\tif (getCurrentContextManager() != cm) {\n\t\t\t\tSanityManager.THROWASSERT(\"resetCurrentContextManager - mismatch contexts - \" + Thread.currentThread());\n\t\t\t}\n\n\t\t\tif (cm.activeCount < -1) {\n\t\t\t\tSanityManager.THROWASSERT(\"resetCurrentContextManager - invalid count - current\" + Thread.currentThread() + \" - count \" + cm.activeCount);\n\t\t\t}\n\n\t\t\tif (cm.activeCount == 0) {\n\t\t\t\tSanityManager.THROWASSERT(\"resetCurrentContextManager - invalid count - current\" + Thread.currentThread() + \" - count \" + cm.activeCount);\n\t\t\t}\n\n\t\t\tif (cm.activeCount > 0) {\n\t\t\t\tif (tcl.get() != cm)\n\t\t\t\t\tSanityManager.THROWASSERT(\"resetCurrentContextManager - invalid thread local \" + Thread.currentThread() + \" - object \" + tcl.get());\n\n\t\t\t}\n\t\t}\n\n\t\tif (cm.activeCount != -1) {\n\t\t\tif (--cm.activeCount == 0) {\n\t\t\t\tcm.activeThread = null;\n                \n                // If the ContextManager is empty\n                // then don't keep a reference to it\n                // when it is not in use. The ContextManager\n                // has been closed (most likely) and this\n                // is now unwanted. Keeping the reference\n                // would hold onto memory and increase the\n                // chance of holding onto a another reference\n                // will could cause issues for future operations.\n                if (cm.isEmpty())\n                    tcl.set(null);\n                    \n            }\n\t\t\treturn;\n\t\t}\n\n\t\tjava.util.Stack stack = (java.util.Stack) tcl.get();\n\n\t\tObject oldCM = stack.pop();\n\n\t\tContextManager nextCM = (ContextManager) stack.peek();\n\n\t\tboolean seenMultipleCM = false;\n\t\tboolean seenCM = false;\n\t\tfor (int i = 0; i < stack.size(); i++) {\n\n\t\t\tObject stackCM = stack.elementAt(i);\n\t\t\tif (stackCM != nextCM)\n\t\t\t\tseenMultipleCM = true;\n\n\t\t\tif (stackCM == cm)\n\t\t\t\tseenCM = true;\n\t\t}\n\n\t\tif (!seenCM) {\n\t\t\tcm.activeThread = null;\n\t\t\tcm.activeCount = 0;\n\t\t}\n\n\t\tif (!seenMultipleCM)\n\t\t{\n\t\t\t// all the context managers on the stack\n\t\t\t// are the same so reduce to a simple count.\n\t\t\tnextCM.activeCount = stack.size();\n\t\t\ttcl.set(nextCM);\n\t\t}\n\t}"}
{"idx": 74, "target": 0, "func": "public void cleanupOnError(Throwable t) {\n\n\t\tboolean doShutdown = false;\n\t\tif (t instanceof StandardException) {\n\t\t\tStandardException se = (StandardException) t;\n\t\t\tint severity = se.getSeverity();\n\t\t\tif (severity < ExceptionSeverity.SESSION_SEVERITY)\n\t\t\t\treturn;\n            \n            popMe();\n\n\t\t\tif (severity >= ExceptionSeverity.SYSTEM_SEVERITY)\n\t\t\t\tdoShutdown = true;\n\t\t} else if (t instanceof ShutdownException) {\n\t\t\t// system is already shutting down ...\n\t\t} else if (t instanceof ThreadDeath) {\n\t\t\t// ignore this too, it means we explicitly told thread to\n\t\t\t// stop.  one way this can happen is after monitor\n\t\t\t// shutdown, so we don't need to shut down again\n\t\t}\n\t\t\n\t\tif (!doShutdown) {\n\t\t\t//ContextManager cm = getContextManager();\n\t\t\t// need to remove me from the list of all contexts.\n\t\t\tgetContextManager().owningCsf.removeContext(getContextManager());\n\t\t\treturn;\n\t\t}\n\n\n\t\ttry {\n\t\t\t// try to print out that the shutdown is occurring.\n\t\t\t// REVISIT: does this need to be a localizable message?\n\t\t\tSystem.err.println(\"Shutting down due to severe error.\");\n\t\t\tMonitor.getStream().printlnWithHeader(\"Shutting down due to severe error.\" + t.getMessage());\n\n\t\t} finally {\n\t\t\t// we need this to happen even if we fail to print out a notice\n\t\t\tMonitor.getMonitor().shutdown();\n\t\t}\n\n\t}"}
{"idx": 75, "target": 1, "func": "public void setArray(Object[] array)\n\t{\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tSanityManager.ASSERT(array != null, \n\t\t\t\t\t\"array input to setArray() is null, code can't handle this.\");\n\t\t}\n\n\t\tthis.array = array;\n\t}"}
{"idx": 76, "target": 1, "func": "public byte[] getByteArray()\n\t{\n\t\t// In some cases the array is bigger than the actual number\n\t\t// of valid bytes.\n\t\tint realByteLength = getLengthInBytes();\n\n\t\t// Currently the case is that the return from this\n\t\t// call only includes the valid bytes.\n\t\tif (value.length != realByteLength) {\n\t\t\tbyte[] data = new byte[realByteLength];\n\t\t\tSystem.arraycopy(value, 0, data, 0, realByteLength);\n\n\t\t\tvalue = data;\n\t\t}\n\n\t\treturn value;\n\t}"}
{"idx": 77, "target": 0, "func": "public Object put(Object key, Object value)\n\t{\n\t\tif (value == null)\n\t\t{\n\t\t\treturn remove(key);\n\t\t}\n\n\t\tif (SanityManager.DEBUG) {\n\n\t\tif ((value instanceof FormatableIntHolder) ||\n\t\t\t(value instanceof FormatableLongHolder) ||\n\t\t\t((value instanceof java.io.Serializable) && (!(value instanceof Formatable)) && (!(value instanceof String)))\n\t\t\t) {\n\n\t\t\tif (!value.getClass().isArray()) {\n\n\t\t\t\t// System.out.println(\"key \" + key + \" class \" + value.getClass());\n\t\t\t\t//new Throwable().printStackTrace(System.out);\n\t\t\t\t//System.exit(1);\n\t\t\t}\n\t\t}\n\t\t}\n\t\treturn super.put(key, value);\n\t}"}
{"idx": 78, "target": 0, "func": "public static FormatableIntHolder[] getFormatableIntHolders(int[] theInts)\n\t{\n\t\tif (theInts == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\tFormatableIntHolder[] fihArray = new FormatableIntHolder[theInts.length];\n\n\t\tfor (int index = 0; index < theInts.length; index++)\n\t\t{\n\t\t\tfihArray[index] = new FormatableIntHolder(theInts[index]);\n\t\t}\n\t\treturn fihArray;\n\t}"}
{"idx": 79, "target": 0, "func": "public static FormatableLongHolder[] getFormatableLongHolders(long[] theLongs)\n\t{\n\t\tif (theLongs == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\tFormatableLongHolder[] flhArray = new FormatableLongHolder[theLongs.length];\n\n\t\tfor (int index = 0; index < theLongs.length; index++)\n\t\t{\n\t\t\tflhArray[index] = new FormatableLongHolder(theLongs[index]);\n\t\t}\n\t\treturn flhArray;\n\t}"}
{"idx": 80, "target": 0, "func": "public String[] getParameterTypes(Member method)\n\t{\n\n\t\tClass[] parameterClasses;\n\t\tif (method instanceof Method) {\n\t\t\tparameterClasses = ((Method) method).getParameterTypes();\n\t\t} else {\n\t\t\tparameterClasses = ((Constructor) method).getParameterTypes();\n\t\t}\n\n\t\tString[] parameterTypes = new String[parameterClasses.length];\n\n\t\tfor (int i = 0; i < parameterTypes.length; i++) {\n\t\t\tparameterTypes[i] = ClassInspector.readableClassName(parameterClasses[i]);\n\t\t}\n\n\t\treturn parameterTypes;\n\t}"}
{"idx": 81, "target": 0, "func": "public static int intPropertyValue(String p, Serializable v,\n\t\t\t\t\t\t\t\t\t   int minValue, int maxValue, int defaultValue)\n\t\t throws StandardException\n\t{\n\t\tif (v==null)\n\t\t\treturn defaultValue;\n\n\t\tString vs = ((String)v).trim();\n\t\ttry {\n\t\t\tint result = Integer.parseInt(vs);\n\t\t\tif (result < minValue || result > maxValue)\n\t\t\t\tthrow StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vs);\n\t\t\treturn result;\n\t\t}\n\t\tcatch (NumberFormatException nfe) {\n\t\t\tthrow StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vs);\n\t\t}\n\t}"}
{"idx": 82, "target": 0, "func": "public static boolean booleanProperty(String p, Serializable v, boolean defaultValue)\n\t\t throws StandardException\n\t{\n\t\tif (v==null)\n\t\t\treturn defaultValue;\n\n\t\tString vS = ((String) v).trim();\n\n\t\tif (\"TRUE\".equals(StringUtil.SQLToUpperCase(vS)))\n\t\t\treturn true;\n        if (\"FALSE\".equals(StringUtil.SQLToUpperCase(vS)))\n\t\t\treturn false;\n\n\t\tthrow StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vS);\n\t}"}
{"idx": 83, "target": 1, "func": "public\tvoid\tinitInfo(int        columnCount,\n\t\t\t\t\t\t\t String \tcatalogName,\n\t\t\t\t\t\t\t int[][] \tindexColumnPositions,\n\t\t\t\t\t\t\t boolean[] \tindexUniqueness,\n\t\t\t\t\t\t\t String[]\tuuidStrings)\n\t\t\t\t\t\t\t \n\t{\n\t\tindexCount = (indexColumnPositions != null) ? \n\t\t\t                 indexColumnPositions.length : 0;\n\n\t\tthis.catalogName = catalogName;\n\t\tthis.columnCount = columnCount;\n\n\t\tUUIDFactory\tuf = getUUIDFactory();\n\t\tthis.tableUUID = uf.recreateUUID(uuidStrings[0] );\n\t\tthis.heapUUID = uf.recreateUUID( uuidStrings[1] );\n\n\t\tif (indexCount > 0)\n\t\t{\n\t\t\tindexNames = new String[indexCount];\n\t\t\tindexUUID = new UUID[indexCount];\n\t\t\tfor (int ictr = 0; ictr < indexCount; ictr++)\n\t\t\t{\n\t\t\t\tindexNames[ictr] = generateIndexName(ictr);\n\t\t\t\tindexUUID[ictr] = uf.recreateUUID(uuidStrings[ictr + 2 ]);\n\t\t\t}\n\t\t\tthis.indexColumnPositions = indexColumnPositions;\n\t\t\tthis.indexUniqueness = indexUniqueness;\n \n\t\t}\n\t}"}
{"idx": 84, "target": 1, "func": "public\tvoid\tinitInfo(int        columnCount,\n\t\t\t\t\t\t\t String \tcatalogName,\n\t\t\t\t\t\t\t int[][] \tindexColumnPositions,\n\t\t\t\t\t\t\t boolean[] \tindexUniqueness,\n\t\t\t\t\t\t\t String[]\tuuidStrings)\n\t\t\t\t\t\t\t \n\t{\n\t\tindexCount = (indexColumnPositions != null) ? \n\t\t\t                 indexColumnPositions.length : 0;\n\n\t\tthis.catalogName = catalogName;\n\t\tthis.columnCount = columnCount;\n\n\t\tUUIDFactory\tuf = getUUIDFactory();\n\t\tthis.tableUUID = uf.recreateUUID(uuidStrings[0] );\n\t\tthis.heapUUID = uf.recreateUUID( uuidStrings[1] );\n\n\t\tif (indexCount > 0)\n\t\t{\n\t\t\tindexNames = new String[indexCount];\n\t\t\tindexUUID = new UUID[indexCount];\n\t\t\tfor (int ictr = 0; ictr < indexCount; ictr++)\n\t\t\t{\n\t\t\t\tindexNames[ictr] = generateIndexName(ictr);\n\t\t\t\tindexUUID[ictr] = uf.recreateUUID(uuidStrings[ictr + 2 ]);\n\t\t\t}\n\t\t\tthis.indexColumnPositions = indexColumnPositions;\n\t\t\tthis.indexUniqueness = indexUniqueness;\n \n\t\t}\n\t}"}
{"idx": 85, "target": 0, "func": "public String getIndexName(int indexNum)\n\t{\n\t\treturn indexNames[indexNum];\n\t}"}
{"idx": 86, "target": 0, "func": "public int[] getIndexColumnPositions(int indexNumber)\n\t{\n\t\treturn indexColumnPositions[indexNumber];\n\t}"}
{"idx": 87, "target": 0, "func": "public int getIndexColumnCount(int indexNum)\n\t{\n\t\treturn indexColumnPositions[indexNum].length;\n\t}"}
{"idx": 88, "target": 1, "func": "public String[] getColumnNames()\n\t{\n\t\treturn columnNames;\n\t}"}
{"idx": 89, "target": 1, "func": "public void setColumnNames(String[] columnNames)\n\t{\n\t\tthis.columnNames = columnNames;\n\t}"}
{"idx": 90, "target": 0, "func": "public UUID\tgetSchemaID()\n\t{\n\t\treturn schemaID;\n\t}"}
{"idx": 91, "target": 0, "func": "public UUID\tgetTableID()\n\t{\n\t\treturn\ttableID;\n\t}"}
{"idx": 92, "target": 1, "func": "public ColumnDescriptorList getColumnDescriptors()\n\t\tthrows StandardException\n\t{\n\t\tif (colDL == null)\n\t\t{\n\t\t\tDataDictionary dd = getDataDictionary();\n\t\t\tcolDL = new ColumnDescriptorList();\n\t\n\t\t\tint[]\trefCols = getReferencedColumns();\n\t\t\tfor (int i = 0; i < refCols.length; i++)\n\t\t\t{\n\t\t\t\tcolDL.add(table.getColumnDescriptor(refCols[i]));\n\t\t\t}\n\t\t}\n\t\treturn colDL;\n\t}"}
{"idx": 93, "target": 1, "func": "public int[]\tgetReferencedColumns()\n\t{\n\t\treturn referencedColumns;\n\t}"}
{"idx": 94, "target": 0, "func": "private\tstatic int  getCurrentDeleteConnections\n\t(\n\t DataDictionary\tdd,\n\t TableDescriptor\ttd,\n\t int refActionType,\n\t Hashtable dch,\n\t boolean prevNotCascade,\n\t boolean findSelfRef\n\t )\n\t\tthrows StandardException\n\t{\n\n\t\tint selfRefValue = -1; //store the self reference referential action \n\n\t\t//make sure we get any foreign key constraints added earlier in the same statement.\n\t\ttd.emptyConstraintDescriptorList();\n\t\tConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);\n\t\tint cdlSize = cdl.size();\n\n\t\tboolean passedInPrevNotCascade = prevNotCascade;\n\t\tfor (int index = 0; index < cdlSize; index++)\n\t\t{\n\t\t\t\tConstraintDescriptor cd = cdl.elementAt(index);\n\n\t\t\t\t//look for  foreign keys\n\t\t\t\tif ((cd instanceof ForeignKeyConstraintDescriptor))\n\t\t\t\t{\n\t\t\t\t\tForeignKeyConstraintDescriptor fkcd = (ForeignKeyConstraintDescriptor) cd;\n\t\t\t\t\tString constraintName = fkcd.getConstraintName();\n\t\t\t\t\tint raDeleteRule = fkcd.getRaDeleteRule();\n\t\t\t\t\tint raUpdateRule = fkcd.getRaUpdateRule();\n\n\t\t\t\t\t if(findSelfRef && fkcd.isSelfReferencingFK())\n\t\t\t\t\t {\n\t\t\t\t\t\t //All self references will have same  referential actions type\n\t\t\t\t\t\t selfRefValue = raDeleteRule;\n\t\t\t\t\t\t findSelfRef = false;\n\t\t\t\t\t }\n\n\t\t\t\t\tReferencedKeyConstraintDescriptor refcd =\n\t\t\t\t\t\tfkcd.getReferencedConstraint(); \n\t\t\t\t\tTableDescriptor refTd = refcd.getTableDescriptor();\n\t\t\t\t\tint childRefAction = refActionType == -1 ? raDeleteRule : refActionType;\n\t\t\t\t   \n\t\t\t\t\tString refTableName = refTd.getSchemaName() + \".\" + refTd.getName();\n\t\t\t\t\t//check with  the existing references.\n\t\t\t\t\tInteger rAction = ((Integer)dch.get(refTableName));\n\t\t\t\t\tif(rAction != null) // we already looked at this table\n\t\t\t\t\t{\n\t\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\t//if we are not cascading, check whether the link before\n\t\t\t\t\t//this was cascade or not. If we travel through  two NON CASCADE ACTION\n\t\t\t\t\t//links then the  delete connection is broken(only a delete can have further\n\t\t\t\t\t// referential effects)\n\t\t\t\t\tif(raDeleteRule != StatementType.RA_CASCADE)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(prevNotCascade)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tprevNotCascade = true;\n\t\t\t\t\t}\n\n\t\t\t\t\t//store the delete connection info in the hash table,\n\t\t\t\t\t//note that the referential action value is not what is\n\t\t\t\t\t//not specified on the current link. It is actually the \n\t\t\t\t\t//value of what happens to the table whose delete\n\t\t\t\t\t// connections we are finding.\n\t\t\t\t\tdch.put(refTableName, (new Integer(childRefAction)));\n\t\t\t\t\t\n\t\t\t\t\t//find the next delete conectiions on this path for non\n\t\t\t\t\t//self referencig delete connections.\n\t\t\t\t\tif(!fkcd.isSelfReferencingFK())\n\t\t\t\t\t\tgetCurrentDeleteConnections(dd , refTd, childRefAction,\n\t\t\t\t\t\t\t\t\t\t\t\t\tdch, true, false);\n\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t}\n\t\t}\n\t\t\n\t\treturn selfRefValue;\n\t}"}
{"idx": 95, "target": 0, "func": "private\tstatic int  getCurrentDeleteConnections\n\t(\n\t DataDictionary\tdd,\n\t TableDescriptor\ttd,\n\t int refActionType,\n\t Hashtable dch,\n\t boolean prevNotCascade,\n\t boolean findSelfRef\n\t )\n\t\tthrows StandardException\n\t{\n\n\t\tint selfRefValue = -1; //store the self reference referential action \n\n\t\t//make sure we get any foreign key constraints added earlier in the same statement.\n\t\ttd.emptyConstraintDescriptorList();\n\t\tConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);\n\t\tint cdlSize = cdl.size();\n\n\t\tboolean passedInPrevNotCascade = prevNotCascade;\n\t\tfor (int index = 0; index < cdlSize; index++)\n\t\t{\n\t\t\t\tConstraintDescriptor cd = cdl.elementAt(index);\n\n\t\t\t\t//look for  foreign keys\n\t\t\t\tif ((cd instanceof ForeignKeyConstraintDescriptor))\n\t\t\t\t{\n\t\t\t\t\tForeignKeyConstraintDescriptor fkcd = (ForeignKeyConstraintDescriptor) cd;\n\t\t\t\t\tString constraintName = fkcd.getConstraintName();\n\t\t\t\t\tint raDeleteRule = fkcd.getRaDeleteRule();\n\t\t\t\t\tint raUpdateRule = fkcd.getRaUpdateRule();\n\n\t\t\t\t\t if(findSelfRef && fkcd.isSelfReferencingFK())\n\t\t\t\t\t {\n\t\t\t\t\t\t //All self references will have same  referential actions type\n\t\t\t\t\t\t selfRefValue = raDeleteRule;\n\t\t\t\t\t\t findSelfRef = false;\n\t\t\t\t\t }\n\n\t\t\t\t\tReferencedKeyConstraintDescriptor refcd =\n\t\t\t\t\t\tfkcd.getReferencedConstraint(); \n\t\t\t\t\tTableDescriptor refTd = refcd.getTableDescriptor();\n\t\t\t\t\tint childRefAction = refActionType == -1 ? raDeleteRule : refActionType;\n\t\t\t\t   \n\t\t\t\t\tString refTableName = refTd.getSchemaName() + \".\" + refTd.getName();\n\t\t\t\t\t//check with  the existing references.\n\t\t\t\t\tInteger rAction = ((Integer)dch.get(refTableName));\n\t\t\t\t\tif(rAction != null) // we already looked at this table\n\t\t\t\t\t{\n\t\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\t//if we are not cascading, check whether the link before\n\t\t\t\t\t//this was cascade or not. If we travel through  two NON CASCADE ACTION\n\t\t\t\t\t//links then the  delete connection is broken(only a delete can have further\n\t\t\t\t\t// referential effects)\n\t\t\t\t\tif(raDeleteRule != StatementType.RA_CASCADE)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(prevNotCascade)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tprevNotCascade = true;\n\t\t\t\t\t}\n\n\t\t\t\t\t//store the delete connection info in the hash table,\n\t\t\t\t\t//note that the referential action value is not what is\n\t\t\t\t\t//not specified on the current link. It is actually the \n\t\t\t\t\t//value of what happens to the table whose delete\n\t\t\t\t\t// connections we are finding.\n\t\t\t\t\tdch.put(refTableName, (new Integer(childRefAction)));\n\t\t\t\t\t\n\t\t\t\t\t//find the next delete conectiions on this path for non\n\t\t\t\t\t//self referencig delete connections.\n\t\t\t\t\tif(!fkcd.isSelfReferencingFK())\n\t\t\t\t\t\tgetCurrentDeleteConnections(dd , refTd, childRefAction,\n\t\t\t\t\t\t\t\t\t\t\t\t\tdch, true, false);\n\t\t\t\t\tprevNotCascade = passedInPrevNotCascade;\n\t\t\t\t}\n\t\t}\n\t\t\n\t\treturn selfRefValue;\n\t}"}
{"idx": 96, "target": 1, "func": "public\tlong[]\t\tgetDistinctIndexConglomerateNumbers()\n\t\t\t\t\tthrows StandardException\n\t{\n\t\tif ( distinctIndexConglomerateNumbers == null ) { getAllIndexes(); }\n\t\treturn\tdistinctIndexConglomerateNumbers;\n\t}"}
{"idx": 97, "target": 1, "func": "public\tString[]\t\tgetDistinctIndexNames()\tthrows StandardException\n\t{\n\t\tif ( indexNames == null ) { getAllIndexes(); }\n\t\treturn\tindexNames;\n\t}"}
{"idx": 98, "target": 1, "func": "public\tIndexRowGenerator[]\t\tgetDistinctIndexRowGenerators()\n\t\t\t\t\tthrows StandardException\n\t{\n\t\tif ( distinctIndexRowGenerators == null ) { getAllIndexes(); }\n\t\treturn\tdistinctIndexRowGenerators;\n\t}"}
{"idx": 99, "target": 1, "func": "public\tIndexRowGenerator[]\t\tgetIndexRowGenerators()\n\t\t\t\t\tthrows StandardException\n\t{\n\t\tif ( indexRowGenerators == null ) { getAllIndexes(); }\n\t\treturn\tindexRowGenerators;\n\t}"}
{"idx": 100, "target": 1, "func": "public\tlong[]\t\tgetIndexConglomerateNumbers()\n\t\t\t\t\tthrows StandardException\n\t{\n\t\tif ( indexConglomerateNumbers == null ) { getAllIndexes(); }\n\t\treturn\tindexConglomerateNumbers;\n\t}"}
{"idx": 101, "target": 1, "func": "public final synchronized Timestamp getCompileTime()\n\t{\n\t\treturn compileTime;\n\t}"}
{"idx": 102, "target": 1, "func": "public final synchronized Object[] getParameterDefaults()\n\t\tthrows StandardException\n\t{\n\t\tif (paramDefaults == null)\n\t\t\tgetParams();\n\n\t\treturn paramDefaults;\n\t}"}
{"idx": 103, "target": 1, "func": "public final synchronized DataTypeDescriptor[] getParams()\n\t\tthrows StandardException\n\t{\n        if (params == null && !lookedUpParams) {\n            List tmpDefaults = new ArrayList();\n            params = getDataDictionary().getSPSParams(this, tmpDefaults);\n            paramDefaults = tmpDefaults.toArray();\n            lookedUpParams = true;\n        }\n\n\t\treturn params;\n\t}"}
{"idx": 104, "target": 1, "func": "public final synchronized void setParameterDefaults(Object[] values)\n\t{\n\t\tthis.paramDefaults = values;\n\t}"}
{"idx": 105, "target": 1, "func": "public final synchronized void setParams(DataTypeDescriptor params[])\n\t{\n\t\tthis.params = params;\n\t}"}
{"idx": 106, "target": 0, "func": "public void prepareToInvalidate\n\t(\n\t\tProvider \t\t\t\t\tp,\n\t\tint\t\t\t\t\t\t\taction,\n\t\tLanguageConnectionContext\tlcc\n\t) throws StandardException\n\t{\n\t\tswitch (action)\n\t\t{   \t\t\t\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t}"}
{"idx": 107, "target": 0, "func": "public boolean equals( Object obj)\n\t{\n\t\tif( obj instanceof StatementColumnPermission)\n\t\t{\n\t\t\tStatementColumnPermission other = (StatementColumnPermission) obj;\n\t\t\tif( ! columns.equals( other.columns))\n\t\t\t\treturn false;\n\t\t\treturn super.equals( obj);\n\t\t}\n\t\treturn false;\n\t}"}
{"idx": 108, "target": 0, "func": "public void check( LanguageConnectionContext lcc,\n\t\t\t\t\t   boolean forGrant,\n\t\t\t\t\t   Activation activation)\n\t\tthrows StandardException\n\t{\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tExecPreparedStatement ps = activation.getPreparedStatement();\n\n        if (hasPermissionOnTable(lcc, activation, forGrant, ps)) {\n\t\t\treturn;\n\t\t}\n\n        String currentUserId = lcc.getCurrentUserId(activation);\n\n\t\tFormatableBitSet permittedColumns = null;\n\t\tif( ! forGrant)\n\t\t{\n\t\t\tpermittedColumns = addPermittedColumns( dd,\n\t\t\t\t\t\t\t\t\t\t\t\t\tfalse /* non-grantable permissions */,\n\t\t\t\t\t\t\t\t\t\t\t\t\tAuthorizer.PUBLIC_AUTHORIZATION_ID,\n\t\t\t\t\t\t\t\t\t\t\t\t\tpermittedColumns);\n\t\t\tpermittedColumns = addPermittedColumns( dd,\n\t\t\t\t\t\t\t\t\t\t\t\t\tfalse /* non-grantable permissions */,\n                                                    currentUserId,\n\t\t\t\t\t\t\t\t\t\t\t\t\tpermittedColumns);\n\t\t}\n\t\tpermittedColumns = addPermittedColumns( dd,\n\t\t\t\t\t\t\t\t\t\t\t\ttrue /* grantable permissions */,\n\t\t\t\t\t\t\t\t\t\t\t\tAuthorizer.PUBLIC_AUTHORIZATION_ID,\n\t\t\t\t\t\t\t\t\t\t\t\tpermittedColumns);\n\t\tpermittedColumns = addPermittedColumns( dd,\n\t\t\t\t\t\t\t\t\t\t\t\ttrue /* grantable permissions */,\n                                                currentUserId,\n\t\t\t\t\t\t\t\t\t\t\t\tpermittedColumns);\n\t\t\n\t\t//DERBY-4191\n\t\t//If we are looking for select privilege on ANY column,\n\t\t//then we can quit as soon as we find some column with select\n\t\t//privilege. This is needed for queries like\n\t\t//select count(*) from t1\n\t\t//select count(1) from t1\n\t\t//select 1 from t1\n\t\t//select t1.c1 from t1, t2\n\t\tif (privType == Authorizer.MIN_SELECT_PRIV && permittedColumns != null)\n\t\t\treturn;\n\n\t\tFormatableBitSet unresolvedColumns = (FormatableBitSet)columns.clone();\n\n\t\tfor (int i = unresolvedColumns.anySetBit();\n\t\t\t i >= 0;\n\t\t\t i = unresolvedColumns.anySetBit(i)) {\n\n\t\t\tif (permittedColumns != null && permittedColumns.get(i)) {\n\t\t\t\t// column i (zero-based here) accounted for:\n\t\t\t\tunresolvedColumns.clear(i);\n\t\t\t}\n\t\t}\n\n\t\tif (unresolvedColumns.anySetBit() < 0) {\n\t\t\t// all ok\n\t\t\treturn;\n\t\t}\n\n\t\t// If columns are still unauthorized, look to role closure for\n\t\t// resolution.\n\t\tString role = lcc.getCurrentRoleId(activation);\n\t\tRoleGrantDescriptor rd = null;\n\n\t\tif (role != null) {\n\t\t\t// Check that role is still granted to current user or\n\t\t\t// to PUBLIC: A revoked role which is current for this\n\t\t\t// session, is lazily set to none when it is attempted\n\t\t\t// used.\n\t\t\tString dbo = dd.getAuthorizationDatabaseOwner();\n            rd = dd.getRoleGrantDescriptor(role, currentUserId, dbo);\n\n\t\t\tif (rd == null) {\n\t\t\t\trd = dd.getRoleGrantDescriptor\n\t\t\t\t\t(role,\n\t\t\t\t\t Authorizer.PUBLIC_AUTHORIZATION_ID,\n\t\t\t\t\t dbo);\n\t\t\t}\n\n\t\t\tif (rd == null) {\n\t\t\t\t// we have lost the right to set this role, so we can't\n\t\t\t\t// make use of any permission granted to it or its ancestors.\n\t\t\t\tlcc.setCurrentRole(activation, null);\n\t\t\t} else {\n\t\t\t\t// The current role is OK, so we can make use of\n\t\t\t\t// any permission granted to it.\n\t\t\t\t//\n\t\t\t\t// Look at the current role and, if necessary, the transitive\n\t\t\t\t// closure of roles granted to current role to see if\n\t\t\t\t// permission has been granted to any of the applicable roles.\n\n\t\t\t\tRoleClosureIterator rci =\n\t\t\t\t\tdd.createRoleClosureIterator\n\t\t\t\t\t(activation.getTransactionController(),\n\t\t\t\t\t role, true /* inverse relation*/);\n\n\t\t\t\tString r;\n\n\t\t\t\twhile (unresolvedColumns.anySetBit() >= 0 &&\n\t\t\t\t\t   (r = rci.next()) != null ) {\n\t\t\t\t\t//The user does not have needed privilege directly \n\t\t\t\t\t//granted to it, so let's see if he has that privilege\n\t\t\t\t\t//available to him/her through his roles.\n\t\t\t\t\tpermittedColumns = tryRole(lcc, dd,\tforGrant, r);\n\t\t\t\t\t//DERBY-4191\n\t\t\t\t\t//If we are looking for select privilege on ANY column,\n\t\t\t\t\t//then we can quit as soon as we find some column with select\n\t\t\t\t\t//privilege through this role. This is needed for queries like\n\t\t\t\t\t//select count(*) from t1\n\t\t\t\t\t//select count(1) from t1\n\t\t\t\t\t//select 1 from t1\n\t\t\t\t\t//select t1.c1 from t1, t2\n\t\t\t\t\tif (privType == Authorizer.MIN_SELECT_PRIV && permittedColumns != null) {\n\t\t\t\t\t\tDependencyManager dm = dd.getDependencyManager();\n\t\t\t\t\t\tRoleGrantDescriptor rgd =\n\t\t\t\t\t\t\tdd.getRoleDefinitionDescriptor(role);\n\t\t\t\t\t\tContextManager cm = lcc.getContextManager();\n\n\t\t\t\t\t\tdm.addDependency(ps, rgd, cm);\n\t\t\t\t\t\tdm.addDependency(activation, rgd, cm);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\t//Use the privileges obtained through the role to satisfy\n\t\t\t\t\t//the column level privileges we need. If all the remaining\n\t\t\t\t\t//column level privileges are satisfied through this role,\n\t\t\t\t\t//we will quit out of this while loop\n\t\t\t\t\tfor(int i = unresolvedColumns.anySetBit();\n\t\t\t\t\t\ti >= 0;\n\t\t\t\t\t\ti = unresolvedColumns.anySetBit(i)) {\n\n\t\t\t\t\t\tif(permittedColumns != null && permittedColumns.get(i)) {\n\t\t\t\t\t\t\tunresolvedColumns.clear(i);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tTableDescriptor td = getTableDescriptor(dd);\n\t\t//if we are still here, then that means that we didn't find any select\n\t\t//privilege on the table or any column in the table\n\t\tif (privType == Authorizer.MIN_SELECT_PRIV)\n\t\t\tthrow StandardException.newException( forGrant ? SQLState.AUTH_NO_TABLE_PERMISSION_FOR_GRANT\n\t\t\t\t\t  : SQLState.AUTH_NO_TABLE_PERMISSION,\n                      currentUserId,\n\t\t\t\t\t  getPrivName(),\n\t\t\t\t\t  td.getSchemaName(),\n\t\t\t\t\t  td.getName());\n\n\t\tint remains = unresolvedColumns.anySetBit();\n\n\t\tif (remains >= 0) {\n\t\t\t// No permission on this column.\n\t\t\tColumnDescriptor cd = td.getColumnDescriptor(remains + 1);\n\n\t\t\tif(cd == null) {\n\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\tSQLState.AUTH_INTERNAL_BAD_UUID, \"column\");\n\t\t\t} else {\n\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t(forGrant\n\t\t\t\t\t ? SQLState.AUTH_NO_COLUMN_PERMISSION_FOR_GRANT\n\t\t\t\t\t : SQLState.AUTH_NO_COLUMN_PERMISSION),\n                    currentUserId,\n\t\t\t\t\tgetPrivName(),\n\t\t\t\t\tcd.getColumnName(),\n\t\t\t\t\ttd.getSchemaName(),\n\t\t\t\t\ttd.getName());\n\t\t\t}\n\t\t} else {\n\t\t\t// We found and successfully applied a role to resolve the\n\t\t\t// (remaining) required permissions.\n\t\t\t//\n\t\t\t// Also add a dependency on the role (qua provider), so\n\t\t\t// that if role is no longer available to the current\n\t\t\t// user (e.g. grant is revoked, role is dropped,\n\t\t\t// another role has been set), we are able to\n\t\t\t// invalidate the ps or activation (the latter is used\n\t\t\t// if the current role changes).\n\t\t\tDependencyManager dm = dd.getDependencyManager();\n\t\t\tRoleGrantDescriptor rgd =\n\t\t\t\tdd.getRoleDefinitionDescriptor(role);\n\t\t\tContextManager cm = lcc.getContextManager();\n\n\t\t\tdm.addDependency(ps, rgd, cm);\n\t\t\tdm.addDependency(activation, rgd, cm);\n\t\t}\n\n\t}"}
{"idx": 109, "target": 0, "func": "public void genericCheck\n        (\n         LanguageConnectionContext lcc,\n         boolean forGrant,\n         Activation activation,\n         String privilegeType )\n        throws StandardException\n\t{\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tTransactionController tc = lcc.getTransactionExecute();\n\t\tExecPreparedStatement ps = activation.getPreparedStatement();\n\n        PermissionsDescriptor perm =\n            getPermissionDescriptor( lcc.getCurrentUserId(activation), dd );\n\t\tif( !isCorrectPermission( perm ) ) { perm = getPermissionDescriptor(Authorizer.PUBLIC_AUTHORIZATION_ID, dd ); }\n\n        // if the user has the correct permission, we're done\n\t\tif ( isCorrectPermission( perm ) ) { return; }\n\n\t\tboolean resolved = false;\n\n\t\t// Since no permission exists for the current user or PUBLIC,\n\t\t// check if a permission exists for the current role (if set).\n\t\tString role = lcc.getCurrentRoleId(activation);\n\n\t\tif (role != null) {\n\n\t\t\t// Check that role is still granted to current user or\n\t\t\t// to PUBLIC: A revoked role which is current for this\n\t\t\t// session, is lazily set to none when it is attemped\n\t\t\t// used.\n\t\t\tString dbo = dd.getAuthorizationDatabaseOwner();\n\t\t\tRoleGrantDescriptor rd = dd.getRoleGrantDescriptor\n                (role, lcc.getCurrentUserId(activation), dbo);\n\n\t\t\tif (rd == null) {\n\t\t\t\trd = dd.getRoleGrantDescriptor(\n\t\t\t\t\trole,\n\t\t\t\t\tAuthorizer.PUBLIC_AUTHORIZATION_ID,\n\t\t\t\t\tdbo);\n\t\t\t}\n\n\t\t\tif (rd == null) {\n\t\t\t\t// We have lost the right to set this role, so we can't\n\t\t\t\t// make use of any permission granted to it or its\n\t\t\t\t// ancestors.\n\t\t\t\tlcc.setCurrentRole(activation, null);\n\t\t\t} else {\n\t\t\t\t// The current role is OK, so we can make use of\n\t\t\t\t// any permission granted to it.\n\t\t\t\t//\n\t\t\t\t// Look at the current role and, if necessary, the\n\t\t\t\t// transitive closure of roles granted to current role to\n\t\t\t\t// see if permission has been granted to any of the\n\t\t\t\t// applicable roles.\n\n\t\t\t\tRoleClosureIterator rci =\n\t\t\t\t\tdd.createRoleClosureIterator\n\t\t\t\t\t(activation.getTransactionController(),\n\t\t\t\t\t role, true );\n\n\t\t\t\tString r;\n\t\t\t\twhile (!resolved && (r = rci.next()) != null)\n                {\n\t\t\t\t\tperm = getPermissionDescriptor( r, dd );\n\n\t\t\t\t\tif ( isCorrectPermission( perm ) ) { resolved = true; }\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (resolved ) {\n\t\t\t\t// Also add a dependency on the role (qua provider), so that if\n\t\t\t\t// role is no longer available to the current user (e.g. grant\n\t\t\t\t// is revoked, role is dropped, another role has been set), we\n\t\t\t\t// are able to invalidate the ps or activation (the latter is\n\t\t\t\t// used if the current role changes).\n\t\t\t\tDependencyManager dm = dd.getDependencyManager();\n\t\t\t\tRoleGrantDescriptor rgd = dd.getRoleDefinitionDescriptor(role);\n\t\t\t\tContextManager cm = lcc.getContextManager();\n\t\t\t\tdm.addDependency(ps, rgd, cm);\n\t\t\t\tdm.addDependency(activation, rgd, cm);\n\t\t\t}\n\t\t}\n\n\t\tif (!resolved)\n        {\n            PrivilegedSQLObject pso = getPrivilegedObject( dd );\n\n\t\t\tif( pso == null )\n            {\n\t\t\t\tthrow StandardException.newException\n                    ( SQLState.AUTH_INTERNAL_BAD_UUID, getObjectType() );\n            }\n\n\t\t\tSchemaDescriptor sd = pso.getSchemaDescriptor();\n\n\t\t\tif( sd == null)\n            {\n\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\tSQLState.AUTH_INTERNAL_BAD_UUID, \"SCHEMA\");\n            }\n\n\t\t\tthrow StandardException.newException(\n\t\t\t\t(forGrant\n\t\t\t\t ? SQLState.AUTH_NO_GENERIC_PERMISSION_FOR_GRANT\n\t\t\t\t : SQLState.AUTH_NO_GENERIC_PERMISSION),\n                lcc.getCurrentUserId(activation),\n                privilegeType,\n\t\t\t\tgetObjectType(),\n\t\t\t\tsd.getSchemaName(),\n\t\t\t\tpso.getName());\n\t\t}\n\n\t}"}
{"idx": 110, "target": 0, "func": "public void check(LanguageConnectionContext lcc,\n                      boolean forGrant,\n                      Activation activation\n                      ) throws StandardException\n    {\n        DataDictionary dd = lcc.getDataDictionary();\n        TransactionController tc = lcc.getTransactionExecute();\n\n        // For now, only allowed for database owner, and this check\n        // is never called for dbo, so always throw.\n        switch (privType) {\n        case Authorizer.CREATE_ROLE_PRIV:\n            throw StandardException.newException\n                (SQLState.AUTH_ROLE_DBO_ONLY, \"CREATE ROLE\");\n            // break;\n        case Authorizer.DROP_ROLE_PRIV:\n            throw StandardException.newException\n                (SQLState.AUTH_ROLE_DBO_ONLY, \"DROP ROLE\");\n            // break;\n        default:\n            if (SanityManager.DEBUG) {\n                SanityManager.THROWASSERT\n                    (\"Unexpected value (\" + privType + \") for privType\");\n            }\n            break;\n        }\n    }"}
{"idx": 111, "target": 0, "func": "public void check(LanguageConnectionContext lcc,\n                      boolean forGrant,\n                      Activation activation\n                      ) throws StandardException\n    {\n        DataDictionary dd = lcc.getDataDictionary();\n        TransactionController tc = lcc.getTransactionExecute();\n\n        // For now, only allowed for database owner, and this check\n        // is never called for dbo, so always throw.\n        switch (privType) {\n        case Authorizer.CREATE_ROLE_PRIV:\n            throw StandardException.newException\n                (SQLState.AUTH_ROLE_DBO_ONLY, \"CREATE ROLE\");\n            // break;\n        case Authorizer.DROP_ROLE_PRIV:\n            throw StandardException.newException\n                (SQLState.AUTH_ROLE_DBO_ONLY, \"DROP ROLE\");\n            // break;\n        default:\n            if (SanityManager.DEBUG) {\n                SanityManager.THROWASSERT\n                    (\"Unexpected value (\" + privType + \") for privType\");\n            }\n            break;\n        }\n    }"}
{"idx": 112, "target": 0, "func": "protected boolean oneAuthHasPermissionOnTable(DataDictionary dd, String authorizationId, boolean forGrant)\n\t\tthrows StandardException\n\t{\n\t\tTablePermsDescriptor perms = dd.getTablePermissions( tableUUID, authorizationId);\n\t\tif( perms == null)\n\t\t\treturn false;\n\t\t\n\t\tString priv = null;\n\t\t\t\n\t\tswitch( privType)\n\t\t{\n\t\tcase Authorizer.SELECT_PRIV:\n\t\tcase Authorizer.MIN_SELECT_PRIV:\n\t\t\tpriv = perms.getSelectPriv();\n\t\t\tbreak;\n\t\tcase Authorizer.UPDATE_PRIV:\n\t\t\tpriv = perms.getUpdatePriv();\n\t\t\tbreak;\n\t\tcase Authorizer.REFERENCES_PRIV:\n\t\t\tpriv = perms.getReferencesPriv();\n\t\t\tbreak;\n\t\tcase Authorizer.INSERT_PRIV:\n\t\t\tpriv = perms.getInsertPriv();\n\t\t\tbreak;\n\t\tcase Authorizer.DELETE_PRIV:\n\t\t\tpriv = perms.getDeletePriv();\n\t\t\tbreak;\n\t\tcase Authorizer.TRIGGER_PRIV:\n\t\t\tpriv = perms.getTriggerPriv();\n\t\t\tbreak;\n\t\t}\n\n\t\treturn \"Y\".equals(priv) || (!forGrant) && \"y\".equals( priv);\n\t}"}
{"idx": 113, "target": 1, "func": "public Timestamp getUpdateTimestamp() { return statUpdateTime; }"}
{"idx": 114, "target": 0, "func": "public long[]   getAutoincIncrementArray()\n\t{\n\t\tif (!tableHasAutoincrement())\n\t\t\treturn null;\n\n\t\tint size = getNumberOfColumns();\n\t\tlong[] inc = new long[size];\n\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tColumnDescriptor cd = getColumnDescriptor(i + 1);\n\t\t\tif (cd.isAutoincrement())\n\t\t\t\tinc[i] = cd.getAutoincInc();\n\t\t}\n\n\t\treturn inc;\n\t}"}
{"idx": 115, "target": 1, "func": "public Timestamp getCreationTimestamp()\n\t{\n\t\treturn creationTimestamp;\n\t}"}
{"idx": 116, "target": 1, "func": "public int[] getReferencedCols()\n\t{\n\t\treturn referencedCols;\n\t}"}
{"idx": 117, "target": 1, "func": "public int[] getReferencedColsInTriggerAction()\n\t{\n\t\treturn referencedColsInTriggerAction;\n\t}"}
{"idx": 118, "target": 1, "func": "public  Timestamp   getLastModified()   { return _lastModified; }"}
{"idx": 119, "target": 0, "func": "public void setColumn(int column, Object columnTemplate) {\n        if (SanityManager.DEBUG &&\n                !(columnTemplate instanceof DataTypeDescriptor) &&\n                !(columnTemplate instanceof DataValueDescriptor)) {\n            SanityManager.THROWASSERT(\n                \"Expected DataTypeDescriptor or DataValueDescriptor. Got: \" +\n                ((columnTemplate == null) ? columnTemplate :\n                    columnTemplate.getClass().getName()));\n        }\n        template[count] = columnTemplate;\n        columns[count] = column;\n        count++;\n        maxColumnNumber = Math.max(maxColumnNumber, column);\n    }"}
{"idx": 120, "target": 0, "func": "public Object nextElement()\n        {\n            if( ! hasMore)\n                throw new NoSuchElementException();\n            try\n            {\n                if (scan.isHeldAfterCommit()) {\n                    // automatically reopens scan:\n                    if (!scan.positionAtRowLocation(rowloc)) {\n                        // Will not happen unless compress of this table\n                        // has invalidated the row location. Possible?\n                        throw StandardException.\n                            newException(SQLState.NO_CURRENT_ROW);\n                    }\n                }\n\n                scan.fetch(row);\n\n                Object retValue =  BackingStoreHashtable.shallowCloneRow( row);\n                hasMore = scan.next();\n\n                if( ! hasMore)\n                {\n                    scan.close();\n                    scan = null;\n                } else if (keepAfterCommit) {\n                    scan.fetchLocation(rowloc);\n                }\n\n                return retValue;\n            }\n            catch( StandardException se)\n            {\n                if( scan != null)\n                {\n                    try\n                    {\n                        scan.close();\n                    }\n                    catch( StandardException se1){};\n                    scan = null;\n                }\n                throw new NoSuchElementException();\n            }\n        }"}
{"idx": 121, "target": 0, "func": "public String toString()\n    {\n\t\tString globalhex = \"\";\n\t\tString branchhex = \"\";\n\t\tif (global_id != null) \n\t    {\n\t\t\tint mask = 0;\n\t\t\tfor (int i = 0; i < global_id.length; i++)\n\t\t    {\n\t\t\t\tmask = (global_id[i] & 0xFF);\n                if (mask < 16) {\n                    globalhex += \"0\" + Integer.toHexString(mask);\n                } else {\n                    globalhex += Integer.toHexString(mask);\n                }\n\t\t    }\n\t    }\n\t\n\t\tif (branch_id != null)\n\t    {\n\t\t\tint mask = 0;\n\t\t\tfor (int i = 0; i < branch_id.length; i++)\n\t\t    {\n\t\t\t\tmask = (branch_id[i] & 0xFF);\n                if (mask < 16) {\n                    branchhex += \"0\" + Integer.toHexString(mask);\n                } else {\n                    branchhex += Integer.toHexString(mask);\n                }\n\t\t    }\n\t    }\n\n\t\treturn(\"(\" + format_id + \",\" + globalhex + \",\" + branchhex + \")\");\n\t\n    }"}
{"idx": 122, "target": 0, "func": "public static String toString(Object[] row)\n    {\n        if (SanityManager.DEBUG)\n        {\n\n            String str = \"\";\n\n            if (row != null)\n            {\n                if (row.length == 0)\n                {\n                    str = \"empty row\";\n                }\n                else\n                {\n                    for (int i = 0; i < row.length; i++)\n                        str += \"col[\" + i + \"]=\" + row[i];\n                }\n            }\n            else\n            {\n                str = \"row is null\";\n            }\n\n            return(str);\n        }\n        else\n        {\n            return(null);\n        }\n    }"}
{"idx": 123, "target": 0, "func": "public static String toString(Object[] row)\n    {\n        if (SanityManager.DEBUG)\n        {\n\n            String str = \"\";\n\n            if (row != null)\n            {\n                if (row.length == 0)\n                {\n                    str = \"empty row\";\n                }\n                else\n                {\n                    for (int i = 0; i < row.length; i++)\n                        str += \"col[\" + i + \"]=\" + row[i];\n                }\n            }\n            else\n            {\n                str = \"row is null\";\n            }\n\n            return(str);\n        }\n        else\n        {\n            return(null);\n        }\n    }"}
{"idx": 124, "target": 1, "func": "public byte[] getBranchQualifier()\n    {\n        return(branch_id);\n    }"}
{"idx": 125, "target": 1, "func": "public byte[] getGlobalTransactionId()\n    {\n        return(global_id);\n    }"}
{"idx": 126, "target": 0, "func": "public boolean equals(Object other) \n    {\n\t\tif (other == this)\n\t\t\treturn true;\n\n\t\tif (other == null)\n\t\t\treturn false;\n\t\n\t\ttry\n\t    {\n\t\t\tif (other instanceof GlobalXact)\n\t\t\t\treturn super.equals(other);\n\t\t\t// Just cast it and catch the exception rather than doing the type\n\t\t\t// checking twice.\n\t\t\tXid other_xid = (Xid) other;\n\t\t\n\t\t\treturn(\n\t\t\t\t   java.util.Arrays.equals(\n\t\t\t\t\t\t\t\t\tother_xid.getGlobalTransactionId(),\n\t\t\t\t\t\t\t\t\tthis.global_id)          &&\n\t\t\t\t   java.util.Arrays.equals(\n\t\t\t\t\t\t\t\t\tother_xid.getBranchQualifier(),\n\t\t\t\t\t\t\t\t\tthis.branch_id)          &&\n\t\t\t\t   other_xid.getFormatId() == this.format_id);\n\t\t\n\t    }\n\t\tcatch(ClassCastException cce)\n\t    {\n\t\t\t// this class only knows how to compare with other Xids\n\t\t\tif (SanityManager.DEBUG)\n\t\t\t\tSanityManager.THROWASSERT(\"comparing XAXactId with \" + \n\t\t\t\t\t\t\t\t\t\t  other.getClass().getName(), cce); \n\t\t\n\t\t\treturn false;\n\t    }\n    }"}
{"idx": 127, "target": 0, "func": "public long getContainerId() {\n\t\treturn containerId;\n\t}"}
{"idx": 128, "target": 0, "func": "public final Qualifier[][] getQualifierList()\n    {\n        return(qualifier_list);\n    }"}
{"idx": 129, "target": 0, "func": "public final int[] getMaterializedColumns()\n    {\n        return(materialized_cols);\n    }"}
{"idx": 130, "target": 0, "func": "public final int[] getValidColumnsArray()\n    {\n        return(validColumnsArray);\n    }"}
{"idx": 131, "target": 0, "func": "public static LocalizedResource getInstance(){\n\t\tif (local == null){\n\t\t\tlocal = new  LocalizedResource();\n\t\t}\n\t\treturn local;\n\t}"}
{"idx": 132, "target": 0, "func": "public static LocalizedInput InputReader(){\n\t\treturn getInstance().in;\n\t}"}
{"idx": 133, "target": 0, "func": "public static LocalizedOutput OutputWriter(){\n\t\treturn getInstance().out;\n\t}"}
{"idx": 134, "target": 0, "func": "private Locale getNewLocale(String locStr){\n\t\t\tString l=\"\", r=\"\", v=\"\";\n\t\t\tStringTokenizer st;\n\t\t\tif (locStr==null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tst=new StringTokenizer(locStr, \"_\");\n\t\t\ttry {\n\t\t\t\tl=st.nextToken();\n\t\t\t\tif(st.hasMoreTokens()==true)\n\t\t\t\t\tr=st.nextToken();\n\t\t\t\tif(st.hasMoreTokens()==true)\n\t\t\t\t\tv=st.nextToken();\n\t\t\t\treturn new Locale(l,r,v);\n\t\t\t} catch (Exception e) {\n\t\t\t\treturn null;\n\t\t\t}\n\t}"}
{"idx": 135, "target": 0, "func": "public String getTextMessage(String key ) {\n        return getTextMessage(key, new Object[0]);\n\t}"}
{"idx": 136, "target": 0, "func": "public void setBigDecimal(Number bigDecimal) throws StandardException\n\t{\n\t\tif (objectNull(bigDecimal))\n\t\t\treturn;\n\n\t\tComparable bdc = (Comparable) bigDecimal;\n\n\n\t\t// See comment in SQLDecimal.getLong()\n\n\t\tif (   (bdc.compareTo(NumberDataType.MINLONG_MINUS_ONE) == 1)\n\t\t\t&& (bdc.compareTo(NumberDataType.MAXLONG_PLUS_ONE) == -1)) {\n\n\t\t\tsetValue(bigDecimal.longValue());\n\t\t} else {\n\n\t\t\tthrow StandardException.newException(SQLState.LANG_OUTSIDE_RANGE_FOR_DATATYPE, getTypeName());\n\t\t}\n\t}"}
{"idx": 137, "target": 0, "func": "public void setBigDecimal(Number bigDecimal) throws StandardException\n\t{\n\t\tif (objectNull(bigDecimal))\n\t\t\treturn;\n\n\t\tComparable bdc = (Comparable) bigDecimal;\n\n\n\t\t// See comment in SQLDecimal.getLong()\n\n\t\tif (   (bdc.compareTo(NumberDataType.MINLONG_MINUS_ONE) == 1)\n\t\t\t&& (bdc.compareTo(NumberDataType.MAXLONG_PLUS_ONE) == -1)) {\n\n\t\t\tsetValue(bigDecimal.longValue());\n\t\t} else {\n\n\t\t\tthrow StandardException.newException(SQLState.LANG_OUTSIDE_RANGE_FOR_DATATYPE, getTypeName());\n\t\t}\n\t}"}
{"idx": 138, "target": 0, "func": "public void checkShutdownPrivileges() throws SQLException {    \n        // get the system's authentication service\n        final AuthenticationService auth\n            = ((AuthenticationService)\n               Monitor.findService(AuthenticationService.MODULE,\n                                   \"authentication\"));\n\n        // authenticate user\n        if (auth != null) {\n            final Properties finfo = new Properties();\n            if (userArg != null) {\n                finfo.setProperty(\"user\", userArg);\n            }\n            if (passwordArg != null) {\n                finfo.setProperty(\"password\", passwordArg);\n            }\n            if (!auth.authenticate((String)null, finfo)) {\n                // not a valid user\n                throw Util.generateCsSQLException(\n                SQLState.NET_CONNECT_AUTH_FAILED,\n                MessageService.getTextMessage(MessageId.AUTH_INVALID));\n            }\n        }\n\n        // approve action if not running under a security manager\n        if (System.getSecurityManager() == null) {\n            return;\n        }\n\n        // the check\n        try {\n            final Permission sp  = new SystemPermission(\n                  SystemPermission.SERVER, SystemPermission.SHUTDOWN);\n            // For porting the network server to J2ME/CDC, consider calling\n            // abstract method InternalDriver.checkShutdownPrivileges(user)\n            // instead of static SecurityUtil.checkUserHasPermission().\n            // SecurityUtil.checkUserHasPermission(userArg, sp);\n        } catch (AccessControlException ace) {\n            throw Util.generateCsSQLException(\n                SQLState.AUTH_SHUTDOWN_MISSING_PERMISSION,\n                userArg, (Object)ace); // overloaded method\n        }\n    }"}
{"idx": 139, "target": 1, "func": "public boolean deleteAll()\n    {\n        if( !exists())\n            return false;\n        if( isDirectory())\n        {\n            String[] childList = super.list();\n            String parentName = getPath();\n            for( int i = 0; i < childList.length; i++)\n            {\n                if( childList[i].equals( \".\") || childList[i].equals( \"..\"))\n                    continue;\n                DirFile child = new DirFile( parentName, childList[i]);\n                if( ! child.deleteAll())\n                    return false;\n            }\n        }\n        return delete();\n    }"}
{"idx": 140, "target": 0, "func": "public void updateObject(int columnIndex, Object x, int scale)\n\t\t\tthrows SQLException {\n\t\tupdateObject(columnIndex, x);\n\t\t/*\n\t\t* If the parameter type is DECIMAL or NUMERIC, then\n\t\t* we need to set them to the passed scale.\n\t\t*/\n\t\tint colType = getColumnType(columnIndex);\n\t\tif ((colType == Types.DECIMAL) || (colType == Types.NUMERIC)) {\n\t\t\tif (scale < 0)\n\t\t\t\tthrow newSQLException(SQLState.BAD_SCALE_VALUE, new Integer(scale));\n\n\t\t\ttry {\n\t\t\t\tDataValueDescriptor value = updateRow.getColumn(columnIndex);\n\n\t\t\t\tint origvaluelen = value.getLength();\n\t\t\t\t((VariableSizeDataValue)\n\t\t\t\t\t\tvalue).setWidth(VariableSizeDataValue.IGNORE_PRECISION,\n\t\t\t\t\t\t\tscale,\n\t\t\t\t\t\t\tfalse);\n\n\t\t\t} catch (StandardException t) {\n\t\t\t\tthrow EmbedResultSet.noStateChangeException(t);\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 141, "target": 1, "func": "public Timestamp getEndCompileTimestamp()\n\t{\n\t\treturn endCompileTimestamp;\n\t}"}
{"idx": 142, "target": 1, "func": "public Timestamp getBeginCompileTimestamp()\n\t{\n\t\treturn beginCompileTimestamp;\n\t}"}
{"idx": 143, "target": 1, "func": "public DataTypeDescriptor[]\tgetParameterTypes()\t{\n\t\treturn paramTypeDescriptors;\n\t}"}
{"idx": 144, "target": 1, "func": "public\tfinal Object[]\tgetSavedObjects()\n\t{\n\t\treturn\tsavedObjects;\n\t}"}
{"idx": 145, "target": 1, "func": "public ResultColumnDescriptor[] getColumnInfo() {\n\t\treturn columns;\n\t}"}
{"idx": 146, "target": 0, "func": "private PreparedStatement prepMinion(LanguageConnectionContext lcc, boolean cacheMe, Object[] paramDefaults,\n\t\tSchemaDescriptor spsSchema, boolean internalSQL)\n\t\tthrows StandardException\n\t{\n\t\t\t\t\t\t  \n\t\tlong\t\t\t\tbeginTime = 0;\n\t\tlong\t\t\t\tparseTime = 0;\n\t\tlong\t\t\t\tbindTime = 0;\n\t\tlong\t\t\t\toptimizeTime = 0;\n\t\tlong\t\t\t\tgenerateTime = 0;\n\t\tTimestamp\t\t\tbeginTimestamp = null;\n\t\tTimestamp\t\t\tendTimestamp = null;\n\t\tStatementContext\tstatementContext = null;\n\n\t\t// verify it isn't already prepared...\n\t\t// if it is, and is valid, simply return that tree.\n\t\t// if it is invalid, we will recompile now.\n\t\tif (preparedStmt != null) {\n\t\t\tif (preparedStmt.upToDate())\n\t\t\t\treturn preparedStmt;\n\t\t}\n\n\t\t// Clear the optimizer trace from the last statement\n\t\tif (lcc.getOptimizerTrace())\n\t\t\tlcc.setOptimizerTraceOutput(getSource() + \"\\n\");\n\n\t\tbeginTime = getCurrentTimeMillis(lcc);\n\t\t/* beginTimestamp only meaningful if beginTime is meaningful.\n\t\t * beginTime is meaningful if STATISTICS TIMING is ON.\n\t\t */\n\t\tif (beginTime != 0)\n\t\t{\n\t\t\tbeginTimestamp = new Timestamp(beginTime);\n\t\t}\n\n\t\t/** set the prepare Isolaton from the LanguageConnectionContext now as \n\t\t * we need to consider it in caching decisions\n\t\t */\n\t\tprepareIsolationLevel = lcc.getPrepareIsolationLevel();\n\n\t\t/* a note on statement caching:\n\t\t * \n\t\t * A GenericPreparedStatement (GPS) is only added it to the cache if the\n\t\t * parameter cacheMe is set to TRUE when the GPS is created.\n\t\t * \n\t\t * Earlier only CacheStatement (CS) looked in the statement cache for a\n\t\t * prepared statement when prepare was called. Now the functionality \n\t\t * of CS has been folded into GenericStatement (GS). So we search the\n\t\t * cache for an existing PreparedStatement only when cacheMe is TRUE.\n\t\t * i.e if the user calls prepare with cacheMe set to TRUE:\n\t\t * then we \n\t\t *         a) look for the prepared statement in the cache.\n\t\t *         b) add the prepared statement to the cache.\n\t\t *\n\t\t * In cases where the statement cache has been disabled (by setting the\n\t\t * relevant Derby property) then the value of cacheMe is irrelevant.\n\t\t */ \n\t\tboolean foundInCache = false;\n\t\tif (preparedStmt == null) \n\t\t{\n\t\t\tif (cacheMe)\n\t\t\t\tpreparedStmt = (GenericPreparedStatement)((GenericLanguageConnectionContext)lcc).lookupStatement(this);\n\n\t\t\tif (preparedStmt == null) \n\t\t\t{\n\t\t\t\tpreparedStmt = new GenericPreparedStatement(this);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfoundInCache = true;\n\t\t\t}\n\t\t}\n\n\t\t// if anyone else also has this prepared statement,\n\t\t// we don't want them trying to compile with it while\n\t\t// we are.  So, we synchronize on it and re-check\n\t\t// its validity first.\n\t\t// this is a no-op if and until there is a central\n\t\t// cache of prepared statement objects...\n\t\tsynchronized (preparedStmt) \n\t\t{\n\n\t\t\tfor (;;) {\n\n\t\t\t\tif (foundInCache) {\n\t\t\t\t\tif (preparedStmt.referencesSessionSchema()) {\n\t\t\t\t\t\t// cannot use this state since it is private to a connection.\n\t\t\t\t\t\t// switch to a new statement.\n\t\t\t\t\t\tfoundInCache = false;\n\t\t\t\t\t\tpreparedStmt = new GenericPreparedStatement(this);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// did it get updated while we waited for the lock on it?\n\t\t\t\tif (preparedStmt.upToDate()) {\n\t\t\t\t\treturn preparedStmt;\n\t\t\t\t}\n\n\t\t\t\tif (!preparedStmt.compilingStatement) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tpreparedStmt.wait();\n\t\t\t\t} catch (InterruptedException ie) {\n                    InterruptStatus.setInterrupted();\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpreparedStmt.compilingStatement = true;\n\t\t\tpreparedStmt.setActivationClass(null);\n\t\t}\n\n\t\ttry {\n\n\t\t\tHeaderPrintWriter istream = lcc.getLogStatementText() ? Monitor.getStream() : null;\n\n\t\t\t/*\n\t\t\t** For stored prepared statements, we want all\n\t\t\t** errors, etc in the context of the underlying\n\t\t\t** EXECUTE STATEMENT statement, so don't push/pop\n\t\t\t** another statement context unless we don't have\n\t\t\t** one.  We won't have one if it is an internal\n\t\t\t** SPS (e.g. jdbcmetadata).\n\t\t\t*/\n\t\t\tif (!preparedStmt.isStorable() || lcc.getStatementDepth() == 0)\n\t\t\t{\n\t\t\t\t// since this is for compilation only, set atomic\n\t\t\t\t// param to true and timeout param to 0\n\t\t\t\tstatementContext = lcc.pushStatementContext(true, isForReadOnly, getSource(),\n                                                            null, false, 0L);\n\t\t\t}\n\n\n\n\t\t\t/*\n\t\t\t** RESOLVE: we may ultimately wish to pass in\n\t\t\t** whether we are a jdbc metadata query or not to\n\t\t\t** get the CompilerContext to make the createDependency()\n\t\t\t** call a noop.\n\t\t\t*/\n\t\t\tCompilerContext cc = lcc.pushCompilerContext(compilationSchema);\n\t\t\t\n\t\t\tif (prepareIsolationLevel != \n\t\t\t\tExecutionContext.UNSPECIFIED_ISOLATION_LEVEL)\n\t\t\t{\n\t\t\t\tcc.setScanIsolationLevel(prepareIsolationLevel);\n\t\t\t}\n\n\n\t\t\t// Look for stored statements that are in a system schema\n\t\t\t// and with a match compilation schema. If so, allow them\n\t\t\t// to compile using internal SQL constructs.\n\n\t\t\tif (internalSQL ||\n\t\t\t\t(spsSchema != null) && (spsSchema.isSystemSchema()) &&\n\t\t\t\t\t(spsSchema.equals(compilationSchema))) {\n\t\t\t\t\t\tcc.setReliability(CompilerContext.INTERNAL_SQL_LEGAL);\n\t\t\t}\n\n\t\t\ttry \n\t\t\t{\n\t\t\t\t// Statement logging if lcc.getLogStatementText() is true\n\t\t\t\tif (istream != null)\n\t\t\t\t{\n\t\t\t\t\tString xactId = lcc.getTransactionExecute().getActiveStateTxIdString();\n\t\t\t\t\tistream.printlnWithHeader(LanguageConnectionContext.xidStr + \n\t\t\t\t\t\t\t\t\t\t\t  xactId + \n\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.lccStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getInstanceNumber() +\n\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.dbnameStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDbname() +\n\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.drdaStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDrdaID() +\n\t\t\t\t\t\t\t\t\t\t\t  \"), Begin compiling prepared statement: \" + \n\t\t\t\t\t\t\t\t\t\t\t  getSource() +\n\t\t\t\t\t\t\t\t\t\t\t  \" :End prepared statement\");\n\t\t\t\t}\n\n\t\t\t\tParser p = cc.getParser();\n\n\t\t\t\tcc.setCurrentDependent(preparedStmt);\n\n\t\t\t\t//Only top level statements go through here, nested statement\n\t\t\t\t//will invoke this method from other places\n\t\t\t\tStatementNode qt = (StatementNode)\n                        p.parseStatement(statementText, paramDefaults);\n\n\t\t\t\tparseTime = getCurrentTimeMillis(lcc);\n\n                // Call user-written tree-printer if it exists\n                walkAST( lcc, qt, ASTVisitor.AFTER_PARSE);\n\n\t\t\t\tif (SanityManager.DEBUG) \n\t\t\t\t{\n\t\t\t\t\tif (SanityManager.DEBUG_ON(\"DumpParseTree\")) \n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.GET_DEBUG_STREAM().print(\n\t\t\t\t\t\t\t\"\\n\\n============PARSE===========\\n\\n\");\n\t\t\t\t\t\tqt.treePrint();\n\t\t\t\t\t\tlcc.getPrintedObjectsMap().clear();\n\t\t\t\t\t}\n\n\t\t\t\t\tif (SanityManager.DEBUG_ON(\"StopAfterParsing\")) \n\t\t\t\t\t{\n                        lcc.setLastQueryTree( qt );\n                        \n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_STOP_AFTER_PARSING);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t** Tell the data dictionary that we are about to do\n\t\t\t\t** a bunch of \"get\" operations that must be consistent with\n\t\t\t\t** each other.\n\t\t\t\t*/\n\t\t\t\t\n\t\t\t\tDataDictionary dataDictionary = lcc.getDataDictionary();\n\n\t\t\t\tint ddMode = dataDictionary == null ? 0 : dataDictionary.startReading(lcc);\n\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\t// start a nested transaction -- all locks acquired by bind\n\t\t\t\t\t// and optimize will be released when we end the nested\n\t\t\t\t\t// transaction.\n\t\t\t\t\tlcc.beginNestedTransaction(true);\n\n\t\t\t\t\tqt.bindStatement();\n\t\t\t\t\tbindTime = getCurrentTimeMillis(lcc);\n\n                    // Call user-written tree-printer if it exists\n                    walkAST( lcc, qt, ASTVisitor.AFTER_BIND);\n\n\t\t\t\t\tif (SanityManager.DEBUG) \n\t\t\t\t\t{\n\t\t\t\t\t\tif (SanityManager.DEBUG_ON(\"DumpBindTree\")) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tSanityManager.GET_DEBUG_STREAM().print(\n\t\t\t\t\t\t\t\t\"\\n\\n============BIND===========\\n\\n\");\n\t\t\t\t\t\t\tqt.treePrint();\n\t\t\t\t\t\t\tlcc.getPrintedObjectsMap().clear();\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (SanityManager.DEBUG_ON(\"StopAfterBinding\")) {\n\t\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_STOP_AFTER_BINDING);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t//Derby424 - In order to avoid caching select statements referencing\n\t\t\t\t\t// any SESSION schema objects (including statements referencing views\n\t\t\t\t\t// in SESSION schema), we need to do the SESSION schema object check\n\t\t\t\t\t// here.  \n\t\t\t\t\t//a specific eg for statement referencing a view in SESSION schema \n\t\t\t\t\t//CREATE TABLE t28A (c28 int)\n\t\t\t\t\t//INSERT INTO t28A VALUES (280),(281)\n\t\t\t\t\t//CREATE VIEW SESSION.t28v1 as select * from t28A\n\t\t\t\t\t//SELECT * from SESSION.t28v1 should show contents of view and we\n\t\t\t\t\t// should not cache this statement because a user can later define\n\t\t\t\t\t// a global temporary table with the same name as the view name.\n\t\t\t\t\t//Following demonstrates that\n\t\t\t\t\t//DECLARE GLOBAL TEMPORARY TABLE SESSION.t28v1(c21 int, c22 int) not\n\t\t\t\t\t//     logged\n\t\t\t\t\t//INSERT INTO SESSION.t28v1 VALUES (280,1),(281,2)\n\t\t\t\t\t//SELECT * from SESSION.t28v1 should show contents of global temporary\n\t\t\t\t\t//table and not the view.  Since this select statement was not cached\n\t\t\t\t\t// earlier, it will be compiled again and will go to global temporary\n\t\t\t\t\t// table to fetch data. This plan will not be cached either because\n\t\t\t\t\t// select statement is using SESSION schema object.\n\t\t\t\t\t//\n\t\t\t\t\t//Following if statement makes sure that if the statement is\n\t\t\t\t\t// referencing SESSION schema objects, then we do not want to cache it.\n\t\t\t\t\t// We will remove the entry that was made into the cache for \n\t\t\t\t\t//this statement at the beginning of the compile phase.\n\t\t\t\t\t//The reason we do this check here rather than later in the compile\n\t\t\t\t\t// phase is because for a view, later on, we loose the information that\n\t\t\t\t\t// it was referencing SESSION schema because the reference\n\t\t\t\t\t//view gets replaced with the actual view definition. Right after\n\t\t\t\t\t// binding, we still have the information on the view and that is why\n\t\t\t\t\t// we do the check here.\n\t\t\t\t\tif (preparedStmt.referencesSessionSchema(qt)) {\n\t\t\t\t\t\tif (foundInCache)\n\t\t\t\t\t\t\t((GenericLanguageConnectionContext)lcc).removeStatement(this);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tqt.optimizeStatement();\n\n\t\t\t\t\toptimizeTime = getCurrentTimeMillis(lcc);\n\n                    // Call user-written tree-printer if it exists\n                    walkAST( lcc, qt, ASTVisitor.AFTER_OPTIMIZE);\n\n\t\t\t\t\t// Statement logging if lcc.getLogStatementText() is true\n\t\t\t\t\tif (istream != null)\n\t\t\t\t\t{\n\t\t\t\t\t\tString xactId = lcc.getTransactionExecute().getActiveStateTxIdString();\n\t\t\t\t\t\tistream.printlnWithHeader(LanguageConnectionContext.xidStr + \n\t\t\t\t\t\t\t\t\t\t\t\t  xactId + \n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.lccStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getInstanceNumber() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.dbnameStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDbname() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.drdaStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDrdaID() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), End compiling prepared statement: \" + \n\t\t\t\t\t\t\t\t\t\t\t\t  getSource() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \" :End prepared statement\");\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcatch (StandardException se)\n\t\t\t\t{\n\t\t\t\t\tlcc.commitNestedTransaction();\n\n\t\t\t\t\t// Statement logging if lcc.getLogStatementText() is true\n\t\t\t\t\tif (istream != null)\n\t\t\t\t\t{\n\t\t\t\t\t\tString xactId = lcc.getTransactionExecute().getActiveStateTxIdString();\n\t\t\t\t\t\tistream.printlnWithHeader(LanguageConnectionContext.xidStr + \n\t\t\t\t\t\t\t\t\t\t\t\t  xactId + \n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.lccStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getInstanceNumber() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.dbnameStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDbname() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), \" +\n\t\t\t\t\t\t\t\t\t\t\t\t  LanguageConnectionContext.drdaStr +\n\t\t\t\t\t\t\t\t\t\t\t\t  lcc.getDrdaID() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \"), Error compiling prepared statement: \" + \n\t\t\t\t\t\t\t\t\t\t\t\t  getSource() +\n\t\t\t\t\t\t\t\t\t\t\t\t  \" :End prepared statement\");\n\t\t\t\t\t}\n\t\t\t\t\tthrow se;\n\t\t\t\t}\n\n\t\t\t\tfinally\n\t\t\t\t{\n\t\t\t\t\t/* Tell the data dictionary that we are done reading */\n\t\t\t\t\tif (dataDictionary != null)\n\t\t\t\t\tdataDictionary.doneReading(ddMode, lcc);\n\t\t\t\t}\n\n\t\t\t\t/* we need to move the commit of nested sub-transaction\n\t\t\t\t * after we mark PS valid, during compilation, we might need\n\t\t\t\t * to get some lock to synchronize with another thread's DDL\n\t\t\t\t * execution, in particular, the compilation of insert/update/\n\t\t\t\t * delete vs. create index/constraint (see Beetle 3976).  We\n\t\t\t\t * can't release such lock until after we mark the PS valid.\n\t\t\t\t * Otherwise we would just erase the DDL's invalidation when\n\t\t\t\t * we mark it valid.\n\t\t\t\t */\n\t\t\t\ttry\t\t// put in try block, commit sub-transaction if bad\n\t\t\t\t{\n\t\t\t\t\tif (SanityManager.DEBUG) \n\t\t\t\t\t{\n\t\t\t\t\t\tif (SanityManager.DEBUG_ON(\"DumpOptimizedTree\")) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tSanityManager.GET_DEBUG_STREAM().print(\n\t\t\t\t\t\t\t\t\"\\n\\n============OPT===========\\n\\n\");\n\t\t\t\t\t\t\tqt.treePrint();\n\t\t\t\t\t\t\tlcc.getPrintedObjectsMap().clear();\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (SanityManager.DEBUG_ON(\"StopAfterOptimizing\")) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_STOP_AFTER_OPTIMIZING);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tGeneratedClass ac = qt.generate(preparedStmt.getByteCodeSaver());\n\n\t\t\t\t\tgenerateTime = getCurrentTimeMillis(lcc);\n\t\t\t\t\t/* endTimestamp only meaningful if generateTime is meaningful.\n\t\t\t\t\t * generateTime is meaningful if STATISTICS TIMING is ON.\n\t\t\t\t\t */\n\t\t\t\t\tif (generateTime != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tendTimestamp = new Timestamp(generateTime);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (SanityManager.DEBUG) \n\t\t\t\t\t{\n\t\t\t\t\t\tif (SanityManager.DEBUG_ON(\"StopAfterGenerating\")) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_STOP_AFTER_GENERATING);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t\tcopy over the compile-time created objects\n\t\t\t\t\t\tto the prepared statement.  This always happens\n\t\t\t\t\t\tat the end of a compile, so there is no need\n\t\t\t\t\t\tto erase the previous entries on a re-compile --\n\t\t\t\t\t\tthis erases as it replaces.  Set the activation\n\t\t\t\t\t\tclass in case it came from a StorablePreparedStatement\n\t\t\t\t\t*/\n\t\t\t\t\tpreparedStmt.setConstantAction( qt.makeConstantAction() );\n\t\t\t\t\tpreparedStmt.setSavedObjects( cc.getSavedObjects() );\n\t\t\t\t\tpreparedStmt.setRequiredPermissionsList(cc.getRequiredPermissionsList());\n                    preparedStmt.incrementVersionCounter();\n\t\t\t\t\tpreparedStmt.setActivationClass(ac);\n\t\t\t\t\tpreparedStmt.setNeedsSavepoint(qt.needsSavepoint());\n\t\t\t\t\tpreparedStmt.setCursorInfo((CursorInfo)cc.getCursorInfo());\n\t\t\t\t\tpreparedStmt.setIsAtomic(qt.isAtomic());\n\t\t\t\t\tpreparedStmt.setExecuteStatementNameAndSchema(\n\t\t\t\t\t\t\t\t\t\t\t\tqt.executeStatementName(),\n\t\t\t\t\t\t\t\t\t\t\t\tqt.executeSchemaName()\n\t\t\t\t\t\t\t\t\t\t\t\t);\n\t\t\t\t\tpreparedStmt.setSPSName(qt.getSPSName());\n\t\t\t\t\tpreparedStmt.completeCompile(qt);\n\t\t\t\t\tpreparedStmt.setCompileTimeWarnings(cc.getWarnings());\n\n                    // Schedule updates of any stale index statistics we may\n                    // have detected when creating the plan.\n                    TableDescriptor[] tds = qt.updateIndexStatisticsFor();\n                    if (tds.length > 0) {\n                        IndexStatisticsDaemon isd = lcc.getDataDictionary().\n                            getIndexStatsRefresher(true);\n                        if (isd != null) {\n                            for (int i=0; i < tds.length; i++) {\n                                isd.schedule(tds[i]);\n                            }\n                        }\n                    }\n                }\n\t\t\t\tcatch (StandardException e) \t// hold it, throw it\n\t\t\t\t{\n\t\t\t\t\tlcc.commitNestedTransaction();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\n\t\t\t\tif (lcc.getRunTimeStatisticsMode())\n\t\t\t\t{\n\t\t\t\t\tpreparedStmt.setCompileTimeMillis(\n\t\t\t\t\t\tparseTime - beginTime, //parse time\n\t\t\t\t\t\tbindTime - parseTime, //bind time\n\t\t\t\t\t\toptimizeTime - bindTime, //optimize time\n\t\t\t\t\t\tgenerateTime - optimizeTime, //generate time\n\t\t\t\t\t\tgenerateTime - beginTime, //total compile time\n\t\t\t\t\t\tbeginTimestamp,\n\t\t\t\t\t\tendTimestamp);\n\t\t\t\t}\n\n\t\t\t}\n\t\t\tfinally // for block introduced by pushCompilerContext()\n\t\t\t{\n\t\t\t\tlcc.popCompilerContext( cc );\n\t\t\t}\n\t\t}\n\t\tcatch (StandardException se)\n\t\t{\n\t\t\tif (foundInCache)\n\t\t\t\t((GenericLanguageConnectionContext)lcc).removeStatement(this);\n\n\t\t\tthrow se;\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tsynchronized (preparedStmt) {\n\t\t\t\tpreparedStmt.compilingStatement = false;\n\t\t\t\tpreparedStmt.notifyAll();\n\t\t\t}\n\t\t}\n\n\t\tlcc.commitNestedTransaction();\n\n\t\tif (statementContext != null)\n\t\t\tlcc.popStatementContext(statementContext, null);\n\n\t\treturn preparedStmt;\n\t}"}
{"idx": 147, "target": 0, "func": "public void writeExternal(ObjectOutput out) throws IOException\n\t{\n\t\tout.writeObject(getCursorInfo());\n\t\tout.writeBoolean(needsSavepoint());\n\t\tout.writeBoolean(isAtomic);\n\t\tout.writeObject(executionConstants);\n\t\tout.writeObject(resultDesc);\n\n\t\t// savedObjects may be null\n\t\tif (savedObjects == null)\n\t\t{\n\t\t\tout.writeBoolean(false);\n\t\t}\n\t\telse\n\t\t{\t\n\t\t\tout.writeBoolean(true);\n\t\t\tArrayUtil.writeArrayLength(out, savedObjects);\n\t\t\tArrayUtil.writeArrayItems(out, savedObjects);\n\t\t}\n\n\t\t/*\n\t\t** Write out the class name and byte code\n\t\t** if we have them.  They might be null if\n\t\t** we don't want to write out the plan, and\n\t\t** would prefer it just write out null (e.g.\n\t\t** we know the plan is invalid).\n\t\t*/\n\t\tout.writeObject(className);\n\t\tout.writeBoolean(byteCode != null);\n\t\tif (byteCode != null)\n\t\t    byteCode.writeExternal(out);\n\t}"}
{"idx": 148, "target": 0, "func": "public boolean validate\n\t(\n\t\tString\t\t\tkey,\n\t\tSerializable\tvalue,\n\t\tDictionary\t\tp\n\t) throws StandardException \n\t{\n        // Can't change the dictionary version manually. That could make the database\n        // unbootable. See DERBY-5838.\n\t\tif ( key.trim().equals( DataDictionary.CORE_DATA_DICTIONARY_VERSION ) )\n\t\t{\n            throw StandardException.newException( SQLState.PROPERTY_UNSUPPORTED_CHANGE, key, value );\n        }\n        \n\t\t// Disallow changing sqlAuthorization from true to false or null after\n\t\t// switching to Standard authorization\n\t\tif (key.trim().equals(Property.SQL_AUTHORIZATION_PROPERTY))\n\t\t{\n\t\t\tLanguageConnectionContext lcc = (LanguageConnectionContext)\n\t\t\t\t\tContextService.getContext(LanguageConnectionContext.CONTEXT_ID);\n\n\t\t\tif (lcc.usesSqlAuthorization() && !Boolean.valueOf((String)value).booleanValue())\n\t\t\t\tthrow StandardException.newException(SQLState.PROPERTY_UNSUPPORTED_CHANGE,\n\t\t\t\t\tkey, value);\n\t\t}\n\n\t\tif (key.equals(Property.LANGUAGE_STALE_PLAN_CHECK_INTERVAL)) {\n\t\t\tPropertyUtil.intPropertyValue(\n\t\t\t\t\t\tProperty.LANGUAGE_STALE_PLAN_CHECK_INTERVAL,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tProperty.MIN_LANGUAGE_STALE_PLAN_CHECK_INTERVAL,\n\t\t\t\t\t\tInteger.MAX_VALUE,\n\t\t\t\t\t\tProperty.DEFAULT_LANGUAGE_STALE_PLAN_CHECK_INTERVAL\n\t\t\t\t\t\t);\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}"}
{"idx": 149, "target": 0, "func": "private void handleMinorRevisionChange(TransactionController tc, DD_Version fromVersion, boolean softUpgradeRun) \n\t\tthrows StandardException\n\t{\n\t\tboolean isReadOnly = bootingDictionary.af.isReadOnly();\n\n\t\tif (!isReadOnly) {\n\t\t\t// Once a database is version 10.5 we will start updating metadata SPSes\n\t\t\t// on any version change,up or down.  This will ensure that metadata queries \n\t\t\t// match the version we are using.  We don't want to do this for lower \n\t\t\t// database versions because on reverting to the previous version the \n\t\t\t// SPSes won't be restored.\n\t\t\tif (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)\n\t\t\t\tbootingDictionary.updateMetadataSPSes(tc);\n\t\t\t//Following make sure that the stored plans (including the ones for\n\t\t\t//triggers) will get cleared during upgrade and hence we will not\n\t\t\t//hold on to stale plans.\n\t\t\tbootingDictionary.clearSPSPlans();\n\n\t\t\tDD_Version lastRun;\n\t\t\t\n\t\t\tif (softUpgradeRun)\n\t\t\t{\n\t\t\t\t// log a version that will cause a minor revision change\n\t\t\t\t// for any subsequent re-boot, including an old Cloudscape version\n\t\t\t\tfromVersion.minorVersionNumber = 1; // see getJBMSMinorVersionNumber\n\t\t\t\tlastRun = fromVersion;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// log the new version\n\t\t\t\tlastRun = this;\n\t\t\t\n\t\t\t\t// and change the in-memory version.\n\t\t\t\tfromVersion.majorVersionNumber = majorVersionNumber;\n\t\t\t\tfromVersion.minorVersionNumber = minorVersionNumber;\n\t\t\t}\n\n\t\t\ttc.setProperty(DataDictionary.CORE_DATA_DICTIONARY_VERSION, fromVersion, true);\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// For a readonly database where we need some kind of upgrade\n\t\t\t// (either minor release or soft upgrade) then since we cannot\n\t\t\t// invalidate all the procedures we need to indicate that\n\t\t\t// any procedure we read off disk is automatically invalid,\n\t\t\t// so we do not try to load the generated class.\n\t\t\tbootingDictionary.setReadOnlyUpgrade();\n\t\t}\n\n\t\tbootingDictionary.clearCaches();\n\t}"}
{"idx": 150, "target": 0, "func": "public void\taddConstraintDescriptor(\n\t\t\tConstraintDescriptor descriptor,\n\t\t\tTransactionController tc)\n\t\tthrows StandardException\n\t{\n\t\tint\t\t\t\t\t\ttype = descriptor.getConstraintType();\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (!(type == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.FOREIGNKEY_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.UNIQUE_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.CHECK_CONSTRAINT))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\"constraint type (\" + type +\n\t\t\t\t\t\") is unexpected value\");\n\t\t\t}\n\t\t}\n\n\t\taddDescriptor(descriptor, descriptor.getSchemaDescriptor(),\n\t\t\t\t\t  SYSCONSTRAINTS_CATALOG_NUM, false,\n\t\t\t\t\t  tc);\n\n\t\tswitch (type)\n\t\t{\n\t\t\tcase DataDictionary.PRIMARYKEY_CONSTRAINT:\n\t\t\tcase DataDictionary.FOREIGNKEY_CONSTRAINT:\n\t\t\tcase DataDictionary.UNIQUE_CONSTRAINT:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tif (!(descriptor instanceof KeyConstraintDescriptor))\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\t\t\"descriptor expected to be instanceof KeyConstraintDescriptor, \" +\n\t\t\t\t\t\t\t\"not, \" + descriptor.getClass().getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\taddSubKeyConstraint((KeyConstraintDescriptor) descriptor, tc);\n\t\t\t\tbreak;\n\n\t\t\tcase DataDictionary.CHECK_CONSTRAINT:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tif (!(descriptor instanceof CheckConstraintDescriptor))\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\"descriptor expected \"+\n\t\t\t\t\t\t\t\"to be instanceof CheckConstraintDescriptorImpl, \" +\n\t\t\t\t\t\t\t\"not, \" + descriptor.getClass().getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\taddDescriptor(descriptor, null, SYSCHECKS_CATALOG_NUM, true, tc);\n\t\t\t\tbreak;\n\t\t}\n\t}"}
{"idx": 151, "target": 0, "func": "public void dropAllPermDescriptors(UUID objectID, TransactionController tc)\n            throws StandardException {\n        TabInfoImpl ti = getNonCoreTI(SYSPERMS_CATALOG_NUM);\n        SYSPERMSRowFactory rf = (SYSPERMSRowFactory) ti.getCatalogRowFactory();\n        DataValueDescriptor objIdOrderable;\n        ExecRow curRow;\n        PermissionsDescriptor perm;\n\n        // In Derby authorization mode, permission catalogs may not be present\n        if (!usesSqlAuthorization)\n            return;\n\n        /* Use objIDOrderable in both start and stop position for scan. */\n        objIdOrderable = getIDValueAsCHAR(objectID);\n\n        /* Set up the start/stop position for the scan */\n        ExecIndexRow keyRow = exFactory.getIndexableRow(1);\n        keyRow.setColumn(1, objIdOrderable);\n\n        while ((curRow = ti.getRow(tc, keyRow, rf.PERMS_OBJECTID_IDX_NUM)) != null) {\n            perm = (PermissionsDescriptor) rf.buildDescriptor(curRow, (TupleDescriptor) null, this);\n            removePermEntryInCache(perm);\n\n            // Build new key based on UUID and drop the entry as we want to drop\n            // only this row\n            ExecIndexRow uuidKey;\n            uuidKey = rf.buildIndexKeyRow(rf.PERMS_UUID_IDX_NUM, perm);\n            ti.deleteRow(tc, uuidKey, rf.PERMS_UUID_IDX_NUM);\n        }\n    }"}
{"idx": 152, "target": 1, "func": "protected boolean isSchemaReferenced(TransactionController\ttc, \n\t\t\t\t\t\tTabInfoImpl\t\t\t\t\tti, \n\t\t\t\t\t\tint\t\t\t\t\t\tindexId, \n\t\t\t\t\t\tint\t\t\t\t\t\tindexCol, \n\t\t\t\t\t\tDataValueDescriptor\t\tschemaIdOrderable )\n\t\tthrows StandardException\n\t{\n\t\tConglomerateController\theapCC = null;\n\t\tScanController\t\t\tscanController = null;\n\t\tboolean\t\t\t\t\tfoundRow;\n\t\tFormatableBitSet\t\t\t\t\tcolToCheck = new FormatableBitSet(indexCol);\n\t\tCatalogRowFactory\t\trf = ti.getCatalogRowFactory();\t\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tSanityManager.ASSERT(indexId >= 0, \"code needs to be enhanced\"+\n\t\t\t\t\" to support a table scan to find the index id\");\n\t\t}\n\n\t\tcolToCheck.set(indexCol - 1);\n\n\t\tScanQualifier[][] qualifier = exFactory.getScanQualifier(1);\n\t\tqualifier[0][0].setQualifier\n\t\t\t\t(indexCol - 1,\n\t\t\t\t schemaIdOrderable,\n\t\t\t\t Orderable.ORDER_OP_EQUALS,\n\t\t\t\t false,\n\t\t\t\t false,\n\t\t\t\t false);\n\n\t\ttry\n\t\t{\n\t\t\theapCC = \n\t            tc.openConglomerate(\n\t                ti.getHeapConglomerate(), false, 0, \n                    TransactionController.MODE_RECORD,\n                    TransactionController.ISOLATION_REPEATABLE_READ);\n\t\n\t\t\tscanController = tc.openScan(\n\t\t\t\t\tti.getIndexConglomerate(indexId),\t// conglomerate to open\n\t\t\t\t\tfalse, \t\t\t\t\t\t\t\t// don't hold open across commit\n\t\t\t\t\t0,                                  // for read\n\t                TransactionController.MODE_RECORD,\t// row locking\n                    TransactionController.ISOLATION_REPEATABLE_READ,\n\t\t\t\t\tcolToCheck, \t\t\t\t\t\t// don't get any rows\n\t\t\t\t\tnull,   \t\t\t\t\t\t\t// start position - first row\n\t\t\t\t\tScanController.GE,      \t\t\t// startSearchOperation\n\t\t\t\t\tqualifier, \t\t\t\t\t\t\t// scanQualifier,\n\t\t\t\t\tnull,   \t\t\t\t\t\t\t// stop position - through last row\n\t\t\t\t\tScanController.GT);     \t\t\t// stopSearchOperation\n\t\n\t\t\tfoundRow = (scanController.next());\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (scanController != null)\t\n\t\t\t{\n\t\t\t\tscanController.close();\n\t\t\t}\n\t\t\tif (heapCC != null)\n\t\t\t{\n\t\t\t\theapCC.close();\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn foundRow;\n\t}"}
{"idx": 153, "target": 0, "func": "protected void populateSYSDUMMY1(\n\t\t\t\t\t\t\tTransactionController tc)\n\t\tthrows StandardException\n\t{\n\t\tTabInfoImpl\t\t\t\t\t\tti = getNonCoreTI(SYSDUMMY1_CATALOG_NUM);\n\t\tExecRow row = ti.getCatalogRowFactory().makeRow(null, null);\n\n\t\tint insertRetCode = ti.insertRow(row, tc);\n\t}"}
{"idx": 154, "target": 0, "func": "void upgradeSYSROUTINEPERMS_10_6( TransactionController tc )\n        throws StandardException\n    {\n        //\n        // Get the aliasID of SYSCS_INPLACE_COMPRESS_TABLE\n        //\n\t\tTabInfoImpl          aliasTI = getNonCoreTI(SYSALIASES_CATALOG_NUM);\n\t\tExecIndexRow         aliasKeyRow = exFactory.getIndexableRow(3);\n\t\tDataValueDescriptor  aliasNameOrderable = new SQLVarchar( \"SYSCS_INPLACE_COMPRESS_TABLE\" );;\n\t\tDataValueDescriptor\t nameSpaceOrderable = new SQLChar\n            ( new String( new char[] { AliasInfo.ALIAS_TYPE_PROCEDURE_AS_CHAR } ) );\n        \n\t\taliasKeyRow.setColumn(1, new SQLChar( SchemaDescriptor.SYSCS_UTIL_SCHEMA_UUID ));\n\t\taliasKeyRow.setColumn(2, aliasNameOrderable);\n\t\taliasKeyRow.setColumn(3, nameSpaceOrderable);\n\n        AliasDescriptor      oldAD = (AliasDescriptor) getDescriptorViaIndex\n            (\n             SYSALIASESRowFactory.SYSALIASES_INDEX1_ID,\n             aliasKeyRow,\n             (ScanQualifier [][]) null,\n             aliasTI,\n             (TupleDescriptor) null,\n             (List) null,\n             true,\n             TransactionController.ISOLATION_REPEATABLE_READ,\n             tc);\n        UUID                 aliasID = oldAD.getUUID();\n\n        //\n        // Now delete the permissions tuple which has a null grantor\n        //\n\t\tTabInfoImpl          rpTI = getNonCoreTI(SYSROUTINEPERMS_CATALOG_NUM);\n\t\tExecIndexRow         rpKeyRow = exFactory.getIndexableRow(3);\n\n\t\trpKeyRow.setColumn(1, new SQLVarchar( \"PUBLIC\" ));\n\t\trpKeyRow.setColumn(2, new SQLChar( aliasID.toString() ));\n\t\trpKeyRow.setColumn(3, new SQLVarchar( (String) null ) );\n\n\t\tint deleteCount = rpTI.deleteRow(tc, rpKeyRow, SYSROUTINEPERMSRowFactory.GRANTEE_ALIAS_GRANTOR_INDEX_NUM);\n    }"}
{"idx": 155, "target": 1, "func": "public  PasswordHasher  makePasswordHasher( Dictionary props )\n        throws StandardException\n    {\n        // Support for configurable hash algorithm was added in Derby 10.6, so\n        // we don't want to store a hash using the new scheme if the database\n        // is running in soft upgrade and may be used with an older version\n        // later.\n        boolean supportConfigurableHash = checkVersion(DataDictionary.DD_VERSION_DERBY_10_6, null);\n\n        // Support for key stretching was added in Derby 10.9, so don't use it\n        // if the database may still be used with an older version.\n        boolean supportKeyStretching = checkVersion(DataDictionary.DD_VERSION_DERBY_10_9, null);\n\n        if ( !supportConfigurableHash ) { return null; }\n        else\n        {\n            String algorithm = (String)\n                    PropertyUtil.getPropertyFromSet(\n                        props,\n                        Property.AUTHENTICATION_BUILTIN_ALGORITHM);\n\n            if ( algorithm == null ) { return null; }\n\n            byte[] salt = null;\n            int iterations = 1;\n            \n            if (algorithm != null && algorithm.length() > 0) {\n\n                if (supportKeyStretching) {\n                    salt = generateRandomSalt(props);\n                    iterations = getIntProperty(\n                            props,\n                            Property.AUTHENTICATION_BUILTIN_ITERATIONS,\n                            Property.AUTHENTICATION_BUILTIN_ITERATIONS_DEFAULT,\n                            1, Integer.MAX_VALUE);\n                }\n            }\n\n            return new PasswordHasher( algorithm, salt, iterations );\n        }\n    }"}
{"idx": 156, "target": 0, "func": "public void\taddConstraintDescriptor(\n\t\t\tConstraintDescriptor descriptor,\n\t\t\tTransactionController tc)\n\t\tthrows StandardException\n\t{\n\t\tint\t\t\t\t\t\ttype = descriptor.getConstraintType();\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (!(type == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.FOREIGNKEY_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.UNIQUE_CONSTRAINT ||\n\t\t\t\t\t\t\t\t type == DataDictionary.CHECK_CONSTRAINT))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\"constraint type (\" + type +\n\t\t\t\t\t\") is unexpected value\");\n\t\t\t}\n\t\t}\n\n\t\taddDescriptor(descriptor, descriptor.getSchemaDescriptor(),\n\t\t\t\t\t  SYSCONSTRAINTS_CATALOG_NUM, false,\n\t\t\t\t\t  tc);\n\n\t\tswitch (type)\n\t\t{\n\t\t\tcase DataDictionary.PRIMARYKEY_CONSTRAINT:\n\t\t\tcase DataDictionary.FOREIGNKEY_CONSTRAINT:\n\t\t\tcase DataDictionary.UNIQUE_CONSTRAINT:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tif (!(descriptor instanceof KeyConstraintDescriptor))\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\t\t\"descriptor expected to be instanceof KeyConstraintDescriptor, \" +\n\t\t\t\t\t\t\t\"not, \" + descriptor.getClass().getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\taddSubKeyConstraint((KeyConstraintDescriptor) descriptor, tc);\n\t\t\t\tbreak;\n\n\t\t\tcase DataDictionary.CHECK_CONSTRAINT:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tif (!(descriptor instanceof CheckConstraintDescriptor))\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\"descriptor expected \"+\n\t\t\t\t\t\t\t\"to be instanceof CheckConstraintDescriptorImpl, \" +\n\t\t\t\t\t\t\t\"not, \" + descriptor.getClass().getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\taddDescriptor(descriptor, null, SYSCHECKS_CATALOG_NUM, true, tc);\n\t\t\t\tbreak;\n\t\t}\n\t}"}
{"idx": 157, "target": 1, "func": "public TupleDescriptor buildDescriptor\n\t(\n\t\tExecRow\t\t\t\t\trow,\n\t\tTupleDescriptor\t\t\tparentTupleDescriptor,\n\t\tDataDictionary \t\t\tdd \n\t) throws StandardException\n\t{\n\t\tDataValueDescriptor\t\tcol;\n\t\tString\t\t\t\t\tname;\n\t\tchar\t\t\t\t\ttheChar;\n\t\tString\t\t\t\t\tuuidStr;\n\t\tString\t\t\t\t\ttriggerDefinition;\n\t\tString\t\t\t\t\toldReferencingName;\n\t\tString\t\t\t\t\tnewReferencingName;\n\t\tUUID\t\t\t\t\tuuid;\t\n\t\tUUID\t\t\t\t\tsuuid;\t\t\t\t\t// schema\t\n\t\tUUID\t\t\t\t\ttuuid;\t\t\t\t\t// referenced table\t\n\t\tUUID\t\t\t\t\tactionSPSID = null;\t\t// action sps uuid string\n\t\tUUID\t\t\t\t\twhenSPSID = null;\t\t// when clause sps uuid string\n\t\tTimestamp\t\t\t\tcreateTime;\n\t\tint\t\t\t\t\t\teventMask = 0;\n\t\tboolean\t\t\t\t\tisBefore;\n\t\tboolean\t\t\t\t\tisRow;\n\t\tboolean\t\t\t\t\tisEnabled;\n\t\tboolean\t\t\t\t\treferencingOld;\n\t\tboolean\t\t\t\t\treferencingNew;\n\t\tReferencedColumns rcd;\n\t\tTriggerDescriptor\t\tdescriptor;\n\t\tDataDescriptorGenerator\tddg = dd.getDataDescriptorGenerator();\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tSanityManager.ASSERT(row.nColumns() == SYSTRIGGERS_COLUMN_COUNT, \n\t\t\t\t\t\t\t\t \"Wrong number of columns for a SYSTRIGGERS row\");\n\t\t}\n\n\t\t// 1st column is TRIGGERID (UUID - char(36))\n\t\tcol = row.getColumn(1);\n\t\tuuidStr = col.getString();\n\t\tuuid = getUUIDFactory().recreateUUID(uuidStr);\n\n\t\t// 2nd column is TRIGGERNAME (varchar(128))\n\t\tcol = row.getColumn(2);\n\t\tname = col.getString();\n\n\t\t// 3rd column is SCHEMAID (UUID - char(36))\n\t\tcol = row.getColumn(3);\n\t\tuuidStr = col.getString();\n\t\tsuuid = getUUIDFactory().recreateUUID(uuidStr);\n\n\t\t// 4th column is CREATIONTIMESTAMP (TIMESTAMP)\n\t\tcol = row.getColumn(4);\n\t\tcreateTime = (Timestamp) col.getObject();\n\n\t\t// 5th column is EVENT (char(1))\n\t\tcol = row.getColumn(5);\n\t\ttheChar = col.getString().charAt(0);\n\t\tswitch (theChar)\n\t\t{\n\t\t\tcase 'U': \n\t\t\t\t\t\teventMask = TriggerDescriptor.TRIGGER_EVENT_UPDATE;\n\t\t\t\t\t\tbreak;\n\n\t\t\tcase 'I': \n\t\t\t\t\t\teventMask = TriggerDescriptor.TRIGGER_EVENT_INSERT;\n\t\t\t\t\t\tbreak;\n\n\t\t\tcase 'D': \n\t\t\t\t\t\teventMask = TriggerDescriptor.TRIGGER_EVENT_DELETE;\n\t\t\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\t\tif (SanityManager.DEBUG)\t\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\"bad event mask: \"+theChar);\n\t\t\t\t\t}\n\t\t}\n\t\t\n\t\t// 6th column is FIRINGTIME (char(1))\n\t\tisBefore = getCharBoolean(row.getColumn(6), 'B', 'A');\n\n\t\t// 7th column is TYPE (char(1))\n\t\tisRow = getCharBoolean(row.getColumn(7), 'R', 'S');\n\n\t\t// 8th column is STATE (char(1))\n\t\tisEnabled = getCharBoolean(row.getColumn(8), 'E', 'D');\n\n\t\t// 9th column is TABLEID (UUID - char(36))\n\t\tcol = row.getColumn(9);\n\t\tuuidStr = col.getString();\n\t\ttuuid = getUUIDFactory().recreateUUID(uuidStr);\n\n\t\t// 10th column is WHENSTMTID (UUID - char(36))\n\t\tcol = row.getColumn(10);\n\t\tuuidStr = col.getString();\n\t\tif (uuidStr != null)\n\t\t\twhenSPSID = getUUIDFactory().recreateUUID(uuidStr);\n\n\t\t// 11th column is ACTIONSTMTID (UUID - char(36))\n\t\tcol = row.getColumn(11);\n\t\tuuidStr = col.getString();\n\t\tif (uuidStr != null)\n\t\t\tactionSPSID = getUUIDFactory().recreateUUID(uuidStr);\n\n\t\t// 12th column is REFERENCEDCOLUMNS user type org.apache.derby.catalog.ReferencedColumns\n\t\tcol = row.getColumn(12);\n\t\trcd = (ReferencedColumns) col.getObject();\n\t\t\n\t\t// 13th column is TRIGGERDEFINITION (longvarhar)\n\t\tcol = row.getColumn(13);\n\t\ttriggerDefinition = col.getString();\n\n\t\t// 14th column is REFERENCINGOLD (boolean)\n\t\tcol = row.getColumn(14);\n\t\treferencingOld = col.getBoolean();\n\n\t\t// 15th column is REFERENCINGNEW (boolean)\n\t\tcol = row.getColumn(15);\n\t\treferencingNew = col.getBoolean();\n\n\t\t// 16th column is REFERENCINGNAME (varchar(128))\n\t\tcol = row.getColumn(16);\n\t\toldReferencingName = col.getString();\n\n\t\t// 17th column is REFERENCINGNAME (varchar(128))\n\t\tcol = row.getColumn(17);\n\t\tnewReferencingName = col.getString();\n\n\t\tdescriptor = new TriggerDescriptor(\n\t\t\t\t\t\t\t\t\tdd,\n\t\t\t\t\t\t\t\t\tdd.getSchemaDescriptor(suuid, null),\n\t\t\t\t\t\t\t\t\tuuid, \n\t\t\t\t\t\t\t\t\tname, \n\t\t\t\t\t\t\t\t\teventMask,\n\t\t\t\t\t\t\t\t\tisBefore, \n\t\t\t\t\t\t\t\t\tisRow,\n\t\t\t\t\t\t\t\t\tisEnabled,\n\t\t\t\t\t\t\t\t\tdd.getTableDescriptor(tuuid),\n\t\t\t\t\t\t\t\t\twhenSPSID,\n\t\t\t\t\t\t\t\t\tactionSPSID,\n\t\t\t\t\t\t\t\t\tcreateTime,\n\t\t\t\t\t\t\t\t\t(rcd == null) ? (int[])null : rcd.getReferencedColumnPositions(),\n\t\t\t\t\t\t\t\t\t(rcd == null) ? (int[])null : rcd.getTriggerActionReferencedColumnPositions(),\n\t\t\t\t\t\t\t\t\ttriggerDefinition,\n\t\t\t\t\t\t\t\t\treferencingOld,\n\t\t\t\t\t\t\t\t\treferencingNew,\n\t\t\t\t\t\t\t\t\toldReferencingName,\n\t\t\t\t\t\t\t\t\tnewReferencingName\n\t\t\t\t\t\t\t\t\t);\n\n\t\treturn descriptor;\n\t}"}
{"idx": 158, "target": 0, "func": "public ExecRow makeRow( TupleDescriptor td, TupleDescriptor parent )\n        throws StandardException\n\t{\n\t\tString  userName = null;\n\t\tString  hashingScheme = null;\n\t\tchar[]  password = null;\n\t\tTimestamp   lastModified = null;\n\t\t\n\t\tExecRow        \t\t\trow;\n\n        try {\n            if ( td != null )\t\n            {\n                UserDescriptor descriptor = (UserDescriptor) td;\n                userName = descriptor.getUserName();\n                hashingScheme = descriptor.getHashingScheme();\n                password = descriptor.getAndZeroPassword();\n                lastModified = descriptor.getLastModified();\n            }\n\t\n            /* Build the row to insert  */\n            row = getExecutionFactory().getValueRow( SYSUSERS_COLUMN_COUNT );\n\n            /* 1st column is USERNAME (varchar(128)) */\n            row.setColumn( USERNAME_COL_NUM, new SQLVarchar( userName ) );\n\n            /* 2nd column is HASHINGSCHEME (varchar(32672)) */\n            row.setColumn( HASHINGSCHEME_COL_NUM, new SQLVarchar( hashingScheme ) );\n\n            /* 3rd column is PASSWORD (varchar(32672)) */\n            row.setColumn( PASSWORD_COL_NUM, new SQLVarchar( password ) );\n\n            /* 4th column is LASTMODIFIED (timestamp) */\n            row.setColumn( LASTMODIFIED_COL_NUM, new SQLTimestamp( lastModified ) );\n        }\n        finally\n        {\n            // zero out the password to prevent it from being memory-sniffed\n            if ( password != null ) { Arrays.fill( password, (char) 0 ); }\n        }\n\n\t\treturn row;\n\t}"}
{"idx": 159, "target": 0, "func": "public ExecRow makeRow(TupleDescriptor td, TupleDescriptor parent)\n\t\tthrows StandardException \n\t{\n\t\tDataValueDescriptor\t\tcol;\n\t\tExecRow    \t\t\t\trow;\n\t\tString\t\t\t\t\ttableID = null;\n\t\tString\t\t\t\t\tcompSchemaId = null;\n\t\tString\t\t\t\t\tviewText = null;\n\t\tString\t   \t\t\t\tcheckSType = null;\n\t\tint\t   \t\t\t\t\tcheckIType;\n\n\t\tif (td != null)\n\t\t{\n\t\t\tUUID\ttableUUID;\n\t\t\tViewDescriptor vd = (ViewDescriptor)td;\n\n\t\t\t/*\n\t\t\t** We only allocate a new UUID if the descriptor doesn't already have one.\n\t\t\t** For descriptors replicated from a Source system, we already have an UUID.\n\t\t\t*/\n\t\t\ttableUUID = vd.getUUID();\n\t\t\tif ( tableUUID == null )\n\t\t    {\n\t\t\t\ttableUUID = getUUIDFactory().createUUID();\n\t\t\t\tvd.setUUID(tableUUID);\n\t\t\t}\n\t\t\ttableID = tableUUID.toString();\n\t\t\tviewText = vd.getViewText();\n\n\t\t\t/* RESOLVE - check constraints not supported yet */\n\t\t\tcheckIType = vd.getCheckOptionType();\n\n\t\t\tif (SanityManager.DEBUG)\n\t\t\t{\n\t\t\t\tif (checkIType != ViewDescriptor.NO_CHECK_OPTION)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"checkIType expected to be \" + \n\t\t\t\t\t\tViewDescriptor.NO_CHECK_OPTION +\n\t\t\t\t\t\t\", not \" + checkIType);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcheckSType = \"N\";\n\n\t\t\tUUID tmpId = vd.getCompSchemaId();\n\t\t\tcompSchemaId = (tmpId == null) ? null : tmpId.toString();\n\t\t}\n\n\t\t/* Insert info into sysviews */\n\n\t\t/* RESOLVE - It would be nice to require less knowledge about sysviews\n\t\t * and have this be more table driven.\n\t\t */\n\n\t\t/* Build the row to insert  */\n\t\trow = getExecutionFactory().getValueRow(SYSVIEWS_COLUMN_COUNT);\n\n\t\t/* 1st column is TABLEID (UUID - char(36)) */\n\t\trow.setColumn(SYSVIEWS_TABLEID, new SQLChar(tableID));\n\n\t\t/* 2nd column is VIEWDEFINITION */\n\t\trow.setColumn(SYSVIEWS_VIEWDEFINITION,\n\t\t\t\tdvf.getLongvarcharDataValue(viewText));\n\n\t\t/* 3rd column is CHECKOPTION (char(1)) */\n\t\trow.setColumn(SYSVIEWS_CHECKOPTION, new SQLChar(checkSType));\n\n\t\t/* 4th column is COMPILATIONSCHEMAID (UUID - char(36)) */\n\t\trow.setColumn(SYSVIEWS_COMPILATION_SCHEMAID, new SQLChar(compSchemaId));\n\n\t\treturn row;\n\t}"}
{"idx": 160, "target": 1, "func": "public void bindComparisonOperator()\n\t\t\tthrows StandardException\n\t{\n\t\tTypeId\tleftType;\n\t\tTypeId\trightType;\n\t\tboolean\t\t\t\tnullableResult;\n\n\t\tleftType = leftOperand.getTypeId();\n\t\trightType = rightOperand.getTypeId();\n\n\n\t\t/*\n\t\t** Can the types be compared to each other?  If not, throw an\n\t\t** exception.\n\t\t*/\n\t\tboolean forEquals = operator.equals(\"=\") || operator.equals(\"<>\");\n\n        boolean cmp = leftOperand.getTypeServices().comparable(\n        \t\trightOperand.getTypeServices(),\n\t\t\t\tforEquals,\n\t\t\t\tgetClassFactory());\n\t\t// Bypass the comparable check if this is a rewrite from the \n\t\t// optimizer.  We will assume Mr. Optimizer knows what he is doing.\n          if (!cmp && !forQueryRewrite) {\n\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_COMPARABLE, \n\t\t\t\t\tleftOperand.getTypeServices().getSQLTypeNameWithCollation() ,\n\t\t\t\t\trightOperand.getTypeServices().getSQLTypeNameWithCollation());\n\t\t\t\t\n\t\t  }\n\n\t\t\n\t\t/*\n\t\t** Set the result type of this comparison operator based on the\n\t\t** operands.  The result type is always SQLBoolean - the only question\n\t\t** is whether it is nullable or not.  If either of the operands is\n\t\t** nullable, the result of the comparison must be nullable, too, so\n\t\t** we can represent the unknown truth value.\n\t\t*/\n\t\tnullableResult = leftOperand.getTypeServices().isNullable() ||\n\t\t\t\t\t\t\trightOperand.getTypeServices().isNullable();\n\t\tsetType(new DataTypeDescriptor(TypeId.BOOLEAN_ID, nullableResult));\n\n\n\t}"}
{"idx": 161, "target": 1, "func": "public ValueNode bindExpression(\n\t\tFromList fromList, SubqueryList subqueryList,\n\t\tVector\taggregateVector)\n\t\t\tthrows StandardException\n\t{\n\t\tsuper.bindExpression(fromList, subqueryList, aggregateVector);\n\n\t\tTypeCompiler leftTC = leftOperand.getTypeCompiler();\n\t\tTypeCompiler rightTC = rightOperand.getTypeCompiler();\n\t\tTypeId leftTypeId = leftOperand.getTypeId();\n\t\tTypeId rightTypeId = rightOperand.getTypeId();\n\n\t\t/*\n\t\t * If we are comparing a non-string with a string type, then we\n\t\t * must prevent the non-string value from being used to probe into\n\t\t * an index on a string column. This is because the string types\n\t\t * are all of low precedence, so the comparison rules of the non-string\n\t\t * value are used, so it may not find values in a string index because\n\t\t * it will be in the wrong order. So, cast the string value to its\n\t\t * own type. This is easier than casting it to the non-string type,\n\t\t * because we would have to figure out the right length to cast it to.\n\t\t */\n\t\tif (! leftTypeId.isStringTypeId() && rightTypeId.isStringTypeId())\n\t\t{\n\t\t\tDataTypeDescriptor rightTypeServices = rightOperand.getTypeServices();\n\n\t\t\trightOperand =  (ValueNode)\n\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\tC_NodeTypes.CAST_NODE,\n\t\t\t\t\trightOperand, \n\t\t\t\t\tnew DataTypeDescriptor(\n\t\t\t\t\t\t\trightTypeId,\n\t\t\t\t\t\t\ttrue, \n\t\t\t\t\t\t\trightTypeServices.getMaximumWidth()),\n\t\t\t\t\tgetContextManager());\n\t\t\t((CastNode) rightOperand).bindCastNodeOnly();\n\t\t}\n\t\telse if (! rightTypeId.isStringTypeId() && leftTypeId.isStringTypeId())\n\t\t{\n\t\t\tDataTypeDescriptor leftTypeServices = leftOperand.getTypeServices();\n\n\t\t\tleftOperand =  (ValueNode)\n\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\tC_NodeTypes.CAST_NODE,\n\t\t\t\t\tleftOperand, \n\t\t\t\t\tnew DataTypeDescriptor(\n\t\t\t\t\t\t\tleftTypeId,\n\t\t\t\t\t\t\ttrue, \n\t\t\t\t\t\t\tleftTypeServices.getMaximumWidth()),\n\t\t\t\t\tgetContextManager());\n\t\t\t((CastNode) leftOperand).bindCastNodeOnly();\n\t\t}\n\n\t\t/* Test type compatability and set type info for this node */\n\t\tbindComparisonOperator();\n\n\t\treturn this;\n\t}"}
{"idx": 162, "target": 1, "func": "public ValueNode bindXMLQuery()\n        throws StandardException\n    {\n        // Check operand types.\n        TypeId leftOperandType = leftOperand.getTypeId();\n        TypeId rightOperandType = rightOperand.getTypeId();\n\n        // Left operand is query expression and must be a string\n        // literal.  SQL/XML spec doesn't allow params nor expressions\n        // 6.17: <XQuery expression> ::= <character string literal> \n        if (!(leftOperand instanceof CharConstantNode))\n        {\n            throw StandardException.newException(\n                SQLState.LANG_INVALID_XML_QUERY_EXPRESSION);\n        }\n        else {\n            xmlQuery = ((CharConstantNode)leftOperand).getString();\n        }\n\n        // Right operand must be an XML data value.  NOTE: This\n        // is a Derby-specific restriction, not an SQL/XML one.\n        // We have this restriction because the query engine\n        // that we use (currently Xalan) cannot handle non-XML\n        // context items.\n        if ((rightOperandType != null) &&\n            !rightOperandType.isXMLTypeId())\n        {\n            throw StandardException.newException(\n                SQLState.LANG_INVALID_CONTEXT_ITEM_TYPE,\n                rightOperandType.getSQLTypeName());\n        }\n\n        // Is there a ? parameter on the right?\n        if (rightOperand.requiresTypeFromContext())\n        {\n            // For now, since JDBC has no type defined for XML, we\n            // don't allow binding to an XML parameter.\n            throw StandardException.newException(\n                SQLState.LANG_ATTEMPT_TO_BIND_XML);\n        }\n\n        // Set the result type of this operator.\n        if (operatorType == XMLEXISTS_OP) {\n        // For XMLEXISTS, the result type is always SQLBoolean.\n        // The \"true\" in the next line says that the result\n        // can be nullable--which it can be if evaluation of\n        // the expression returns a null (this is per SQL/XML\n        // spec, 8.4)\n            setType(new DataTypeDescriptor(TypeId.BOOLEAN_ID, true));\n        }\n        else {\n        // The result of an XMLQUERY operator is always another\n        // XML data value, per SQL/XML spec 6.17: \"...yielding a value\n        // X1 of an XML type.\"\n            setType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(\n                    JDBC40Translation.SQLXML));\n        }\n\n        return genSQLJavaSQLTree();\n    }"}
{"idx": 163, "target": 0, "func": "public void generateOperator(MethodBuilder mb,\n\t\t\t\t\t\t\t\t Optimizable optTable)\n\t{\n\t\tswitch (operatorType)\n\t\t{\n\t\t\tcase RelationalOperator.EQUALS_RELOP:\n\t\t\t\tmb.push(Orderable.ORDER_OP_EQUALS);\n\t\t\t\tbreak;\n\n\t\t\tcase RelationalOperator.NOT_EQUALS_RELOP:\n\t\t\t\tmb.push(Orderable.ORDER_OP_EQUALS);\n\t\t\t\tbreak;\n\n\t\t\tcase RelationalOperator.LESS_THAN_RELOP:\n\t\t\tcase RelationalOperator.GREATER_EQUALS_RELOP:\n\t\t\t\tmb.push(keyColumnOnLeft(optTable) ? \n\t\t\t\t\t\tOrderable.ORDER_OP_LESSTHAN : Orderable.ORDER_OP_LESSOREQUALS);\n\t\t\t\tbreak;\n\t\t\tcase RelationalOperator.LESS_EQUALS_RELOP:\n\t\t\tcase RelationalOperator.GREATER_THAN_RELOP:\n\t\t\t\tmb.push(keyColumnOnLeft(optTable) ? \n\t\t\t\t\t\tOrderable.ORDER_OP_LESSOREQUALS : Orderable.ORDER_OP_LESSTHAN);\n\t\t\t\t\n\t\t}\t\t\t\t\t\t\t\t\t\t\t\n\t}"}
{"idx": 164, "target": 0, "func": "public void generateNegate(MethodBuilder mb, Optimizable optTable)\n\t{\n\t\tswitch (operatorType)\n\t\t{\n\t\t\tcase RelationalOperator.EQUALS_RELOP:\n\t\t\t\tmb.push(false);\n\t\t\t\tbreak;\n\t\t\tcase RelationalOperator.NOT_EQUALS_RELOP:\n\t\t\t\tmb.push(true);\n\t\t\t\tbreak;\n\t\t\tcase RelationalOperator.LESS_THAN_RELOP:\n\t\t\tcase RelationalOperator.LESS_EQUALS_RELOP:\n\t\t\t\tmb.push(!keyColumnOnLeft(optTable));\n\t\t\t\tbreak;\n\t\t\tcase RelationalOperator.GREATER_THAN_RELOP:\n\t\t\tcase RelationalOperator.GREATER_EQUALS_RELOP:\n\t\t\t\tmb.push(keyColumnOnLeft(optTable));\n\t\t\t\tbreak;\n\t\t}\n\t\t\n\t\treturn;\n\t}"}
{"idx": 165, "target": 0, "func": "public void generateOperator(MethodBuilder mb,\n\t\t\t\t\t\t\t\t Optimizable optTable)\n\t{\n\t\tswitch (operatorType)\n\t\t{\n\t\t\tcase RelationalOperator.EQUALS_RELOP:\n\t\t\t\tmb.push(Orderable.ORDER_OP_EQUALS);\n\t\t\t\tbreak;\n\n\t\t\tcase RelationalOperator.NOT_EQUALS_RELOP:\n\t\t\t\tmb.push(Orderable.ORDER_OP_EQUALS);\n\t\t\t\tbreak;\n\n\t\t\tcase RelationalOperator.LESS_THAN_RELOP:\n\t\t\tcase RelationalOperator.GREATER_EQUALS_RELOP:\n\t\t\t\tmb.push(keyColumnOnLeft(optTable) ? \n\t\t\t\t\t\tOrderable.ORDER_OP_LESSTHAN : Orderable.ORDER_OP_LESSOREQUALS);\n\t\t\t\tbreak;\n\t\t\tcase RelationalOperator.LESS_EQUALS_RELOP:\n\t\t\tcase RelationalOperator.GREATER_THAN_RELOP:\n\t\t\t\tmb.push(keyColumnOnLeft(optTable) ? \n\t\t\t\t\t\tOrderable.ORDER_OP_LESSOREQUALS : Orderable.ORDER_OP_LESSTHAN);\n\t\t\t\t\n\t\t}\t\t\t\t\t\t\t\t\t\t\t\n\t}"}
{"idx": 166, "target": 1, "func": "public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,\n\t\t\t\t\t\t\t\t\tVector aggregateVector)\n\t\t\t\tthrows StandardException\n\t{\n\t\tcastOperand = castOperand.bindExpression(\n\t\t\t\t\t\t\t\tfromList, subqueryList,\n\t\t\t\t\t\t\t\taggregateVector);\n\n\t\tif (getTypeServices() == null)   //CHAR or VARCHAR function without specifying target length\n\t\t{\n\t\t\tDataTypeDescriptor opndType = castOperand.getTypeServices();\n\t\t\tint length = -1;\n\t\t\tTypeId srcTypeId = opndType.getTypeId();\n\t\t\tif (opndType != null)\n\t\t\t{\n\t\t\t\tif (srcTypeId.isNumericTypeId())\n\t\t\t\t{\n\t\t\t\t\tlength = opndType.getPrecision() + 1; // 1 for the sign\n\t\t\t\t\tif (opndType.getScale() > 0)\n\t\t\t\t\t\tlength += 1;               // 1 for the decimal .\n\t\t\t\t \n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Derby-1132 : The length for the target type was calculated\n\t\t\t\t * incorrectly while Char & Varchar functions were used. Thus\n\t\t\t\t * adding the check for Char & Varchar and calculating the\n\t\t\t\t * length based on the operand type.\n\t\t\t\t */\n\t\t\t\telse if(srcTypeId.isStringTypeId())\n\t\t\t\t{\n\t\t\t\t\tlength = opndType.getMaximumWidth();\n\t\t\t\n\t\t\t\t\t// Truncate the target type width to the max width of the\n\t\t\t\t\t// data type\n\t\t\t\t\tif (this.targetCharType == Types.CHAR)\n\t\t\t\t\t\tlength = Math.min(length, Limits.DB2_CHAR_MAXWIDTH);\n\t\t\t\t\telse if (this.targetCharType == Types.VARCHAR)\n\t\t\t\t\t\tlength = Math.min(length, Limits.DB2_VARCHAR_MAXWIDTH);\n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tTypeId typeid = opndType.getTypeId();\n\t\t\t\t\tif (length < 0)\n\t\t\t\t\t\tlength = DataTypeUtilities.getColumnDisplaySize(typeid.getJDBCTypeId(),-1);\n\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (length < 0)\n\t\t\t\tlength = 1;  // same default as in parser\n\t\t\tsetType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(targetCharType, length));\n\t\t\t\n\t\t}\n\n\t\t/* \n\t\t** If castOperand is an untyped null, \n\t\t** then we must set the type.\n\t\t*/\n\t\tif (castOperand instanceof UntypedNullConstantNode)\n\t\t{\n\t\t\tcastOperand.setType(getTypeServices());\n\t\t}\n\n\t\tbindCastNodeOnly();\n\t\t\n\t\t/* We can't chop out cast above an untyped null because\n\t\t * the store can't handle it.\n\t\t */\n\t\tif ((castOperand instanceof ConstantNode) &&\n\t\t\t!(castOperand instanceof UntypedNullConstantNode))\n\t\t{\n\t\t\t/* If the castOperand is a typed constant then we do the cast at\n\t\t\t * bind time and return a constant of the correct type.\n\t\t\t * NOTE: This could return an exception, but we're prepared to \n\t\t\t * deal with that. (NumberFormatException, etc.)\n\t\t\t * We only worry about the easy (and useful)\n\t\t\t * converions at bind time.\n\t\t\t * Here's what we support:\n\t\t\t *\t\t\tsource\t\t\t\t\tdestination\n\t\t\t *\t\t\t------\t\t\t\t\t-----------\n\t\t\t *\t\t\tboolean\t\t\t\t\tboolean\n\t\t\t *\t\t\tboolean\t\t\t\t\tchar\n\t\t\t *\t\t\tchar\t\t\t\t\tboolean\n\t\t\t *\t\t\tchar\t\t\t\t\tdate/time/ts\n\t\t\t *\t\t\tchar\t\t\t\t\tnon-decimal numeric\n\t\t\t *\t\t\tdate/time/ts\t\t\tchar\n\t\t\t *\t\t\tnumeric\t\t\t\t\tchar\n\t\t\t *\t\t\tnumeric\t\t\t\t\tnon-decimal numeric\n\t\t\t */\n\t\t\t/* RESOLVE - to be filled in. */\n\t\t\tValueNode retNode = this;\n\t\t\tint\t\t  sourceJDBCTypeId = sourceCTI.getJDBCTypeId();\n\t\t\tint\t\t  destJDBCTypeId = getTypeId().getJDBCTypeId();\n\n\t\t\tswitch (sourceJDBCTypeId)\n\t\t\t{\n\t\t\t\tcase Types.BIT:\n\t\t\t\tcase Types.BOOLEAN:\n\t\t\t\t\t// (BIT is boolean)\n\t\t\t\t\tif (destJDBCTypeId == Types.BIT || destJDBCTypeId == Types.BOOLEAN)\n\t\t\t\t\t{\n\t\t\t\t\t\tretNode = castOperand;\n\t\t\t\t\t}\n\t\t\t\t\telse if (destJDBCTypeId == Types.CHAR)\n\t\t\t\t\t{\n\t\t\t\t\t\tBooleanConstantNode bcn = (BooleanConstantNode) castOperand;\n\t\t\t\t\t\tString booleanString = bcn.getValueAsString();\n\t\t\t\t\t\tretNode = (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\t\tbooleanString,\n\t\t\t\t\t\t\t\t\t\t\tReuseFactory.getInteger(\n                                                    getTypeServices().getMaximumWidth()),\n\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.CHAR:\n\t\t\t\t\t\tretNode = getCastFromCharConstant(destJDBCTypeId);\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.DATE:\n\t\t\t\t\tcase Types.TIME:\n\t\t\t\t\tcase Types.TIMESTAMP:\n\t\t\t\t\t\tif (destJDBCTypeId == Types.CHAR)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tString castValue =  \n\t\t\t\t\t\t\t\t((UserTypeConstantNode) castOperand).\n\t\t\t\t\t\t\t\t\t\t\tgetObjectValue().\n\t\t\t\t\t\t\t\t\t\t\t\ttoString();\n\t\t\t\t\t\t\tretNode = (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tcastValue, \n\t\t\t\t\t\t\t\t\t\t\t\tReuseFactory.getInteger(\n                                                        getTypeServices().getMaximumWidth()),\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.DECIMAL:\n\t\t\t\t\t\t// ignore decimal -> decimal casts for now\n\t\t\t\t\t\tif (destJDBCTypeId == Types.DECIMAL ||\n\t\t\t\t\t\t\tdestJDBCTypeId == Types.NUMERIC)\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t// fall through\n\t\t\t\t\tcase Types.TINYINT:\n\t\t\t\t\tcase Types.SMALLINT:\n\t\t\t\t\tcase Types.INTEGER:\n\t\t\t\t\tcase Types.BIGINT:\n\t\t\t\t\tcase Types.DOUBLE:\n\t\t\t\t\tcase Types.REAL:\n\t\t\t\t\t\tretNode = getCastFromNumericType(\n\t\t\t\t\t\t\t\t\t\t\t((ConstantNode) castOperand).getValue(), \n\t\t\t\t\t\t\t\t\t\t\tdestJDBCTypeId);\n\t\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\t// Return the new constant if the cast was performed\n\t\t\treturn retNode;\n\t\t}\n\n\t\treturn this;\n\t}"}
{"idx": 167, "target": 0, "func": "public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,\n\t\t\t\t\t\t\t\t\tVector aggregateVector)\n\t\t\t\tthrows StandardException\n\t{\n\t\tcastOperand = castOperand.bindExpression(\n\t\t\t\t\t\t\t\tfromList, subqueryList,\n\t\t\t\t\t\t\t\taggregateVector);\n\n\t\tif (getTypeServices() == null)   //CHAR or VARCHAR function without specifying target length\n\t\t{\n\t\t\tDataTypeDescriptor opndType = castOperand.getTypeServices();\n\t\t\tint length = -1;\n\t\t\tTypeId srcTypeId = opndType.getTypeId();\n\t\t\tif (opndType != null)\n\t\t\t{\n\t\t\t\tif (srcTypeId.isNumericTypeId())\n\t\t\t\t{\n\t\t\t\t\tlength = opndType.getPrecision() + 1; // 1 for the sign\n\t\t\t\t\tif (opndType.getScale() > 0)\n\t\t\t\t\t\tlength += 1;               // 1 for the decimal .\n\t\t\t\t \n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Derby-1132 : The length for the target type was calculated\n\t\t\t\t * incorrectly while Char & Varchar functions were used. Thus\n\t\t\t\t * adding the check for Char & Varchar and calculating the\n\t\t\t\t * length based on the operand type.\n\t\t\t\t */\n\t\t\t\telse if(srcTypeId.isStringTypeId())\n\t\t\t\t{\n\t\t\t\t\tlength = opndType.getMaximumWidth();\n\t\t\t\n\t\t\t\t\t// Truncate the target type width to the max width of the\n\t\t\t\t\t// data type\n\t\t\t\t\tif (this.targetCharType == Types.CHAR)\n\t\t\t\t\t\tlength = Math.min(length, Limits.DB2_CHAR_MAXWIDTH);\n\t\t\t\t\telse if (this.targetCharType == Types.VARCHAR)\n\t\t\t\t\t\tlength = Math.min(length, Limits.DB2_VARCHAR_MAXWIDTH);\n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tTypeId typeid = opndType.getTypeId();\n\t\t\t\t\tif (length < 0)\n\t\t\t\t\t\tlength = DataTypeUtilities.getColumnDisplaySize(typeid.getJDBCTypeId(),-1);\n\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (length < 0)\n\t\t\t\tlength = 1;  // same default as in parser\n\t\t\tsetType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(targetCharType, length));\n\t\t\t\n\t\t}\n\n\t\t/* \n\t\t** If castOperand is an untyped null, \n\t\t** then we must set the type.\n\t\t*/\n\t\tif (castOperand instanceof UntypedNullConstantNode)\n\t\t{\n\t\t\tcastOperand.setType(getTypeServices());\n\t\t}\n\n\t\tbindCastNodeOnly();\n\t\t\n\t\t/* We can't chop out cast above an untyped null because\n\t\t * the store can't handle it.\n\t\t */\n\t\tif ((castOperand instanceof ConstantNode) &&\n\t\t\t!(castOperand instanceof UntypedNullConstantNode))\n\t\t{\n\t\t\t/* If the castOperand is a typed constant then we do the cast at\n\t\t\t * bind time and return a constant of the correct type.\n\t\t\t * NOTE: This could return an exception, but we're prepared to \n\t\t\t * deal with that. (NumberFormatException, etc.)\n\t\t\t * We only worry about the easy (and useful)\n\t\t\t * converions at bind time.\n\t\t\t * Here's what we support:\n\t\t\t *\t\t\tsource\t\t\t\t\tdestination\n\t\t\t *\t\t\t------\t\t\t\t\t-----------\n\t\t\t *\t\t\tboolean\t\t\t\t\tboolean\n\t\t\t *\t\t\tboolean\t\t\t\t\tchar\n\t\t\t *\t\t\tchar\t\t\t\t\tboolean\n\t\t\t *\t\t\tchar\t\t\t\t\tdate/time/ts\n\t\t\t *\t\t\tchar\t\t\t\t\tnon-decimal numeric\n\t\t\t *\t\t\tdate/time/ts\t\t\tchar\n\t\t\t *\t\t\tnumeric\t\t\t\t\tchar\n\t\t\t *\t\t\tnumeric\t\t\t\t\tnon-decimal numeric\n\t\t\t */\n\t\t\t/* RESOLVE - to be filled in. */\n\t\t\tValueNode retNode = this;\n\t\t\tint\t\t  sourceJDBCTypeId = sourceCTI.getJDBCTypeId();\n\t\t\tint\t\t  destJDBCTypeId = getTypeId().getJDBCTypeId();\n\n\t\t\tswitch (sourceJDBCTypeId)\n\t\t\t{\n\t\t\t\tcase Types.BIT:\n\t\t\t\tcase Types.BOOLEAN:\n\t\t\t\t\t// (BIT is boolean)\n\t\t\t\t\tif (destJDBCTypeId == Types.BIT || destJDBCTypeId == Types.BOOLEAN)\n\t\t\t\t\t{\n\t\t\t\t\t\tretNode = castOperand;\n\t\t\t\t\t}\n\t\t\t\t\telse if (destJDBCTypeId == Types.CHAR)\n\t\t\t\t\t{\n\t\t\t\t\t\tBooleanConstantNode bcn = (BooleanConstantNode) castOperand;\n\t\t\t\t\t\tString booleanString = bcn.getValueAsString();\n\t\t\t\t\t\tretNode = (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\t\tbooleanString,\n\t\t\t\t\t\t\t\t\t\t\tReuseFactory.getInteger(\n                                                    getTypeServices().getMaximumWidth()),\n\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.CHAR:\n\t\t\t\t\t\tretNode = getCastFromCharConstant(destJDBCTypeId);\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.DATE:\n\t\t\t\t\tcase Types.TIME:\n\t\t\t\t\tcase Types.TIMESTAMP:\n\t\t\t\t\t\tif (destJDBCTypeId == Types.CHAR)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tString castValue =  \n\t\t\t\t\t\t\t\t((UserTypeConstantNode) castOperand).\n\t\t\t\t\t\t\t\t\t\t\tgetObjectValue().\n\t\t\t\t\t\t\t\t\t\t\t\ttoString();\n\t\t\t\t\t\t\tretNode = (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tcastValue, \n\t\t\t\t\t\t\t\t\t\t\t\tReuseFactory.getInteger(\n                                                        getTypeServices().getMaximumWidth()),\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase Types.DECIMAL:\n\t\t\t\t\t\t// ignore decimal -> decimal casts for now\n\t\t\t\t\t\tif (destJDBCTypeId == Types.DECIMAL ||\n\t\t\t\t\t\t\tdestJDBCTypeId == Types.NUMERIC)\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t// fall through\n\t\t\t\t\tcase Types.TINYINT:\n\t\t\t\t\tcase Types.SMALLINT:\n\t\t\t\t\tcase Types.INTEGER:\n\t\t\t\t\tcase Types.BIGINT:\n\t\t\t\t\tcase Types.DOUBLE:\n\t\t\t\t\tcase Types.REAL:\n\t\t\t\t\t\tretNode = getCastFromNumericType(\n\t\t\t\t\t\t\t\t\t\t\t((ConstantNode) castOperand).getValue(), \n\t\t\t\t\t\t\t\t\t\t\tdestJDBCTypeId);\n\t\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\t// Return the new constant if the cast was performed\n\t\t\treturn retNode;\n\t\t}\n\n\t\treturn this;\n\t}"}
{"idx": 168, "target": 0, "func": "private ValueNode getCastFromNumericType(\n\t\t\t\t\t\t\t\t\t  DataValueDescriptor constantValue, \n\t\t\t\t\t\t\t\t\t  int destJDBCTypeId)\n\t\tthrows StandardException\n\t{\n\t\tint nodeType = -1;\n\t\tObject constantObject = null;\n\n\t\tswitch (destJDBCTypeId)\n\t\t{\n\t\t\tcase Types.CHAR:\n\t\t\t\tnodeType = C_NodeTypes.CHAR_CONSTANT_NODE;\n\t\t\t\tconstantObject = constantValue.getString();\n\t\t\t\treturn (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tnodeType,\n\t\t\t\t\t\t\t\t\t\tconstantObject, \n\t\t\t\t\t\t\t\t\t\tReuseFactory.getInteger(\n                                                getTypeServices().getMaximumWidth()),\n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\n\t\t\tcase Types.TINYINT:\n\t\t\t\tnodeType = C_NodeTypes.TINYINT_CONSTANT_NODE;\n\t\t\t\tconstantObject = new Byte(constantValue.getByte());\n\t\t\t\tbreak;\n\n\t\t\tcase Types.SMALLINT:\n\t\t\t\tnodeType = C_NodeTypes.SMALLINT_CONSTANT_NODE;\n\t\t\t\tconstantObject = ReuseFactory.getShort(constantValue.getShort());\n\t\t\t\tbreak;\n\n\t\t\tcase Types.INTEGER:\n\t\t\t\tnodeType = C_NodeTypes.INT_CONSTANT_NODE;\n\t\t\t\tconstantObject = ReuseFactory.getInteger(constantValue.getInt());\n\t\t\t\tbreak;\n\n\t\t\tcase Types.BIGINT:\n\t\t\t\tnodeType = C_NodeTypes.LONGINT_CONSTANT_NODE;\n\t\t\t\tconstantObject = ReuseFactory.getLong(constantValue.getLong());\n\t\t\t\tbreak;\n\n\t\t\tcase Types.REAL:\n\t\t\t\tnodeType = C_NodeTypes.FLOAT_CONSTANT_NODE;\n\t\t\t\tconstantObject = new Float(NumberDataType.normalizeREAL(constantValue.getDouble()));\n\t\t\t\tbreak;\n\n\t\t\tcase Types.DOUBLE:\n\t\t\t\t// no need to normalize here because no constant could be out of range for a double\n\t\t\t\tnodeType = C_NodeTypes.DOUBLE_CONSTANT_NODE;\n\t\t\t\tconstantObject = new Double(constantValue.getDouble());\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (nodeType == -1)\n\t\t\treturn this;\n\n\n\t\treturn (ValueNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tnodeType,\n\t\t\t\t\t\t\t\t\t\tconstantObject, \n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\n\t}"}
{"idx": 169, "target": 0, "func": "public String toString() {\n\t\tString retval = \"\";\n\n\t\tif (SanityManager.DEBUG) {\n\t\t\tretval += \"Direction: \" + myDirection;\n\n\t\t\tfor (int i = 0; i < columns.size(); i++) {\n\t\t\t\tretval += \" Table \" + tables.get(i) +\n\t\t\t\t\t\t\t\", Column \" + columns.get(i);\n\t\t\t}\n\t\t}\n\n\t\treturn retval;\n\t}"}
{"idx": 170, "target": 0, "func": "public ValueNode remapColumnReferencesToExpressions()\n\t\tthrows StandardException\n\t{\n\t\tResultColumn\trc;\n\t\tResultColumn\tsourceRC = source;\n\n\t\t/* Nothing to do if we are not pointing to a redundant RC */\n\t\tif (! source.isRedundant())\n\t\t{\n\t\t\treturn this;\n\t\t}\n\n\t\t/* Find the last redundant RC in the chain.  We\n\t\t * want to clone its expression.\n\t\t */\n\t\tfor (rc = source; rc != null && rc.isRedundant(); )\n\t\t{\n\t\t\t/* Find the matching ResultColumn */\n            ResultColumn nextRC = rc.getExpression().getSourceResultColumn();\n\n\t\t\tif (nextRC != null && nextRC.isRedundant())\n\t\t\t{\n\t\t\t\tsourceRC = nextRC;\n\t\t\t}\n\t\t\trc = nextRC;\n\t\t}\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (sourceRC == null)\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"sourceRC is expected to be non-null for \" +\n\t\t\t\t\tcolumnName);\n\t\t\t}\n\n\t\t\tif ( ! sourceRC.isRedundant())\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"sourceRC is expected to be redundant for \" +\n\t\t\t\t\tcolumnName);\n\t\t\t}\n\t\t}\n\n\t\t/* If last expression is a VCN, then we can't clone it.\n\t\t * Instead, we just reset our source to point to the\n\t\t * source of the VCN, those chopping out the layers.\n\t\t * Otherwise, we return a clone of the underlying expression.\n\t\t */\n\t\tif (sourceRC.getExpression() instanceof VirtualColumnNode)\n\t\t{\n\t\t\tVirtualColumnNode vcn =\n\t\t\t\t(VirtualColumnNode) (sourceRC.getExpression());\n\t\t\tResultSetNode rsn = vcn.getSourceResultSet();\n\t\t\tif (rsn instanceof FromTable)\n\t\t\t{\n\t\t\t\tFromTable ft = (FromTable)rsn;\n\n\t\t\t\t/* It's not enough to just set the table number.  Depending\n\t\t\t\t * on the original query specified and on whether or not\n\t\t\t\t * subquery flattening has occurred, it's possible that\n\t\t\t\t * the expression to which we're remapping has a different\n\t\t\t\t * RCL ordering than the one to which we were mapped before\n\t\t\t\t * we got here.  In that case we also need to update the\n\t\t\t\t * columnNumber to point to the correct column in \"ft\".\n\t\t\t\t * See DERBY-2526 for details.\n                 * See DERBY-3023 and DERBY-4679 for further improvement\n                 * details.\n\t\t\t\t */\n\n                ResultColumnList rcl = ft.getResultColumns();\n\n                ResultColumn ftRC = null;\n\n\n                // Need to save original (tn,cn) in case we have several\n                // flattenings so we can relocate the correct column many\n                // times. After the first flattening, the (tn,cn) pair points\n                // to the top RCL which is going away..\n                if (tableNumberBeforeFlattening == -1) {\n                    tableNumberBeforeFlattening = tableNumber;\n                    columnNumberBeforeFlattening = columnNumber;\n                }\n\n                // Covers references to a table not being flattened out, e.g.\n                // inside a join tree, which can have many columns in the rcl\n                // with the same name, so looking up via column name can give\n                // the wrong column. DERBY-4679.\n                ftRC = rcl.getResultColumn(\n                    tableNumberBeforeFlattening,\n                    columnNumberBeforeFlattening,\n                    columnName);\n\n                if (ftRC == null) {\n                    // The above lookup won't work for references to a base\n                    // column, so fall back on column name, which is unique\n                    // then.\n                    ftRC = rcl.getResultColumn(columnName);\n                }\n\n                if (SanityManager.DEBUG) {\n                    SanityManager.ASSERT(\n                        ftRC != null,\n                        \"Failed to find column '\" + columnName +\n                        \"' in the \" + \"RCL for '\" + ft.getTableName() +\n                        \"'.\");\n                }\n\n                tableNumber = ft.getTableNumber();\n\n\t\t\t\tif (SanityManager.DEBUG) {\n\t\t\t\t\tSanityManager.ASSERT(tableNumber != -1,\n\t\t\t\t\t\t\"tableNumber not expected to be -1\");\n\t\t\t\t}\n\n\t\t\t\t/* Use the virtual column id if the ResultColumn's expression\n\t\t\t\t * is a virtual column (DERBY-3023).\n\t\t\t\t */\n\t\t\t\tcolumnNumber =\n\t\t\t\t\t(ftRC.getExpression() instanceof VirtualColumnNode)\n\t\t\t\t\t\t? ftRC.getVirtualColumnId()\n\t\t\t\t\t\t: ftRC.getColumnPosition();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"rsn expected to be a FromTable, but is a \" + rsn.getClass().getName());\n\t\t\t\t}\n\t\t\t}\n\t\t\tsource = sourceRC.getExpression().getSourceResultColumn();\n\t\t\treturn this;\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn sourceRC.getExpression().getClone();\n\t\t}\n\t}"}
{"idx": 171, "target": 0, "func": "public DataTypeDescriptor[] getParameterTypes()\n\t{\n\t\treturn parameterDescriptors;\n\t}"}
{"idx": 172, "target": 0, "func": "public Object[] getSavedObjects() {\n\t\tif (savedObjects == null) return null;\n\n\t\tObject[] retVal = new Object[savedObjects.size()];\n\t\tsavedObjects.copyInto(retVal);\n\t\tsavedObjects = null; // erase to start over\n\t\treturn retVal;\n\t}"}
{"idx": 173, "target": 0, "func": "public String getUniqueClassName()\n\t{\n\t\t// REMIND: should get a new UUID if we roll over...\n\t\tif (SanityManager.DEBUG)\n\t\t{\n    \t\tSanityManager.ASSERT(nextClassName <= Long.MAX_VALUE);\n    \t}\n\t\treturn classPrefix.concat(Long.toHexString(nextClassName++));\n\t}"}
{"idx": 174, "target": 0, "func": "public List getRequiredPermissionsList()\n\t{\n\t\tint size = 0;\n\t\tif( requiredRoutinePrivileges != null)\n        { size += requiredRoutinePrivileges.size(); }\n\t\tif( requiredUsagePrivileges != null)\n        { size += requiredUsagePrivileges.size(); }\n\t\tif( requiredTablePrivileges != null)\n        { size += requiredTablePrivileges.size(); }\n\t\tif( requiredSchemaPrivileges != null)\n        { size += requiredSchemaPrivileges.size(); }\n\t\tif( requiredColumnPrivileges != null)\n        { size += requiredColumnPrivileges.size(); }\n\t\tif( requiredRolePrivileges != null)\n        { size += requiredRolePrivileges.size(); }\n\t\t\n\t\tArrayList list = new ArrayList( size);\n\t\tif( requiredRoutinePrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredRoutinePrivileges.keySet().iterator(); itr.hasNext();)\n\t\t\t{\n\t\t\t\tUUID routineUUID = (UUID) itr.next();\n\t\t\t\t\n\t\t\t\tlist.add( new StatementRoutinePermission( routineUUID));\n\t\t\t}\n\t\t}\n\t\tif( requiredUsagePrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredUsagePrivileges.keySet().iterator(); itr.hasNext();)\n\t\t\t{\n\t\t\t\tUUID objectID = (UUID) itr.next();\n\t\t\t\t\n\t\t\t\tlist.add( new StatementGenericPermission( objectID, (String) requiredUsagePrivileges.get( objectID ), PermDescriptor.USAGE_PRIV ) );\n\t\t\t}\n\t\t}\n\t\tif( requiredTablePrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredTablePrivileges.values().iterator(); itr.hasNext();)\n\t\t\t{\n\t\t\t\tlist.add( itr.next());\n\t\t\t}\n\t\t}\n\t\tif( requiredSchemaPrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredSchemaPrivileges.values().iterator(); itr.hasNext();)\n\t\t\t{\n\t\t\t\tlist.add( itr.next());\n\t\t\t}\n\t\t}\n\t\tif( requiredColumnPrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredColumnPrivileges.values().iterator(); itr.hasNext();)\n\t\t\t{\n\t\t\t\tlist.add( itr.next());\n\t\t\t}\n\t\t}\n\t\tif( requiredRolePrivileges != null)\n\t\t{\n\t\t\tfor( Iterator itr = requiredRolePrivileges.values().iterator();\n\t\t\t\t itr.hasNext();)\n\t\t\t{\n\t\t\t\tlist.add( itr.next());\n\t\t\t}\n\t\t}\n\t\treturn list;\n\t}"}
{"idx": 175, "target": 1, "func": "public void bindStatement() throws StandardException\n\t{\n\t\tCompilerContext\t\t\tcc = getCompilerContext();\n\t\tSchemaDescriptor\t\tsd;\n\t\tint\t\t\t\t\t\tcolumnCount;\n\n\t\tsd = getSchemaDescriptor();\n\n\t\ttd = getTableDescriptor(tableName);\n\n\t\t//throw an exception if user is attempting to create an index on a temporary table\n\t\tif (td.getTableType() == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)\n\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);\n\t\t}\n\n\t\t//If total number of indexes on the table so far is more than 32767, then we need to throw an exception\n\t\tif (td.getTotalNumberOfIndexes() > Limits.DB2_MAX_INDEXES_ON_TABLE)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_TOO_MANY_INDEXES_ON_TABLE,\n\t\t\t\tString.valueOf(td.getTotalNumberOfIndexes()),\n\t\t\t\ttableName,\n\t\t\t\tString.valueOf(Limits.DB2_MAX_INDEXES_ON_TABLE));\n\t\t}\n\n\t\t/* Validate the column name list */\n\t\tverifyAndGetUniqueNames();\n\n\t\tcolumnCount = columnNames.length;\n\t\tboundColumnIDs = new int[ columnCount ];\n\n\t\t// Verify that the columns exist\n\t\tfor (int i = 0; i < columnCount; i++)\n\t\t{\n\t\t\tColumnDescriptor\t\t\tcolumnDescriptor;\n\n\t\t\tcolumnDescriptor = td.getColumnDescriptor(columnNames[i]);\n\t\t\tif (columnDescriptor == null)\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolumnNames[i],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttableName);\n\t\t\t}\n\t\t\tboundColumnIDs[ i ] = columnDescriptor.getPosition();\n\n\t\t\t// Don't allow a column to be created on a non-orderable type\n\t\t\tif ( ! columnDescriptor.getType().getTypeId().\n\t\t\t\t\t\t\t\t\t\t\t\torderable(getClassFactory()))\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION,\n\t\t\t\t\tcolumnDescriptor.getType().getTypeId().getSQLTypeName());\n\t\t\t}\n\t\t}\n\n\t\t/* Check for number of key columns to be less than 16 to match DB2 */\n\t\tif (columnCount > 16)\n\t\t\tthrow StandardException.newException(SQLState.LANG_TOO_MANY_INDEX_KEY_COLS);\n\n\t\t/* See if the index already exists in this schema.\n\t\t * NOTE: We still need to check at execution time\n\t\t * since the index name is only unique to the schema,\n\t\t * not the table.\n\t\t */\n//  \t\tif (dd.getConglomerateDescriptor(indexName.getTableName(), sd, false) != null)\n//  \t\t{\n//  \t\t\tthrow StandardException.newException(SQLState.LANG_OBJECT_ALREADY_EXISTS_IN_OBJECT,\n//  \t\t\t\t\t\t\t\t\t\t\t\t \"Index\",\n//  \t\t\t\t\t\t\t\t\t\t\t\t indexName.getTableName(),\n//  \t\t\t\t\t\t\t\t\t\t\t\t \"schema\",\n//  \t\t\t\t\t\t\t\t\t\t\t\t sd.getSchemaName());\n//  \t\t}\n\n\t\t/* Statement is dependent on the TableDescriptor */\n\t\tgetCompilerContext().createDependency(td);\n\n\t}"}
{"idx": 176, "target": 1, "func": "public void bindStatement() throws StandardException {\n        CompilerContext cc = getCompilerContext();\n\n        // implicitly create the schema if it does not exist.\n        // this method also compiles permissions checks\n        SchemaDescriptor sd = getSchemaDescriptor();\n\n        // set the default schema name if the user did not explicitly specify a schema\n        if (_sequenceName.getSchemaName() == null) {\n            _sequenceName.setSchemaName(sd.getSchemaName());\n        }\n\n        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {\n            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {\n            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n        } else {\n            // BIGINT\n            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n        }\n\n        if (_minValue.longValue() >= _maxValue.longValue()) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,\n                    _minValue.toString(),\n                    _maxValue.toString());\n        }\n\n        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {\n             throw StandardException.newException(\n                     SQLState.LANG_SEQ_INVALID_START,\n                     _initialValue.toString(),\n                     _minValue.toString(),\n                     _maxValue.toString());\n        }       \n\n        if (_stepValue.longValue() == 0L) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_INCREMENT_ZERO);\n        }\n\n    }"}
{"idx": 177, "target": 0, "func": "public void bindStatement() throws StandardException {\n        CompilerContext cc = getCompilerContext();\n\n        // implicitly create the schema if it does not exist.\n        // this method also compiles permissions checks\n        SchemaDescriptor sd = getSchemaDescriptor();\n\n        // set the default schema name if the user did not explicitly specify a schema\n        if (_sequenceName.getSchemaName() == null) {\n            _sequenceName.setSchemaName(sd.getSchemaName());\n        }\n\n        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {\n            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {\n            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n        } else {\n            // BIGINT\n            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n        }\n\n        if (_minValue.longValue() >= _maxValue.longValue()) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,\n                    _minValue.toString(),\n                    _maxValue.toString());\n        }\n\n        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {\n             throw StandardException.newException(\n                     SQLState.LANG_SEQ_INVALID_START,\n                     _initialValue.toString(),\n                     _minValue.toString(),\n                     _maxValue.toString());\n        }       \n\n        if (_stepValue.longValue() == 0L) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_INCREMENT_ZERO);\n        }\n\n    }"}
{"idx": 178, "target": 0, "func": "public void bindStatement() throws StandardException {\n        CompilerContext cc = getCompilerContext();\n\n        // implicitly create the schema if it does not exist.\n        // this method also compiles permissions checks\n        SchemaDescriptor sd = getSchemaDescriptor();\n\n        // set the default schema name if the user did not explicitly specify a schema\n        if (_sequenceName.getSchemaName() == null) {\n            _sequenceName.setSchemaName(sd.getSchemaName());\n        }\n\n        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {\n            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"SMALLINT\",\n                        Short.MIN_VALUE + \"\",\n                        Short.MAX_VALUE + \"\");\n            }\n        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {\n            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"INTEGER\",\n                        Integer.MIN_VALUE + \"\",\n                        Integer.MAX_VALUE + \"\");\n            }\n        } else {\n            // BIGINT\n            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MINVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {\n                throw StandardException.newException(\n                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,\n                        \"MAXVALUE\",\n                        \"BIGINT\",\n                        Long.MIN_VALUE + \"\",\n                        Long.MAX_VALUE + \"\");\n            }\n        }\n\n        if (_minValue.longValue() >= _maxValue.longValue()) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,\n                    _minValue.toString(),\n                    _maxValue.toString());\n        }\n\n        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {\n             throw StandardException.newException(\n                     SQLState.LANG_SEQ_INVALID_START,\n                     _initialValue.toString(),\n                     _minValue.toString(),\n                     _maxValue.toString());\n        }       \n\n        if (_stepValue.longValue() == 0L) {\n            throw StandardException.newException(\n                    SQLState.LANG_SEQ_INCREMENT_ZERO);\n        }\n\n    }"}
{"idx": 179, "target": 0, "func": "public void bindStatement() throws StandardException\n\t{\n\t\tDataDictionary\tdataDictionary = getDataDictionary();\n\t\tint numPrimaryKeys = 0;\n\t\tint numCheckConstraints = 0;\n\t\tint numReferenceConstraints = 0;\n\t\tint numUniqueConstraints = 0;\n        int numGenerationClauses = 0;\n\n        SchemaDescriptor sd = getSchemaDescriptor\n            ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE, true);\n\n\t\tif (queryExpression != null)\n\t\t{\n\t\t\tFromList fromList = (FromList) getNodeFactory().getNode(\n\t\t\t\t\tC_NodeTypes.FROM_LIST,\n\t\t\t\t\tgetNodeFactory().doJoinOrderOptimization(),\n\t\t\t\t\tgetContextManager());\n\t\t\t\n\t\t\tCompilerContext cc = getCompilerContext();\n\t\t\tProviderList prevAPL = cc.getCurrentAuxiliaryProviderList();\n\t\t\tProviderList apl = new ProviderList();\n\t\t\t\n\t\t\ttry\n\t\t\t{\n\t\t\t\tcc.setCurrentAuxiliaryProviderList(apl);\n\t\t\t\tcc.pushCurrentPrivType(Authorizer.SELECT_PRIV);\n\t\t\t\t\n\t\t\t\t/* Bind the tables in the queryExpression */\n\t\t\t\tqueryExpression =\n\t\t\t\t\tqueryExpression.bindNonVTITables(dataDictionary, fromList);\n\t\t\t\tqueryExpression = queryExpression.bindVTITables(fromList);\n\t\t\t\t\n\t\t\t\t/* Bind the expressions under the resultSet */\n\t\t\t\tqueryExpression.bindExpressions(fromList);\n\t\t\t\t\n\t\t\t\t/* Bind the query expression */\n\t\t\t\tqueryExpression.bindResultColumns(fromList);\n\t\t\t\t\n\t\t\t\t/* Reject any untyped nulls in the RCL */\n\t\t\t\t/* e.g. CREATE TABLE t1 (x) AS VALUES NULL WITH NO DATA */\n\t\t\t\tqueryExpression.bindUntypedNullsToResultColumns(null);\n\t\t\t}\n\t\t\tfinally\n\t\t\t{\n\t\t\t\tcc.popCurrentPrivType();\n\t\t\t\tcc.setCurrentAuxiliaryProviderList(prevAPL);\n\t\t\t}\n\t\t\t\n\t\t\t/* If there is an RCL for the table definition then copy the\n\t\t\t * names to the queryExpression's RCL after verifying that\n\t\t\t * they both have the same size.\n\t\t\t */\n\t\t\tResultColumnList qeRCL = queryExpression.getResultColumns();\n\t\t\t\n\t\t\tif (resultColumns != null)\n\t\t\t{\n\t\t\t\tif (resultColumns.size() != qeRCL.visibleSize())\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\tSQLState.LANG_TABLE_DEFINITION_R_C_L_MISMATCH,\n\t\t\t\t\t\t\tgetFullName());\n\t\t\t\t}\n\t\t\t\tqeRCL.copyResultColumnNames(resultColumns);\n\t\t\t}\n\t\t\t\n\t\t\tint schemaCollationType = sd.getCollationType();\n\t    \n\t\t\t/* Create table element list from columns in query expression */\n\t\t\ttableElementList = new TableElementList();\n\t\t\t\n\t\t\tfor (int index = 0; index < qeRCL.size(); index++)\n\t\t\t{\n\t\t\t\tResultColumn rc = (ResultColumn) qeRCL.elementAt(index);\n\t\t\t\tif (rc.isGenerated()) \n\t\t\t\t{\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* Raise error if column name is system generated. */\n\t\t\t\tif (rc.isNameGenerated())\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\tSQLState.LANG_TABLE_REQUIRES_COLUMN_NAMES);\n\t\t\t\t}\n\n\t\t\t\tDataTypeDescriptor dtd = rc.getExpression().getTypeServices();\n\t\t\t\tif ((dtd != null) && !dtd.isUserCreatableType())\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\tSQLState.LANG_INVALID_COLUMN_TYPE_CREATE_TABLE,\n\t\t\t\t\t\t\tdtd.getFullSQLTypeName(),\n\t\t\t\t\t\t\trc.getName());\n\t\t\t\t}\n\t\t\t\t//DERBY-2879  CREATE TABLE AS <subquery> does not maintain the \n\t\t\t\t//collation for character types. \n\t\t\t\t//eg for a territory based collation database\n\t\t\t\t//create table t as select tablename from sys.systables with no data;\n\t\t\t\t//Derby at this point does not support for a table's character \n\t\t\t\t//columns to have a collation different from it's schema's\n\t\t\t\t//collation. Which means that in a territory based database, \n\t\t\t\t//the query above will cause table t's character columns to\n\t\t\t\t//have collation of UCS_BASIC but the containing schema of t\n\t\t\t\t//has collation of territory based. This is not supported and\n\t\t\t\t//hence we will throw an exception below for the query above in\n\t\t\t\t//a territory based database. \n\t\t\t\tif (dtd.getTypeId().isStringTypeId() && \n\t\t\t\t\t\tdtd.getCollationType() != schemaCollationType)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\tSQLState.LANG_CAN_NOT_CREATE_TABLE,\n\t\t\t\t\t\t\tdtd.getCollationName(),\n\t\t\t\t\t\t\tDataTypeDescriptor.getCollationName(schemaCollationType));\n\t\t\t\t}\n\n\t\t\t\tColumnDefinitionNode column = (ColumnDefinitionNode) getNodeFactory().getNode\n                    ( C_NodeTypes.COLUMN_DEFINITION_NODE, rc.getName(), null, rc.getType(), null, getContextManager() );\n\t\t\t\ttableElementList.addTableElement(column);\n\t\t\t}\n\t\t} else {\n\t\t\t//Set the collation type and collation derivation of all the \n\t\t\t//character type columns. Their collation type will be same as the \n\t\t\t//collation of the schema they belong to. Their collation \n\t\t\t//derivation will be \"implicit\". \n\t\t\t//Earlier we did this in makeConstantAction but that is little too \n\t\t\t//late (DERBY-2955)\n\t\t\t//eg \n\t\t\t//CREATE TABLE STAFF9 (EMPNAME CHAR(20),\n\t\t\t//  CONSTRAINT STAFF9_EMPNAME CHECK (EMPNAME NOT LIKE 'T%'))\n\t\t\t//For the query above, when run in a territory based db, we need \n\t\t\t//to have the correct collation set in bind phase of create table \n\t\t\t//so that when LIKE is handled in LikeEscapeOperatorNode, we have \n\t\t\t//the correct collation set for EMPNAME otherwise it will throw an \n\t\t\t//exception for 'T%' having collation of territory based and \n\t\t\t//EMPNAME having the default collation of UCS_BASIC\n\t\t\ttableElementList.setCollationTypesOnCharacterStringColumns(\n\t\t\t\tgetSchemaDescriptor(\n\t\t\t\t\ttableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE,\n\t\t\t\t\ttrue));\n\t\t}\n\n\t\ttableElementList.validate(this, dataDictionary, (TableDescriptor) null);\n\n\t\t/* Only 1012 columns allowed per table */\n\t\tif (tableElementList.countNumberOfColumns() > Limits.DB2_MAX_COLUMNS_IN_TABLE)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_TOO_MANY_COLUMNS_IN_TABLE_OR_VIEW,\n\t\t\t\tString.valueOf(tableElementList.countNumberOfColumns()),\n\t\t\t\tgetRelativeName(),\n\t\t\t\tString.valueOf(Limits.DB2_MAX_COLUMNS_IN_TABLE));\n\t\t}\n\n\t\tnumPrimaryKeys = tableElementList.countConstraints(\n\t\t\t\t\t\t\t\tDataDictionary.PRIMARYKEY_CONSTRAINT);\n\n\t\t/* Only 1 primary key allowed per table */\n\t\tif (numPrimaryKeys > 1)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_TOO_MANY_PRIMARY_KEY_CONSTRAINTS, getRelativeName());\n\t\t}\n\n\t\t/* Check the validity of all check constraints */\n\t\tnumCheckConstraints = tableElementList.countConstraints(\n\t\t\t\t\t\t\t\t\tDataDictionary.CHECK_CONSTRAINT);\n\n\t\tnumReferenceConstraints = tableElementList.countConstraints(\n\t\t\t\t\t\t\t\t\tDataDictionary.FOREIGNKEY_CONSTRAINT);\n\n\t\tnumUniqueConstraints = tableElementList.countConstraints(\n\t\t\t\t\t\t\t\t\tDataDictionary.UNIQUE_CONSTRAINT);\n\n        numGenerationClauses = tableElementList.countGenerationClauses();\n\n\t\t//temp tables can't have primary key or check or foreign key or unique constraints defined on them\n\t\tif ((tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE) &&\n\t\t\t(numPrimaryKeys > 0 || numCheckConstraints > 0 || numReferenceConstraints > 0 || numUniqueConstraints > 0))\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);\n\n\t\t//each of these constraints have a backing index in the back. We need to make sure that a table never has more\n\t\t//more than 32767 indexes on it and that is why this check.\n\t\tif ((numPrimaryKeys + numReferenceConstraints + numUniqueConstraints) > Limits.DB2_MAX_INDEXES_ON_TABLE)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_TOO_MANY_INDEXES_ON_TABLE, \n\t\t\t\tString.valueOf(numPrimaryKeys + numReferenceConstraints + numUniqueConstraints),\n\t\t\t\tgetRelativeName(),\n\t\t\t\tString.valueOf(Limits.DB2_MAX_INDEXES_ON_TABLE));\n\t\t}\n\n\t\tif ( (numCheckConstraints > 0) || (numGenerationClauses > 0) || (numReferenceConstraints > 0) )\n\t\t{\n\t\t\t/* In order to check the validity of the check constraints and\n\t\t\t * generation clauses\n\t\t\t * we must goober up a FromList containing a single table,\n\t\t\t * the table being created, with an RCL containing the\n\t\t\t * new columns and their types.  This will allow us to\n\t\t\t * bind the constraint definition trees against that\n\t\t\t * FromList.  When doing this, we verify that there are\n\t\t\t * no nodes which can return non-deterministic results.\n\t\t\t */\n\t\t\tFromList fromList = makeFromList( null, tableElementList, true );\n            FormatableBitSet    generatedColumns = new FormatableBitSet();\n\n\t\t\t/* Now that we've finally goobered stuff up, bind and validate\n\t\t\t * the check constraints and generation clauses.\n\t\t\t */\n\t\t\tif  (numGenerationClauses > 0) { tableElementList.bindAndValidateGenerationClauses( sd, fromList, generatedColumns, null ); }\n\t\t\tif  (numCheckConstraints > 0) { tableElementList.bindAndValidateCheckConstraints(fromList); }\n            if ( numReferenceConstraints > 0) { tableElementList.validateForeignKeysOnGenerationClauses( fromList, generatedColumns ); }\n\t\t}\n\n        if ( numPrimaryKeys > 0 ) { tableElementList.validatePrimaryKeyNullability(); }\n\t}"}
{"idx": 180, "target": 0, "func": "private int[] justTheRequiredColumns(int[] columnsArrary) {\n\t\tint countOfColsRefedInArray = 0;\n\t\tint numberOfColsInTriggerTable = triggerTableDescriptor.getNumberOfColumns();\n\n\t\t//Count number of non -1 entries\n\t\tfor (int i=0; i < numberOfColsInTriggerTable; i++) {\n\t\t\tif (columnsArrary[i] != -1)\n\t\t\t\tcountOfColsRefedInArray++;\n\t\t}\n\n\t\tif (countOfColsRefedInArray > 0){\n\t\t\tint[] tempArrayOfNeededColumns = new int[countOfColsRefedInArray];\n\t\t\tint j=0;\n\t\t\tfor (int i=0; i < numberOfColsInTriggerTable; i++) {\n\t\t\t\tif (columnsArrary[i] != -1)\n\t\t\t\t\ttempArrayOfNeededColumns[j++] = columnsArrary[i];\n\t\t\t}\n\t\t\treturn tempArrayOfNeededColumns;\n\t\t} else\n\t\t\treturn null;\n\t}"}
{"idx": 181, "target": 1, "func": "static void\tbindRowScopedExpression\n\t(\n\t\tNodeFactory\t\t\tnodeFactory,\n        ContextManager    contextManager,\n\t\tTableDescriptor\t\ttargetTableDescriptor,\n\t\tResultColumnList\tsourceRCL,\n\t\tValueNode\t\t\texpression\n    )\n\t\tthrows StandardException\n\t{\n\n\t\tTableName\ttargetTableName = makeTableName\n            (nodeFactory, contextManager, targetTableDescriptor.getSchemaName(), targetTableDescriptor.getName());\n\n\t\t/* We now have the expression as a query tree.  Now, we prepare\n\t\t * to bind that query tree to the source's RCL.  That way, the\n\t\t * generated code for the expression will be evaluated against the\n\t\t * source row to be inserted into the target table or\n\t\t * against the after portion of the source row for the update\n\t\t * into the target table.\n\t\t *\t\to  Goober up a new FromList which has a single table,\n\t\t *\t\t   a goobered up FromBaseTable for the target table\n\t\t *\t\t   which has the source's RCL as it RCL.\n\t\t *\t\t   (This allows the ColumnReferences in the expression\n\t\t *\t\t   tree to be bound to the right RCs.)\n\t\t *\n\t \t * Note that in some circumstances we may not actually verify\n\t\t * the expression against the source RCL but against a temp\n\t\t * row source used for deferred processing because of a trigger.\n\t\t * In this case, the caller of bindConstraints (UpdateNode)\n\t\t * has chosen to pass in the correct RCL to bind against.\n\t\t */\n\t\tFromList fakeFromList =\n\t\t\t(FromList) nodeFactory.getNode(\n\t\t\t\t\t\t\tC_NodeTypes.FROM_LIST,\n\t\t\t\t\t\t\tnodeFactory.doJoinOrderOptimization(),\n\t\t\t\t\t\t\tcontextManager);\n\t\tFromBaseTable table = (FromBaseTable)\n\t\t\tnodeFactory.getNode(\n\t\t\t\tC_NodeTypes.FROM_BASE_TABLE,\n\t\t\t\ttargetTableName,\n\t\t\t\tnull,\n\t\t\t\tsourceRCL,\n\t\t\t\tnull,\n\t\t\t\tcontextManager);\n\t\ttable.setTableNumber(0);\n\t\tfakeFromList.addFromTable(table);\n\n\t\t// Now we can do the bind.\n\t\texpression = expression.bindExpression(\n\t\t\t\t\t\t\t\t\t\tfakeFromList,\n\t\t\t\t\t\t\t\t\t\t(SubqueryList) null,\n\t\t\t\t\t\t\t\t\t\t(Vector) null);\n\t}"}
{"idx": 182, "target": 1, "func": "public\tValueNode\tparseCheckConstraint\n\t(\n\t\tString\t\t\t\tcheckConstraintText,\n\t\tTableDescriptor\t\ttd\n    )\n\t\tthrows StandardException\n\t{\n\t\tParser\t\t\t\t\t\tp;\n\t\tValueNode\t\t\t\t\tcheckTree;\n\t\tLanguageConnectionContext\tlcc = getLanguageConnectionContext();\n\t\tCompilerContext \t\t\tcompilerContext = getCompilerContext();\n\n\t\t/* Get a Statement to pass to the parser */\n\n\t\t/* We're all set up to parse. We have to build a compile SQL statement\n\t\t * before we can parse - we just have a WHERE clause right now.\n\t\t * So, we goober up a SELECT * FROM table WHERE checkDefs.\n\t\t */\n\t\tString select = \"SELECT * FROM \" +\n\t\t\t            td.getQualifiedName() +\n\t\t\t            \" WHERE \" +\n\t\t\t            checkConstraintText;\n\t\t\n\t\t/*\n\t\t** Get a new compiler context, so the parsing of the select statement\n\t\t** doesn't mess up anything in the current context (it could clobber\n\t\t** the ParameterValueSet, for example).\n\t\t*/\n\t\tCompilerContext newCC = lcc.pushCompilerContext();\n\n\t\tp = newCC.getParser();\n\t\t\t\t\n\t\t/* Finally, we can call the parser */\n\t\t// Since this is always nested inside another SQL statement, so topLevel flag\n\t\t// should be false\n\t\tVisitable qt = p.parseStatement(select);\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (! (qt instanceof CursorNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"qt expected to be instanceof CursorNode, not \" +\n\t\t\t\t\tqt.getClass().getName());\n\t\t\t}\n\t\t\tCursorNode cn = (CursorNode) qt;\n\t\t\tif (! (cn.getResultSetNode() instanceof SelectNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"cn.getResultSetNode() expected to be instanceof SelectNode, not \" +\n\t\t\t\t\tcn.getResultSetNode().getClass().getName());\n\t\t\t}\n\t\t}\n\n\t\tcheckTree = ((SelectNode) ((CursorNode) qt).getResultSetNode()).getWhereClause();\n\n\t\tlcc.popCompilerContext(newCC);\n\n\t\treturn\tcheckTree;\n\t}"}
{"idx": 183, "target": 1, "func": "public\tValueNode\tparseGenerationClause\n\t(\n     String\t\t\t\tclauseText,\n     TableDescriptor    td\n    )\n\t\tthrows StandardException\n\t{\n\t\tParser\t\t\t\t\t\tp;\n\t\tValueNode\t\t\t\t\tclauseTree;\n\t\tLanguageConnectionContext\tlcc = getLanguageConnectionContext();\n\t\tCompilerContext \t\t\tcompilerContext = getCompilerContext();\n\n\t\t/* Get a Statement to pass to the parser */\n\n\t\t/* We're all set up to parse. We have to build a compilable SQL statement\n\t\t * before we can parse -  So, we goober up a VALUES defaultText.\n\t\t */\n\t\tString select = \"SELECT \" + clauseText + \" FROM \" + td.getQualifiedName();\n\t\t\n\t\t/*\n\t\t** Get a new compiler context, so the parsing of the select statement\n\t\t** doesn't mess up anything in the current context (it could clobber\n\t\t** the ParameterValueSet, for example).\n\t\t*/\n\t\tCompilerContext newCC = lcc.pushCompilerContext();\n\n\t\tp = newCC.getParser();\n\t\t\t\t\n\t\t/* Finally, we can call the parser */\n\t\t// Since this is always nested inside another SQL statement, so topLevel flag\n\t\t// should be false\n\t\tVisitable qt = p.parseStatement(select);\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (! (qt instanceof CursorNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"qt expected to be instanceof CursorNode, not \" +\n\t\t\t\t\tqt.getClass().getName());\n\t\t\t}\n\t\t\tCursorNode cn = (CursorNode) qt;\n\t\t\tif (! (cn.getResultSetNode() instanceof SelectNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"cn.getResultSetNode() expected to be instanceof SelectNode, not \" +\n\t\t\t\t\tcn.getResultSetNode().getClass().getName());\n\t\t\t}\n\t\t}\n\n\t\tclauseTree = ((ResultColumn) \n\t\t\t\t\t\t\t((CursorNode) qt).getResultSetNode().getResultColumns().elementAt(0)).\n\t\t\t\t\t\t\t\t\tgetExpression();\n\n\t\tlcc.popCompilerContext(newCC);\n\n\t\treturn\tclauseTree;\n\t}"}
{"idx": 184, "target": 0, "func": "public static int[] getReadColMap(int column_map_length,FormatableBitSet readColsBitSet)\n\t{\n\t\tif (readColsBitSet == null) return null;\n\n        int partial_col_cnt = 0;\n        int column_map[] = new int[column_map_length];\n\t\tint readColsBitSetSize = readColsBitSet.size();\n\n        for (int base_index = 0; base_index < column_map.length; base_index++)\n        {\n\t\t\tif (readColsBitSetSize > base_index && readColsBitSet.get(base_index+1))\n\t\t\t\tcolumn_map[base_index] = partial_col_cnt++;\n\t\t\telse\n\t\t\t\t// this column map offset entry should never be referenced.\n\t\t\t\tcolumn_map[base_index] = -1;\n\t\t}\n\n        return(column_map);\n\t}"}
{"idx": 185, "target": 0, "func": "private StatementNode getEmptyDeleteNode(String schemaName, String targetTableName)\n        throws StandardException\n    {\n\n        ValueNode whereClause = null;\n\n        TableName tableName = new TableName();\n        tableName.init(schemaName , targetTableName);\n\n        NodeFactory nodeFactory = getNodeFactory();\n        FromList   fromList = (FromList) nodeFactory.getNode(C_NodeTypes.FROM_LIST, getContextManager());\n        FromTable fromTable = (FromTable) nodeFactory.getNode(\n                                                    C_NodeTypes.FROM_BASE_TABLE,\n                                                    tableName,\n                                                    null,\n                                                    ReuseFactory.getInteger(FromBaseTable.DELETE),\n                                                    null,\n                                                    getContextManager());\n\n\t\t//we would like to use references index & table scan instead of \n\t\t//what optimizer says for the dependent table scan.\n\t\tProperties targetProperties = new FormatableProperties();\n\t\ttargetProperties.put(\"index\", \"null\");\n\t\t((FromBaseTable) fromTable).setTableProperties(targetProperties);\n\n        fromList.addFromTable(fromTable);\n        SelectNode resultSet = (SelectNode) nodeFactory.getNode(\n                                                     C_NodeTypes.SELECT_NODE,\n                                                     null,\n                                                     null,   /* AGGREGATE list */\n                                                     fromList, /* FROM list */\n                                                     whereClause, /* WHERE clause */\n                                                     null, /* GROUP BY list */\n                                                     null, /* having clause */\n\t\t\t\t\t\t\t\t\t\t\t\t\t null, /* windows */\n\t\t\t\t\t\t\t\t\t\t\t\t\t getContextManager());\n\n        return (StatementNode) nodeFactory.getNode(\n                                                    C_NodeTypes.DELETE_NODE,\n                                                    tableName,\n                                                    resultSet,\n                                                    getContextManager());\n\n    }"}
{"idx": 186, "target": 0, "func": "private StatementNode getEmptyUpdateNode(String schemaName, \n\t\t\t\t\t\t\t\t\t\t\t String targetTableName,\n\t\t\t\t\t\t\t\t\t\t\t ColumnDescriptorList cdl)\n        throws StandardException\n    {\n\n        ValueNode whereClause = null;\n\n        TableName tableName = new TableName();\n        tableName.init(schemaName , targetTableName);\n\n        NodeFactory nodeFactory = getNodeFactory();\n        FromList   fromList = (FromList) nodeFactory.getNode(C_NodeTypes.FROM_LIST, getContextManager());\n        FromTable fromTable = (FromTable) nodeFactory.getNode(\n                                                    C_NodeTypes.FROM_BASE_TABLE,\n                                                    tableName,\n                                                    null,\n                                                    ReuseFactory.getInteger(FromBaseTable.DELETE),\n                                                    null,\n                                                    getContextManager());\n\n\n\t\t//we would like to use references index & table scan instead of \n\t\t//what optimizer says for the dependent table scan.\n\t\tProperties targetProperties = new FormatableProperties();\n\t\ttargetProperties.put(\"index\", \"null\");\n\t\t((FromBaseTable) fromTable).setTableProperties(targetProperties);\n\n        fromList.addFromTable(fromTable);\n\n        SelectNode resultSet = (SelectNode) nodeFactory.getNode(\n                                                     C_NodeTypes.SELECT_NODE,\n                                                     getSetClause(tableName, cdl),\n                                                     null,   /* AGGREGATE list */\n                                                     fromList, /* FROM list */\n                                                     whereClause, /* WHERE clause */\n                                                     null, /* GROUP BY list */\n\t\t\t\t\t\t\t\t\t\t\t\t\t null, /* having clause */\n\t\t\t\t\t\t\t\t\t\t\t\t\t null, /* windows */\n                                                     getContextManager());\n\n        return (StatementNode) nodeFactory.getNode(\n                                                    C_NodeTypes.UPDATE_NODE,\n                                                    tableName,\n                                                    resultSet,\n                                                    getContextManager());\n\n    }"}
{"idx": 187, "target": 0, "func": "public void generate(ActivationClassBuilder acb,\n\t\t\t\t\t\t\t\tMethodBuilder mb)\n\t\t\t\t\t\t\tthrows StandardException\n\t{\n\n\t\t// If the DML is on the temporary table, generate the code to\n\t\t// mark temporary table as modified in the current UOW. After\n\t\t// DERBY-827 this must be done in execute() since\n\t\t// createResultSet() will only be called once.\n\t\tgenerateCodeForTemporaryTable(acb);\n\n\t\t/* generate the parameters */\n\t\tif(!isDependentTable)\n\t\t\tgenerateParameterValueSet(acb);\n\n\t\tacb.pushGetResultSetFactoryExpression(mb); \n\t\tacb.newRowLocationScanResultSetName();\n\t\tresultSet.generate(acb, mb); // arg 1\n\n\t\tString resultSetGetter;\n\t\tint argCount;\n\t\tString parentResultSetId;\n\n\t\t// Base table\n\t\tif (targetTableDescriptor != null)\n\t\t{\n\t\t\t/* Create the declaration for the scan ResultSet which generates the\n\t\t\t * RowLocations to be deleted.\n\t \t\t * Note that the field cannot be static because there\n\t\t\t * can be multiple activations of the same activation class,\n\t\t\t * and they can't share this field.  Only exprN fields can\n\t\t\t * be shared (or, more generally, read-only fields).\n\t\t\t * RESOLVE - Need to deal with the type of the field.\n\t\t\t */\n\n\t\t\tacb.newFieldDeclaration(Modifier.PRIVATE, \n\t\t\t\t\t\t\t\t\tClassName.CursorResultSet, \n\t\t\t\t\t\t\t\t\tacb.getRowLocationScanResultSetName());\n\n\t\t\tif(cascadeDelete || isDependentTable)\n\t\t\t{\n\t\t\t\tresultSetGetter = \"getDeleteCascadeResultSet\";\n\t\t\t\targCount = 4;\n\t\t\t}\t\t\n\t\t\telse\n\t\t\t{\n\t\t\t\tresultSetGetter = \"getDeleteResultSet\";\n\t\t\t\targCount = 1;\n\t\t\t}\n\t\t\t\n\t\t} else {\n\t\t\targCount = 1;\n\t\t\tresultSetGetter = \"getDeleteVTIResultSet\";\n\t\t}\n\n\t\tif(isDependentTable)\n\t\t{\n\t\t\tmb.push(acb.addItem(makeConstantAction()));\n\t\t\n\t\t}else\n\t\t{\n\t\t\tif(cascadeDelete)\n\t\t\t{\n\t\t\t\tmb.push(-1); //root table.\n\t\t\t}\n\t\t}\t\t\n\n\t\tString\t\tresultSetArrayType = ClassName.ResultSet + \"[]\";\n\t\tif(cascadeDelete)\n\t\t{\n\t\t\tparentResultSetId = targetTableDescriptor.getSchemaName() +\n\t\t\t                       \".\" + targetTableDescriptor.getName();\n\t\t\t// Generate the code to build the array\n\t\t\tLocalField arrayField =\n\t\t\t\tacb.newFieldDeclaration(Modifier.PRIVATE, resultSetArrayType);\n\t\t\tmb.pushNewArray(ClassName.ResultSet, dependentNodes.length);  // new ResultSet[size]\n\t\t\tmb.setField(arrayField);\n\t\t\tfor(int index=0 ; index <  dependentNodes.length ; index++)\n\t\t\t{\n\n\t\t\t\tdependentNodes[index].setRefActionInfo(fkIndexConglomNumbers[index],\n\t\t\t\t\t\t\t\t\t\t\t\t\t   fkColArrays[index],\n\t\t\t\t\t\t\t\t\t\t\t\t\t   parentResultSetId,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   true);\n\t\t\t\tmb.getField(arrayField); // first arg (resultset array reference)\n\t\t\t\t/*beetle:5360 : if too many statements are added  to a  method, \n\t\t\t\t *size of method can hit  65k limit, which will\n\t\t\t\t *lead to the class format errors at load time.\n\t\t\t\t *To avoid this problem, when number of statements added \n\t\t\t\t *to a method is > 2048, remaing statements are added to  a new function\n\t\t\t\t *and called from the function which created the function.\n\t\t\t\t *See Beetle 5135 or 4293 for further details on this type of problem.\n\t\t\t\t*/\n\t\t\t\tif(mb.statementNumHitLimit(10))\n\t\t\t\t{\n\t\t\t\t\tMethodBuilder dmb = acb.newGeneratedFun(ClassName.ResultSet, Modifier.PRIVATE);\n\t\t\t\t\tdependentNodes[index].generate(acb,dmb); //generates the resultset expression\n\t\t\t\t\tdmb.methodReturn();\n\t\t\t\t\tdmb.complete();\n\t\t\t\t\t/* Generate the call to the new method */\n\t\t\t\t\tmb.pushThis(); \n\t\t\t\t\t//second arg will be generated by this call\n\t\t\t\t\tmb.callMethod(VMOpcode.INVOKEVIRTUAL, (String) null, dmb.getName(), ClassName.ResultSet, 0);\n\t\t\t\t}else\n\t\t\t\t{\n\t\t\t\t\tdependentNodes[index].generate(acb,mb); //generates the resultset expression\n\t\t\t\t}\n\n\t\t\t\tmb.setArrayElement(index);\n\t\t\t}\t\n\t\t\tmb.getField(arrayField); // fourth argument - array reference\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif(isDependentTable)\n\t\t\t{\n\t\t\t\tmb.pushNull(resultSetArrayType); //No dependent tables for this table\n\t\t\t}\n\t\t}\n\n\n\t\tif(cascadeDelete || isDependentTable)\n\t\t{\n\t\t\tparentResultSetId = targetTableDescriptor.getSchemaName() +\n\t\t\t                       \".\" + targetTableDescriptor.getName();\n\t\t\tmb.push(parentResultSetId);\n\n\t\t}\n\t\tmb.callMethod(VMOpcode.INVOKEINTERFACE, (String) null, resultSetGetter, ClassName.ResultSet, argCount);\n\n\n\t\tif(!isDependentTable && cascadeDelete)\n\t\t{\n\t\t\tint numResultSets = acb.getRowCount();\n\t\t\tif(numResultSets > 0)\n\t\t\t{\n\t\t\t\t//generate activation.raParentResultSets = new NoPutResultSet[size]\n\t\t\t\tMethodBuilder constructor = acb.getConstructor();\n\t\t\t\tconstructor.pushThis();\n\t\t\t\tconstructor.pushNewArray(ClassName.CursorResultSet, numResultSets);\n\t\t\t\tconstructor.putField(ClassName.BaseActivation,\n\t\t\t\t\t\t\t\t\t \"raParentResultSets\",\n\t\t\t\t\t\t\t\t\t ClassName.CursorResultSet + \"[]\");\n\t\t\t\tconstructor.endStatement();\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 188, "target": 0, "func": "public void optimizeStatement() throws StandardException\n\t{\n\t\tif(cascadeDelete)\n\t\t{\n\t\t\tfor(int index=0 ; index < dependentNodes.length ; index++)\n\t\t\t{\n\t\t\t\tdependentNodes[index].optimizeStatement();\n\t\t\t}\n\t\t}\n\n\t\tsuper.optimizeStatement();\n\t}"}
{"idx": 189, "target": 1, "func": "public CostEstimate optimizeIt(Optimizer optimizer,\n\t\t\t\t\t\t\t\t\tOptimizablePredicateList predList,\n\t\t\t\t\t\t\t\t\tCostEstimate outerCost,\n\t\t\t\t\t\t\t\t\tRowOrdering rowOrdering)\n\t\t\tthrows StandardException\n\t{\n\t\tCostEstimate childCost =\n\t\t\t((Optimizable) childResult).optimizeIt(optimizer,\n\t\t\t\t\t\t\t\t\tpredList,\n\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\trowOrdering);\n\n\t\treturn super.optimizeIt(optimizer, predList, outerCost, rowOrdering);\n\t}"}
{"idx": 190, "target": 0, "func": "private static String aliasTypeName( char actualType)\n\t{\n\t\tString\ttypeName = null;\n\n\t\tswitch ( actualType )\n\t\t{\n\t\t\tcase AliasInfo.ALIAS_TYPE_AGGREGATE_AS_CHAR:\n\t\t\t\ttypeName = \"DERBY AGGREGATE\";\n\t\t\t\tbreak;\n\t\t\tcase AliasInfo.ALIAS_TYPE_PROCEDURE_AS_CHAR:\n\t\t\t\ttypeName = \"PROCEDURE\";\n\t\t\t\tbreak;\n\t\t\tcase AliasInfo.ALIAS_TYPE_FUNCTION_AS_CHAR:\n\t\t\t\ttypeName = \"FUNCTION\";\n\t\t\t\tbreak;\n\t\t\tcase AliasInfo.ALIAS_TYPE_SYNONYM_AS_CHAR:\n\t\t\t\ttypeName = \"SYNONYM\";\n\t\t\t\tbreak;\n\t\t\tcase AliasInfo.ALIAS_TYPE_UDT_AS_CHAR:\n\t\t\t\ttypeName = \"TYPE\";\n\t\t\t\tbreak;\n\t\t}\n\t\treturn typeName;\n\t}"}
{"idx": 191, "target": 1, "func": "public boolean isOneRowResultSet()\tthrows StandardException\n\t{\n\t\t// EXISTS FBT will only return a single row\n\t\tif (existsBaseTable)\n\t\t{\n\t\t\treturn true;\n\t\t}\n\n\t\t/* For hash join, we need to consider both the qualification\n\t\t * and hash join predicates and we consider them against all\n\t\t * conglomerates since we are looking for any uniqueness\n\t\t * condition that holds on the columns in the hash table, \n\t\t * otherwise we just consider the predicates in the \n\t\t * restriction list and the conglomerate being scanned.\n\n\t\t */\n\t\tAccessPath ap = getTrulyTheBestAccessPath();\n\t\tJoinStrategy trulyTheBestJoinStrategy = ap.getJoinStrategy();\n\t\tPredicateList pl;\n\n\t\tif (trulyTheBestJoinStrategy.isHashJoin())\n\t\t{\n\t\t\tpl = (PredicateList) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.PREDICATE_LIST,\n\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\tif (storeRestrictionList != null)\n\t\t\t{\n\t\t\t\tpl.nondestructiveAppend(storeRestrictionList);\n\t\t\t}\n\t\t\tif (nonStoreRestrictionList != null)\n\t\t\t{\n\t\t\t\tpl.nondestructiveAppend(nonStoreRestrictionList);\n\t\t\t}\n\t\t\treturn isOneRowResultSet(pl);\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn isOneRowResultSet(getTrulyTheBestAccessPath().\n\t\t\t\t\t\t\t\t\t\tgetConglomerateDescriptor(),\n\t\t\t\t\t\t\t\t\t restrictionList);\n\t\t}\n\t}"}
{"idx": 192, "target": 0, "func": "public void setRefActionInfo(long fkIndexConglomId, \n\t\t\t\t\t\t\t\t int[]fkColArray, \n\t\t\t\t\t\t\t\t String parentResultSetId,\n\t\t\t\t\t\t\t\t boolean dependentScan)\n\t{\n\n\n\t\tthis.fkIndexConglomId = fkIndexConglomId;\n\t\tthis.fkColArray = fkColArray;\n\t\tthis.raParentResultSetId = parentResultSetId;\n\t\tthis.raDependentScan = dependentScan;\n\t}"}
{"idx": 193, "target": 1, "func": "private ResultSetNode mapTableAsVTI(\n            TableDescriptor td,\n            String correlationName,\n            ResultColumnList resultColumns,\n            Properties tableProperties,\n            ContextManager cm)\n        throws StandardException {\n\n\n        // The fact that we pass a non-null table descriptor to the following\n        // call is an indication that we are mapping to a no-argument VTI. Since\n        // we have the table descriptor we do not need to pass in a TableName.\n        // See NewInvocationNode for more.\n        QueryTreeNode newNode = (QueryTreeNode) getNodeFactory().getNode(\n                C_NodeTypes.NEW_INVOCATION_NODE,\n                null, // TableName\n                td, // TableDescriptor\n                Collections.EMPTY_LIST,\n                Boolean.FALSE,\n                cm);\n\n        QueryTreeNode vtiNode;\n\n        if (correlationName != null) {\n            vtiNode = (QueryTreeNode) getNodeFactory().getNode(\n                    C_NodeTypes.FROM_VTI,\n                    newNode,\n                    correlationName,\n                    resultColumns,\n                    tableProperties,\n                    cm);\n        } else {\n            TableName exposedName = newNode.makeTableName(td.getSchemaName(),\n                    td.getDescriptorName());\n\n            vtiNode = (QueryTreeNode) getNodeFactory().getNode(\n                    C_NodeTypes.FROM_VTI,\n                    newNode,\n                    correlationName,\n                    resultColumns,\n                    tableProperties,\n                    exposedName,\n                    cm);\n        }\n\n        return (ResultSetNode) vtiNode;\n    }"}
{"idx": 194, "target": 0, "func": "public void verifyProperties(DataDictionary dDictionary)\n\t\tthrows StandardException\n\t{\n\t\tif (tableProperties == null)\n\t\t{\n\t\t\treturn;\n\t\t}\n\t\t/* Check here for:\n\t\t *\t\tinvalid properties key\n\t\t *\t\tindex and constraint properties\n\t\t *\t\tnon-existent index\n\t\t *\t\tnon-existent constraint\n\t\t *\t\tinvalid joinStrategy\n\t\t *\t\tinvalid value for hashInitialCapacity\n\t\t *\t\tinvalid value for hashLoadFactor\n\t\t *\t\tinvalid value for hashMaxCapacity\n\t\t */\n\t\tboolean indexSpecified = false;\n\t\tboolean constraintSpecified = false;\n\t\tConstraintDescriptor consDesc = null;\n\t\tEnumeration e = tableProperties.keys();\n\n\t\t\tStringUtil.SQLEqualsIgnoreCase(tableDescriptor.getSchemaName(), \n\t\t\t\t\t\t\t\t\t\t   \"SYS\");\n\t\twhile (e.hasMoreElements())\n\t\t{\n\t\t\tString key = (String) e.nextElement();\n\t\t\tString value = (String) tableProperties.get(key);\n\n\t\t\tif (key.equals(\"index\"))\n\t\t\t{\n\t\t\t\t// User only allowed to specify 1 of index and constraint, not both\n\t\t\t\tif (constraintSpecified)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_BOTH_FORCE_INDEX_AND_CONSTRAINT_SPECIFIED, \n\t\t\t\t\t\t\t\tgetBaseTableName());\n\t\t\t\t}\n\t\t\t\tindexSpecified = true;\n\n\t\t\t\t/* Validate index name - NULL means table scan */\n\t\t\t\tif (! StringUtil.SQLToUpperCase(value).equals(\"NULL\"))\n\t\t\t\t{\n\t\t\t\t\tConglomerateDescriptor cd = null;\n\t\t\t\t\tConglomerateDescriptor[] cds = tableDescriptor.getConglomerateDescriptors();\n\n\t\t\t\t\tfor (int index = 0; index < cds.length; index++)\n\t\t\t\t\t{\n\t\t\t\t\t\tcd = cds[index];\n\t\t\t\t\t\tString conglomerateName = cd.getConglomerateName();\n\t\t\t\t\t\tif (conglomerateName != null)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (conglomerateName.equals(value))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Not a match, clear cd\n\t\t\t\t\t\tcd = null;\n\t\t\t\t\t}\n\n\t\t\t\t\t// Throw exception if user specified index not found\n\t\t\t\t\tif (cd == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_FORCED_INDEX1, \n\t\t\t\t\t\t\t\t\t\tvalue, getBaseTableName());\n\t\t\t\t\t}\n\t\t\t\t\t/* Query is dependent on the ConglomerateDescriptor */\n\t\t\t\t\tgetCompilerContext().createDependency(cd);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (key.equals(\"constraint\"))\n\t\t\t{\n\t\t\t\t// User only allowed to specify 1 of index and constraint, not both\n\t\t\t\tif (indexSpecified)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_BOTH_FORCE_INDEX_AND_CONSTRAINT_SPECIFIED, \n\t\t\t\t\t\t\t\tgetBaseTableName());\n\t\t\t\t}\n\t\t\t\tconstraintSpecified = true;\n\n\t\t\t\tif (! StringUtil.SQLToUpperCase(value).equals(\"NULL\"))\n\t\t\t\t{\n\t\t\t\t\tconsDesc = \n\t\t\t\t\t\tdDictionary.getConstraintDescriptorByName(\n\t\t\t\t\t\t\t\t\ttableDescriptor, (SchemaDescriptor)null, value,\n\t\t\t\t\t\t\t\t\tfalse);\n\n\t\t\t\t\t/* Throw exception if user specified constraint not found\n\t\t\t\t\t * or if it does not have a backing index.\n\t\t\t\t\t */\n\t\t\t\t\tif ((consDesc == null) || ! consDesc.hasBackingIndex())\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_FORCED_INDEX2, \n\t\t\t\t\t\t\t\t\t\tvalue, getBaseTableName());\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Query is dependent on the ConstraintDescriptor */\n\t\t\t\t\tgetCompilerContext().createDependency(consDesc);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (key.equals(\"joinStrategy\"))\n\t\t\t{\n\t\t\t\tuserSpecifiedJoinStrategy = StringUtil.SQLToUpperCase(value);\n\t\t\t}\n\t\t\telse if (key.equals(\"hashInitialCapacity\"))\n\t\t\t{\n\t\t\t\tinitialCapacity = getIntProperty(value, key);\n\n\t\t\t\t// verify that the specified value is valid\n\t\t\t\tif (initialCapacity <= 0)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_HASH_INITIAL_CAPACITY, \n\t\t\t\t\t\t\tString.valueOf(initialCapacity));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (key.equals(\"hashLoadFactor\"))\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tloadFactor = Float.parseFloat(value);\n\t\t\t\t}\n\t\t\t\tcatch (NumberFormatException nfe)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_NUMBER_FORMAT_FOR_OVERRIDE, \n\t\t\t\t\t\t\tvalue, key);\n\t\t\t\t}\n\n\t\t\t\t// verify that the specified value is valid\n\t\t\t\tif (loadFactor <= 0.0 || loadFactor > 1.0)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_HASH_LOAD_FACTOR, \n\t\t\t\t\t\t\tvalue);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (key.equals(\"hashMaxCapacity\"))\n\t\t\t{\n\t\t\t\tmaxCapacity = getIntProperty(value, key);\n\n\t\t\t\t// verify that the specified value is valid\n\t\t\t\tif (maxCapacity <= 0)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_HASH_MAX_CAPACITY, \n\t\t\t\t\t\t\tString.valueOf(maxCapacity));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (key.equals(\"bulkFetch\"))\n\t\t\t{\n\t\t\t\tbulkFetch = getIntProperty(value, key);\n\n\t\t\t\t// verify that the specified value is valid\n\t\t\t\tif (bulkFetch <= 0)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_BULK_FETCH_VALUE, \n\t\t\t\t\t\t\tString.valueOf(bulkFetch));\n\t\t\t\t}\n\t\t\t\n\t\t\t\t// no bulk fetch on updatable scans\n\t\t\t\tif (forUpdate())\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_BULK_FETCH_UPDATEABLE);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// No other \"legal\" values at this time\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_INVALID_FROM_TABLE_PROPERTY, key,\n\t\t\t\t\t\"index, constraint, joinStrategy\");\n\t\t\t}\n\t\t}\n\n\t\t/* If user specified a non-null constraint name(DERBY-1707), then  \n\t\t * replace it in the properties list with the underlying index name to \n\t\t * simplify the code in the optimizer.\n\t\t * NOTE: The code to get from the constraint name, for a constraint\n\t\t * with a backing index, to the index name is convoluted.  Given\n\t\t * the constraint name, we can get the conglomerate id from the\n\t\t * ConstraintDescriptor.  We then use the conglomerate id to get\n\t\t * the ConglomerateDescriptor from the DataDictionary and, finally,\n\t\t * we get the index name (conglomerate name) from the ConglomerateDescriptor.\n\t\t */\n\t\tif (constraintSpecified && consDesc != null)\n\t\t{\n\t\t\tConglomerateDescriptor cd = \n\t\t\t\tdDictionary.getConglomerateDescriptor(\n\t\t\t\t\tconsDesc.getConglomerateId());\n\t\t\tString indexName = cd.getConglomerateName();\n\n\t\t\ttableProperties.remove(\"constraint\");\n\t\t\ttableProperties.put(\"index\", indexName);\n\t\t}\n\t}"}
{"idx": 195, "target": 1, "func": "public void reOrder(int[] joinOrder)\n\t{\n\t\tint\tposn;\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (joinOrder.length != size())\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\"In reOrder(), size of FromList is \" + size() + \" while size of joinOrder array is \" + joinOrder.length);\n\t\t\t}\n\n\t\t\t/*\n\t\t\t** Determine that the values in the list are unique and in range.\n\t\t\t** The easiest way to determine that they are unique is to add\n\t\t\t** them all up and see whether the result is what's expected\n\t\t\t** for that array size.\n\t\t\t*/\n\t\t\tint sum = 0;\n\t\t\tfor (int i = 0; i < joinOrder.length; i++)\n\t\t\t{\n\t\t\t\tif (joinOrder[i] < 0 || joinOrder[i] > (joinOrder.length - 1))\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"joinOrder[\" + i + \"] == \" +\n\t\t\t\t\t\t\t\t\t\t\tjoinOrder[i] +\n\t\t\t\t\t\t\t\t\t\t\t\" is out of range - must be between 0 and \" + \n\t\t\t\t\t\t\t\t\t\t\t(joinOrder.length - 1) +\n\t\t\t\t\t\t\t\t\t\t\t\" inclusive.\");\n\t\t\t\t}\n\n\t\t\t\tsum += joinOrder[i];\n\t\t\t}\n\n\t\t\t/*\n\t\t\t** The sum of all integers from 0 through n is (n * (n - 1)) / 2.\n\t\t\t*/\n\t\t\tif (sum != ( ( joinOrder.length * (joinOrder.length - 1) ) / 2) )\n\t\t\t{\n\t\t\t\tString arrayVals = \"\";\n\t\t\t\tfor (int i = 0; i < joinOrder.length; i++)\n\t\t\t\t\tarrayVals = arrayVals + joinOrder[i] + \" \";\n\t\t\t\tSanityManager.THROWASSERT(\"joinOrder array has some duplicate value: \" + arrayVals);\n\t\t\t}\n\t\t}\n\n\t\t/* Form a list that's in the order we want */\n\t\tQueryTreeNode[] orderedFL = new FromTable[joinOrder.length];\n\t\tfor (posn = 0; posn < joinOrder.length; posn++)\n\t\t{\n\t\t\t/*\n\t\t\t** Get the element at the i'th join order position from the\n\t\t\t** current list and make it the next element of orderedList.\n\t\t\t*/\n\t\t\torderedFL[posn] = elementAt(joinOrder[posn]);\n\t\t}\n\n\t\t/* Now orderedList has been built, so set this list to the same order */\n\t\tfor (posn = 0; posn < joinOrder.length; posn++)\n\t\t{\n\t\t\tsetElementAt(orderedFL[posn], posn);\n\t\t}\n\t}"}
{"idx": 196, "target": 0, "func": "private VTICosting  getVTICosting()\n        throws StandardException\n    {\n        if ( !isDerbyStyleTableFunction ) { return (version2) ? (VTICosting) ps : (VTICosting) rs; }\n        \n        String              className = methodCall.getJavaClassName();\n        Class               vtiClass = lookupClass( className );\n        \n        try {\n            Constructor         constructor = vtiClass.getConstructor( new Class[] {} );\n            VTICosting          result = (VTICosting) constructor.newInstance( null );\n\n            return result;\n        }\n        catch (Throwable t)\n        {\n            throw StandardException.unexpectedUserException( t );\n        }\n    }"}
{"idx": 197, "target": 0, "func": "private Object getNewInstance()\n        throws StandardException\n    {\n\t\tNewInvocationNode   constructor = (NewInvocationNode) methodCall;\n\t\tClass[]  paramTypeClasses = constructor.getMethodParameterClasses();\n\t\tObject[] paramObjects = null;\n\n\t\tif (paramTypeClasses != null)\n\t\t{\n\t\t\tparamObjects = new Object[paramTypeClasses.length];\n\n\t\t\tfor (int index = 0; index < paramTypeClasses.length; index++)\n\t\t\t{\n\t\t\t\tClass paramClass = paramTypeClasses[index];\n\n\t\t\t\tparamObjects[index] = methodParms[index].getConstantValueAsObject();\n\n\t\t\t\t// As-per the JDBC spec SMALLINT and TINYINT map to java.lang.Integer\n\t\t\t\t// as objects. This means if getConstantValueAsObject() has returned an\n\t\t\t\t// Integer obejct in these cases, whereas Java method calling requires\n\t\t\t\t// Short or Byte object.\n\t\t\t\tif ((paramObjects[index] != null) && paramClass.isPrimitive()) {\n\n\t\t\t\t\tif (paramClass.equals(Short.TYPE)) {\n\t\t\t\t\t\tparamObjects[index] =\n\t\t\t\t\t\t\tnew Short(((Integer) paramObjects[index]).shortValue());\n\t\t\t\t\t} else if (paramClass.equals(Byte.TYPE)) {\n\t\t\t\t\t\tparamObjects[index] =\n\t\t\t\t\t\t\tnew Byte(((Integer) paramObjects[index]).byteValue());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Pass defaults for unknown primitive values\n\t\t\t\tif (paramObjects[index] == null && \n\t\t\t\t\tparamClass.isPrimitive())\n\t\t\t\t{\n\t\t\t\t\tif (paramClass.equals(Integer.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Integer(0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Short.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Short((short) 0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Byte.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Byte((byte) 0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Long.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Long((long) 0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Float.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Float((float) 0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Double.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Double((double) 0);\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Boolean.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = Boolean.FALSE;\n\t\t\t\t\t}\n\t\t\t\t\telse if (paramClass.equals(Character.TYPE))\n\t\t\t\t\t{\n\t\t\t\t\t\tparamObjects[index] = new Character(Character.MIN_VALUE);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tparamTypeClasses = new Class[0];\n\t\t\tparamObjects = new Object[0];\n\t\t}\n\n        try\n        {\n            ClassInspector classInspector = getClassFactory().getClassInspector();\n            String javaClassName = methodCall.getJavaClassName();\n            Constructor constr = classInspector.getClass(javaClassName).getConstructor(paramTypeClasses);\n\n            return constr.newInstance(paramObjects);\n        }\n\t\tcatch(Throwable t)\n\t\t{\n            if( t instanceof InvocationTargetException)\n            {\n                InvocationTargetException ite = (InvocationTargetException) t;\n                Throwable wrappedThrowable = ite.getTargetException();\n                if( wrappedThrowable instanceof StandardException)\n                    throw (StandardException) wrappedThrowable;\n            }\n\t\t\tthrow StandardException.unexpectedUserException(t);\n\t\t}\n    }"}
{"idx": 198, "target": 1, "func": "public CostEstimate optimizeIt(\n\t\t\t\t\t\t\tOptimizer optimizer,\n\t\t\t\t\t\t\tOptimizablePredicateList predList,\n\t\t\t\t\t\t\tCostEstimate outerCost,\n\t\t\t\t\t\t\tRowOrdering rowOrdering)\n\t\t\tthrows StandardException\n\t{\n\t\t// RESOLVE: NEED TO FACTOR IN THE COST OF GROUPING (SORTING) HERE\n\t\tCostEstimate childCost = ((Optimizable) childResult).optimizeIt(\n\t\t\t\t\t\t\t\t\t\t\t\t\toptimizer,\n\t\t\t\t\t\t\t\t\t\t\t\t\tpredList,\n\t\t\t\t\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\trowOrdering);\n\n\t\tCostEstimate retval = super.optimizeIt(\n\t\t\t\t\t\t\t\t\t\t\t\toptimizer,\n\t\t\t\t\t\t\t\t\t\t\t\tpredList,\n\t\t\t\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\t\t\t\trowOrdering\n\t\t\t\t\t\t\t\t\t\t\t  );\n\n\t\treturn retval;\n\t}"}
{"idx": 199, "target": 0, "func": "public boolean LOJ_reorderable(int numTables)\n\t\tthrows StandardException\n\t{\n\t\tboolean anyChange = false;\n\n\t\tResultSetNode logicalLeftResultSet;  // row-preserving side\n\t\tResultSetNode logicalRightResultSet; // null-producing side\n\n\t\t// Figure out which is the row-preserving side and which is\n\t\t// null-producing side.\n\t\tif (rightOuterJoin)\n\t\t{ // right outer join\n\t\t\tlogicalLeftResultSet  = rightResultSet;\n\t\t\tlogicalRightResultSet = leftResultSet;\n\t\t}\n\t\telse \n\t\t{\n\t\t\tlogicalLeftResultSet  = leftResultSet;\n\t\t\tlogicalRightResultSet = rightResultSet;\n\t\t}\n\t\t\n\t\t// Redundantly normalize the ON predicate (it will also be called in preprocess()).\n\t\tsuper.normExpressions();\n\n        // This is a very simple OJ of base tables. Do nothing.\n\t\tif (logicalLeftResultSet instanceof FromBaseTable &&\n\t\t\tlogicalRightResultSet instanceof FromBaseTable)\n\t\t\treturn anyChange;\n\n        // Recursively check if we can reordering OJ, and build the table\n\t\t// references. Note that joins may have been reordered and therefore the\n\t\t// table references need to be recomputed.\n\t\tif (logicalLeftResultSet instanceof HalfOuterJoinNode)\n\t\t{\n\t\t\tanyChange =\t((HalfOuterJoinNode)logicalLeftResultSet).LOJ_reorderable(numTables) || anyChange;\n\t\t}\n\t\telse if (!(logicalLeftResultSet instanceof FromBaseTable))\n        {// left operand must be either a base table or another OJ\n\t\t\t// In principle, we don't care about the left operand.  However, we\n\t\t\t// need to re-bind the resultColumns.  If the left operand is a\n\t\t\t// view, we may have to re-bind the where clause etc...\n\t\t\t// We ran into difficulty for the following query:\n\t\t\t//  create view v8 (cv, bv, av) as (select c, b, a from t union select f, e, d from s);\n\t\t\t//  select * from v8 left outer join (s left outer join r on (f = i)) on (e=v8.bv);\n\t\t\treturn anyChange;\n\t\t}\n\n\t\tif (logicalRightResultSet instanceof HalfOuterJoinNode)\n\t\t{\n\t\t\tanyChange = ((HalfOuterJoinNode)logicalRightResultSet).LOJ_reorderable(numTables) || anyChange;\n\t\t}\n\t\telse if (!(logicalRightResultSet instanceof FromBaseTable))\n        {// right operand must be either a base table or another OJ\n\t\t\treturn anyChange;\n\t\t}\n\n        // It is much easier to do OJ reordering if there is no ROJ.\n\t\t// However, we ran into some problem downstream when we transform an ROJ\n\t\t// into LOJ -- transformOuterJoin() didn't expect ROJ to be transformed\n\t\t// into LOJ alread.  So, we skip optimizing ROJ at the moment.\n\t\tif (rightOuterJoin || (logicalRightResultSet instanceof HalfOuterJoinNode && \n\t\t\t\t\t\t\t   ((HalfOuterJoinNode)logicalRightResultSet).rightOuterJoin))\n\t\t{\n\t\t\treturn LOJ_bindResultColumns(anyChange);\n\t\t}\n\n        // Build the data structure for testing/doing OJ reordering.  Fill in\n        // the table references on row-preserving and null-producing sides.  It\n        // may be possible that either operand is a complex view.\n\n        JBitSet RPReferencedTableMap; // Row-preserving\n        JBitSet NPReferencedTableMap; // Null-producing\n\n\t\tRPReferencedTableMap = logicalLeftResultSet.LOJgetReferencedTables(numTables);\n\t\tNPReferencedTableMap = logicalRightResultSet.LOJgetReferencedTables(numTables);\n\n\t\tif ((RPReferencedTableMap == null || NPReferencedTableMap == null) &&\n\t\t\tanyChange)\n\t\t{\n\t\t\treturn LOJ_bindResultColumns(anyChange);\n\t\t}\n\n\n        // Check if logical right operand is another OJ... so we may be able\n        // to push the join.\n        if (logicalRightResultSet instanceof HalfOuterJoinNode)\n\t\t{\n            // Get the row-preserving map of the  child OJ\n            JBitSet  nestedChildOJRPRefTableMap =\n                ((HalfOuterJoinNode)logicalRightResultSet).\n                LOJgetRPReferencedTables(numTables);\n\n            // Checks that top has p(t1,t2)\n            if ( ! isNullRejecting(\n                         joinClause,\n                         RPReferencedTableMap,\n                         nestedChildOJRPRefTableMap)) {\n                // No, give up.\n                return LOJ_bindResultColumns(anyChange);\n            }\n\n            // Get the null-producing map of the child OJ\n            JBitSet  nestedChildOJNPRefTableMap =\n                ((HalfOuterJoinNode)logicalRightResultSet).\n                LOJgetNPReferencedTables(numTables);\n\n            // Checks that right child has p(t2,t3)\n            if ( isNullRejecting(\n                         ((HalfOuterJoinNode)logicalRightResultSet).joinClause,\n                         nestedChildOJRPRefTableMap,\n                         nestedChildOJNPRefTableMap)) {\n                // Push the current OJ into the next level For safety, check\n                // the JoinNode data members: they should null or empty list\n                // before we proceed.\n                if (super.subqueryList.size() != 0 ||\n                    ((JoinNode)logicalRightResultSet).\n                        subqueryList.size() != 0 ||\n                    super.joinPredicates.size() != 0 ||\n                    ((JoinNode)logicalRightResultSet).\n                        joinPredicates.size() != 0 ||\n                    super.usingClause != null ||\n                    ((JoinNode)logicalRightResultSet).\n                        usingClause != null) {\n\n                    return LOJ_bindResultColumns(anyChange); //  get out of here\n                }\n                anyChange = true; // we are reordering the OJs.\n\n                ResultSetNode tmp = logicalLeftResultSet;\n                ResultSetNode LChild, RChild;\n\n                //            this OJ\n                //            /      \\\n                //  logicalLeftRS   LogicalRightRS\n                //                   /     \\\n                //                LChild  RChild\n                // becomes\n                //\n                //               this OJ\n                //               /      \\\n                //     LogicalRightRS   RChild\n                //           /     \\\n                // logicalLeftRS LChild <<< we need to be careful about this\n                //                          order as the \"LogicalRightRS\n                //                          may be a ROJ\n                //\n\n                // handle the lower level OJ node\n                LChild = ((HalfOuterJoinNode)logicalRightResultSet).\n                    leftResultSet;\n                RChild = ((HalfOuterJoinNode)logicalRightResultSet).\n                    rightResultSet;\n\n                ((HalfOuterJoinNode)logicalRightResultSet).\n                    rightResultSet = LChild;\n                ((HalfOuterJoinNode)logicalRightResultSet).\n                    leftResultSet  = tmp;\n\n                // switch the ON clause\n                {\n                    ValueNode vn = joinClause;\n                    joinClause =\n                        ((HalfOuterJoinNode)logicalRightResultSet).joinClause;\n                    ((HalfOuterJoinNode)logicalRightResultSet).joinClause = vn;\n                }\n\n                // No need to switch HalfOuterJoinNode data members for now\n                // because we are handling only OJ.\n                // boolean local_rightOuterJoin = rightOuterJoin;\n                // boolean local_transformed    = transformed;\n                // rightOuterJoin = ((HalfOuterJoinNode)logicalRightResultSet).\n                //     rightOuterJoin;\n                // transformed = ((HalfOuterJoinNode)logicalRightResultSet).\n                //     transformed;\n                // ((HalfOuterJoinNode)logicalRightResultSet).rightOuterJoin =\n                //     local_rightOuterJoin;\n                // ((HalfOuterJoinNode)logicalRightResultSet).transformed =\n                //     local_transformed;\n\n                FromList localFromList = (FromList) getNodeFactory().getNode(\n                    C_NodeTypes.FROM_LIST,\n                    getNodeFactory().doJoinOrderOptimization(),\n                    getContextManager());\n\n                // switch OJ nodes: by handling the current OJ node\n                leftResultSet  = logicalRightResultSet;\n                rightResultSet = RChild;\n\n                // rebuild the result columns and re-bind column references\n                ((HalfOuterJoinNode)leftResultSet).resultColumns = null;\n                 // localFromList is empty:\n                ((JoinNode)leftResultSet).bindResultColumns(localFromList);\n\n                // left operand must be another OJ, so recurse.\n                boolean localChange = ((HalfOuterJoinNode)leftResultSet).\n                    LOJ_reorderable(numTables);\n            }\n        }\n\n        return LOJ_bindResultColumns(anyChange);\n    }"}
{"idx": 200, "target": 1, "func": "public ValueNode bindExpression(\n    FromList        fromList, \n    SubqueryList    subqueryList,\n    Vector          aggregateVector) \n        throws StandardException\n    {\n        super.bindExpression(fromList, subqueryList, aggregateVector);\n\n        String pattern = null;\n\n        // pattern must be a string or a parameter\n\n        if (!(leftOperand.requiresTypeFromContext()) && \n             !(leftOperand.getTypeId().isStringTypeId()))\n        {\n            throw StandardException.newException(\n                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, \"LIKE\", \"FUNCTION\");\n        }\n\n        // escape must be a string or a parameter\n        if ((rightOperand != null) && \n            !(rightOperand.requiresTypeFromContext()) && \n            !(rightOperand.getTypeId().isStringTypeId()))\n        {\n            throw StandardException.newException(\n                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, \"LIKE\", \"FUNCTION\");\n        }\n\n        // deal with operand parameters\n\n        /* \n        *  Is there a ? parameter on the left? ie. \"? like 'Derby'\"\n        *\n        *  Do left first because its length is always maximum;\n        *  a parameter on the right copies its length from\n        *  the left, since it won't match if it is any longer than it.\n        */\n        if (receiver.requiresTypeFromContext())\n        {\n            receiver.setType(\n                new DataTypeDescriptor(\n                    TypeId.getBuiltInTypeId(Types.VARCHAR), true));\n            //check if this parameter can pick up it's collation from pattern\n            //or escape clauses in that order. If not, then it will take it's\n            //collation from the compilation schema.\n            if (!leftOperand.requiresTypeFromContext()) {\n                receiver.setCollationInfo(leftOperand.getTypeServices());\n\n            } else if (rightOperand != null && !rightOperand.requiresTypeFromContext()) {\n                receiver.setCollationInfo(rightOperand.getTypeServices());          \t\n            } else {\n    \t\t\treceiver.setCollationUsingCompilationSchema();            \t\n            }\n        }\n\n        /* \n         *  Is there a ? parameter for the PATTERN of LIKE? ie. \"column like ?\"\n         *  \n         *  Copy from the receiver -- legal if both are parameters,\n         *  both will be max length.\n         *  REMIND: should nullability be copied, or set to true?\n         */\n        if (leftOperand.requiresTypeFromContext())\n        {\n            /*\n            * Set the pattern to the type of the left parameter, if\n            * the left is a string, otherwise set it to be VARCHAR. \n            */\n            if (receiver.getTypeId().isStringTypeId())\n            {\n                leftOperand.setType(receiver.getTypeServices());\n            }\n            else\n            {\n                leftOperand.setType(\n                    new DataTypeDescriptor(\n                        TypeId.getBuiltInTypeId(Types.VARCHAR), true));\n            }\n\t\t\t//collation of ? operand should be picked up from the context.\n            //By the time we come here, receiver will have correct collation\n            //set on it and hence we can rely on it to get correct collation\n            //for the other ? in LIKE clause\n            leftOperand.setCollationInfo(receiver.getTypeServices());          \t\n        }\n\n        /* \n         *  Is there a ? parameter for the ESCAPE of LIKE?\n         *  Copy from the receiver -- legal if both are parameters,\n         *  both will be max length.  nullability is set to true.\n         */\n\n        if (rightOperand != null && rightOperand.requiresTypeFromContext())\n        {\n            /*\n             * Set the pattern to the type of the left parameter, if\n             * the left is a string, otherwise set it to be VARCHAR. \n             */\n            if (receiver.getTypeId().isStringTypeId())\n            {\n                rightOperand.setType(receiver.getTypeServices());\n            }\n            else\n            {\n                rightOperand.setType(\n                    new DataTypeDescriptor(\n                        TypeId.getBuiltInTypeId(Types.VARCHAR), true));\n            }\n\t\t\t//collation of ? operand should be picked up from the context.\n            //By the time we come here, receiver will have correct collation\n            //set on it and hence we can rely on it to get correct collation\n            //for the other ? in LIKE clause\n            rightOperand.setCollationInfo(receiver.getTypeServices());    \t\n        }\n\n        bindToBuiltIn();\n\n        TypeCompiler receiverTC = receiver.getTypeCompiler();\n        TypeCompiler leftTC     = leftOperand.getTypeCompiler();\n\n        /* The receiver must be a string type\n        */\n        if (! receiver.getTypeId().isStringTypeId())\n        {\n            throw StandardException.newException(\n                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, \"LIKE\", \"FUNCTION\");\n        }\n\n        /* If either the left or right operands are non-string types,\n         * then we generate an implicit cast to VARCHAR.\n         */\n        if (!leftOperand.getTypeId().isStringTypeId())\n        {\n            leftOperand = castArgToString(leftOperand);\n            leftTC      = leftOperand.getTypeCompiler();\n        }\n\n        if (rightOperand != null)\n        {\n            rightOperand = castArgToString(rightOperand);\n        }\n\n        /* \n         * Remember whether or not the right side (the like pattern) is a string \n         * constant.  We need to remember here so that we can transform LIKE \n         * 'constant' into = 'constant' for non unicode based collation columns.\n         */\n        boolean leftConstant = (leftOperand instanceof CharConstantNode);\n        if (leftConstant)\n        {\n            pattern = ((CharConstantNode) leftOperand).getString();\n        }\n\n        boolean rightConstant = (rightOperand instanceof CharConstantNode);\n\n        if (rightConstant)\n        {\n            escape = ((CharConstantNode) rightOperand).getString();\n            if (escape.length() != 1)\n            {\n                throw StandardException.newException(\n                    SQLState.LANG_INVALID_ESCAPE_CHARACTER, escape);\n            }\n        }\n        else if (rightOperand == null)\n        {\n            // No Escape clause: Let optimization continue for the = case below\n            rightConstant = true;\n        }\n\n        /* If we are comparing a UCS_BASIC char with a terriotry based char \n         * then we generate a cast above the receiver to force preprocess to\n         * not attempt any of the > <= optimizations since there is no\n         * way to determine the 'next' character for the <= operand.\n         *\n         * TODO-COLLATE - probably need to do something about different \n         *                collation types here.\n         */\n\n        // The left and the pattern of the LIKE must be same collation type\n        // and derivation.\n        if (!receiver.getTypeServices().compareCollationInfo(\n        \t\tleftOperand.getTypeServices()))\n        {\n            // throw error.\n            throw StandardException.newException(\n                        SQLState.LANG_LIKE_COLLATION_MISMATCH, \n                        receiver.getTypeServices().getSQLstring(),\n                        receiver.getTypeServices().getCollationName(),\n                        leftOperand.getTypeServices().getSQLstring(),\n                        leftOperand.getTypeServices().getCollationName());\n        }\n\n        /* If the left side of LIKE is a ColumnReference and right side is a \n         * string constant without a wildcard (eg. column LIKE 'Derby') then we \n         * transform the LIKE into the equivalent LIKE AND =.  \n         * If we have an escape clause it also must be a constant \n         * (eg. column LIKE 'Derby' ESCAPE '%').\n         *\n         * These types of transformations are normally done at preprocess time, \n         * but we make an exception and do this one at bind time because we \n         * transform a NOT LIKE 'a' into (a LIKE 'a') = false prior to \n         * preprocessing.  \n         *\n         * The transformed tree will become:\n         *\n         *        AND\n         *       /   \\\n         *     LIKE   =\n         */\n\n        if ((receiver instanceof ColumnReference) && \n            leftConstant                          && \n            rightConstant)\n        {\n            if (Like.isOptimizable(pattern))\n            {\n                String newPattern = null;\n\n                /*\n                 * If our pattern has no pattern chars (after stripping them out\n                 * for the ESCAPE case), we are good to apply = to this match\n                 */\n\n                if (escape != null)\n                {\n                    /* we return a new pattern stripped of ESCAPE chars */\n                    newPattern =\n                        Like.stripEscapesNoPatternChars(\n                            pattern, escape.charAt(0));\n                }\n                else if (pattern.indexOf('_') == -1 && \n                         pattern.indexOf('%') == -1)\n                {\n                    // no pattern characters.\n                    newPattern = pattern;\n                }\n\n                if (newPattern != null)\n                {\n                    // met all conditions, transform LIKE into a \"LIKE and =\"\n\n                    ValueNode leftClone = receiver.getClone();\n\n                    // Remember that we did xform, see preprocess()\n                    addedEquals = true;\n\n                    // create equals node of the form (eg. column like 'Derby' :\n                    //       =\n                    //     /   \\\n                    //  column  'Derby'\n                    BinaryComparisonOperatorNode equals = \n                        (BinaryComparisonOperatorNode) getNodeFactory().getNode(\n                            C_NodeTypes.BINARY_EQUALS_OPERATOR_NODE,\n                            leftClone, \n                            (ValueNode) getNodeFactory().getNode(\n                                C_NodeTypes.CHAR_CONSTANT_NODE,\n                                newPattern,\n                                getContextManager()),\n                            getContextManager());\n\n                    // Set forQueryRewrite to bypass comparability checks\n                    equals.setForQueryRewrite(true);\n\n                    equals = (BinaryComparisonOperatorNode) \n                        equals.bindExpression(\n                            fromList, subqueryList, aggregateVector);\n\n                    // create new and node and hook in \"equals\" the new \"=' node\n                    //\n                    //        AND\n                    //       /   \\\n                    //     LIKE   = \n                    //           / \\\n                    //       column 'Derby'\n\n                    AndNode newAnd = \n                        (AndNode) getNodeFactory().getNode(\n                                    C_NodeTypes.AND_NODE,\n                                    this,\n                                    equals,\n                                    getContextManager());\n\n                    finishBindExpr();\n                    newAnd.postBindFixup();\n\n                    return newAnd;\n                }\n            }\n        }\n\n        finishBindExpr();\n\n        return this;\n    }"}
{"idx": 201, "target": 1, "func": "public void bindStatement() throws StandardException\n\t{\n\t\tCompilerContext\t\t\tcc = getCompilerContext();\n\t\tConglomerateDescriptor\tcd;\n\t\tDataDictionary\t\t\tdd = getDataDictionary();\n\t\tSchemaDescriptor\t\tsd;\n\n\t\tString schemaName = tableName.getSchemaName();\n\t\tsd = getSchemaDescriptor(schemaName);\n\n\t\t// Users are not allowed to lock system tables\n\t\tif (sd.isSystemSchema())\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_NO_USER_DDL_IN_SYSTEM_SCHEMA, \n\t\t\t\t\t\t\tstatementToString(), schemaName);\n\t\t}\n\n\t\tlockTableDescriptor = getTableDescriptor(tableName.getTableName(), sd);\n\n\t\tif (lockTableDescriptor == null)\n\t\t{\n\t\t\t// Check if the reference is for a synonym.\n\t\t\tTableName synonymTab = resolveTableToSynonym(tableName);\n\t\t\tif (synonymTab == null)\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_TABLE_NOT_FOUND, tableName);\n\t\t\ttableName = synonymTab;\n\t\t\tsd = getSchemaDescriptor(tableName.getSchemaName());\n\n\t\t\tlockTableDescriptor = getTableDescriptor(synonymTab.getTableName(), sd);\n\t\t\tif (lockTableDescriptor == null)\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_TABLE_NOT_FOUND, tableName);\n\t\t}\n\n\t\t//throw an exception if user is attempting to lock a temporary table\n\t\tif (lockTableDescriptor.getTableType() == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)\n\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);\n\t\t}\n\n\t\tconglomerateNumber = lockTableDescriptor.getHeapConglomerateId();\n\n\t\t/* Get the base conglomerate descriptor */\n\t\tcd = lockTableDescriptor.getConglomerateDescriptor(conglomerateNumber);\n\n\t\t/* Statement is dependent on the TableDescriptor and ConglomerateDescriptor */\n\t\tcc.createDependency(lockTableDescriptor);\n\t\tcc.createDependency(cd);\n\n\t\tif (isPrivilegeCollectionRequired())\n\t\t{\n\t\t\t// need SELECT privilege to perform lock table statement.\n\t\t\tcc.pushCurrentPrivType(Authorizer.SELECT_PRIV);\n\t\t\tcc.addRequiredTablePriv(lockTableDescriptor);\n\t\t\tcc.popCurrentPrivType();\n\t\t}\n\t}"}
{"idx": 202, "target": 0, "func": "public boolean referencesSessionSchema()\n\t\tthrows StandardException\n\t{\n\t\t//If lock table is on a SESSION schema table, then return true. \n\t\treturn isSessionSchema(lockTableDescriptor.getSchemaName());\n\t}"}
{"idx": 203, "target": 0, "func": "protected void resolveMethodCall\n        (\n         String javaClassName,\n         boolean staticMethod\n         ) \n        throws StandardException\n\t{\n\t\t// only allow direct method calls through routines and internal SQL.\n\t\tif (routineInfo == null && !internalCall)\n\t\t{\n\t\t\t// See if we are being executed in an internal context\n\t\t\tif ((getCompilerContext().getReliability() & CompilerContext.INTERNAL_SQL_ILLEGAL) != 0) {\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_SYNTAX_ERROR,  javaClassName + (staticMethod ? \"::\" : \".\") + methodName);\n\t\t\t}\n\t\t}\n\n\t\tint\t\t\tcount = signature.length;\n\n\t\tClassInspector classInspector = getClassFactory().getClassInspector();\n\n\t\t\n\t\tString[]\t\tparmTypeNames;\n\t\tString[]\t\tprimParmTypeNames = null;\n\t\tboolean[]\t\tisParam = getIsParam();\n\n\t\tboolean hasDynamicResultSets = hasVarargs() ?\n            false :\n            (routineInfo != null) && (count != 0) && (count != methodParms.length);\n\n        /*\n        ** Find the matching method that is public.\n        */\n        int signatureOffset = methodName.indexOf('(');\n        \t\n        // support Java signatures by checking if the method name contains a '('\n        if (signatureOffset != -1) {\n            parmTypeNames = parseValidateSignature(methodName, signatureOffset, hasDynamicResultSets);\n            methodName = methodName.substring(0, signatureOffset);\n            \n            // If the signature is specified then Derby resolves to exactly\n            // that method. Setting this flag to false disables the method\n            // resolution from automatically optionally repeating the last\n            // parameter as needed.\n            hasDynamicResultSets = false;\n        }\n        else\n        {\n            parmTypeNames = getObjectSignature();\n        }\n\n        // the actual type of the trailing Java varargs arg is an array\n        if ( hasVarargs() )\n        {\n            parmTypeNames[ count - 1 ] = parmTypeNames[ count - 1 ] + \"[]\";\n        }\n\n        try\n        {\n            method = classInspector.findPublicMethod\n                (\n                 javaClassName,\n                 methodName,\n                 parmTypeNames,\n                 null,\n                 isParam,\n                 staticMethod,\n                 hasDynamicResultSets,\n                 hasVarargs()\n                 );\n\n            // DB2 LUW does not support Java object types for SMALLINT, INTEGER, BIGINT, REAL, DOUBLE\n            // and these are the only types that can map to a primitive or an object type according\n            // to SQL part 13. So we never have a second chance match.\n            // Also if the DDL specified a signature, then no alternate resolution\n            if (signatureOffset == -1 && routineInfo == null) {\n\n                /* If no match, then retry with combinations of object and\n                 * primitive types.\n                 */\n                if (method == null)\n                {\n                    primParmTypeNames = getPrimitiveSignature(false);\n\n                    method = classInspector.findPublicMethod\n                        (\n                         javaClassName,\n                         methodName,\n                         parmTypeNames,\n                         primParmTypeNames,\n                         isParam,\n                         staticMethod,\n                         hasDynamicResultSets,\n                         hasVarargs()\n                         );\n                }\n            }\n        }\n        catch (ClassNotFoundException e)\n        {\n            /*\n            ** If one of the classes couldn't be found, just act like the\n            ** method couldn't be found.  The error lists all the class names,\n            ** which should give the user enough info to diagnose the problem.\n            */\n            method = null;\n        }\n\t\t/* Throw exception if no matching signature found */\n\t\tif (method == null)\n\t\t{\n\t\t\tthrowNoMethodFound(javaClassName, parmTypeNames, primParmTypeNames);\n\t\t}\n\n\t\tString\ttypeName = classInspector.getType(method);\n\t\tactualMethodReturnType = typeName;\n\n\t\tif (routineInfo == null) {\n\n\t\t\t/* void methods are only okay for CALL Statements */\n\t\t\tif (typeName.equals(\"void\"))\n\t\t\t{\n\t\t\t\tif (!forCallStatement)\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_VOID_METHOD_CALL);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tString promoteName = null;\n\t\t\tTypeDescriptorImpl returnType = (TypeDescriptorImpl) routineInfo.getReturnType();\n\t\t\tString requiredType;\n\t\t\tif (returnType == null)\n\t\t\t{\n\t\t\t\t// must have a void method for a procedure call.\n\t\t\t\trequiredType = \"void\";\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tTypeId returnTypeId = TypeId.getBuiltInTypeId(returnType.getJDBCTypeId());\n\n\t\t\t\tif (\n\t\t\t\t    returnType.isRowMultiSet() &&\n\t\t\t\t    ( routineInfo.getParameterStyle() == RoutineAliasInfo.PS_DERBY_JDBC_RESULT_SET )\n\t\t\t\t)\n\t\t\t\t{\n\t\t\t\t    requiredType = ResultSet.class.getName();\n\t\t\t\t}\n                else if ( returnType.getTypeId().userType() )\n                {\n                    requiredType = ((UserDefinedTypeIdImpl) returnType.getTypeId()).getClassName();\n                }\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t \t\trequiredType = returnTypeId.getCorrespondingJavaTypeName();\n\n\t\t\t\t\tif (!requiredType.equals(typeName)) {\n\t\t\t\t\t\tswitch (returnType.getJDBCTypeId()) {\n\t\t\t\t\t\tcase java.sql.Types.BOOLEAN:\n\t\t\t\t\t\tcase java.sql.Types.SMALLINT:\n\t\t\t\t\t\tcase java.sql.Types.INTEGER:\n\t\t\t\t\t\tcase java.sql.Types.BIGINT:\n\t\t\t\t\t\tcase java.sql.Types.REAL:\n\t\t\t\t\t\tcase java.sql.Types.DOUBLE:\n\t\t\t\t\t\t\tTypeCompiler tc = getTypeCompiler(returnTypeId);\n\t\t\t\t\t\t\trequiredType = tc.getCorrespondingPrimitiveTypeName();\n\t\t\t\t\t\t\tif (!routineInfo.calledOnNullInput() && routineInfo.getParameterCount() != 0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpromoteName = returnTypeId.getCorrespondingJavaTypeName();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            boolean foundCorrectType;\n            if ( ResultSet.class.getName().equals( requiredType )  )\n            {\n                // allow subtypes of ResultSet too\n                try {\n                    Class actualType = classInspector.getClass( typeName );\n\n                    foundCorrectType = ResultSet.class.isAssignableFrom( actualType );\n                }\n                catch (ClassNotFoundException cnfe) { foundCorrectType = false; }\n            }\n            else{ foundCorrectType = requiredType.equals(typeName); }\n\n\t\t\tif (!foundCorrectType)\n\t\t\t{\n\t\t\t\tthrowNoMethodFound(requiredType + \" \" + javaClassName, parmTypeNames, primParmTypeNames);\n\t\t\t}\n\n\t\t\t// for a returns null on null input with a primitive\n\t\t\t// type we need to promote to an object so we can return null.\n\t\t\tif (promoteName != null)\n\t\t\t\ttypeName = promoteName;\n\t\t\t//propogate collation type from RoutineAliasInfo to\n\t\t\t// MethodCallNode DERBY-2972\n                        if (routineInfo.getReturnType() != null)\n                            setCollationType(routineInfo.getReturnType().getCollationType());     \n                }\n\t \tsetJavaTypeName( typeName );\n                \n\t\tmethodParameterTypes = classInspector.getParameterTypes(method);\n\n        String methodParameter = null;\n        \n\t\tfor (int i = 0; i < methodParameterTypes.length; i++)\n\t\t{\n\t\t\tmethodParameter = methodParameterTypes[i];\n\n\t\t\tif (routineInfo != null) {\n\t\t\t\tif (i < routineInfo.getParameterCount()) {\n\t\t\t\t\tint parameterMode = routineInfo.getParameterModes()[ getRoutineArgIdx( i ) ];\n\n\t\t\t\t\tswitch (parameterMode) {\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_IN:\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_IN_OUT:\n\t\t\t\t\t\t// we need to see if the type of the array is\n\t\t\t\t\t\t// primitive, not the array itself.\n\t\t\t\t\t\tmethodParameter = stripOneArrayLevel( methodParameter );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_OUT:\n\t\t\t\t\t\t// value is not obtained *from* parameter.\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            //\n            // Strip off the array type if this is a varargs arg. We are only interested in\n            // whether we need to cast to the cell type.\n            //\n            if ( hasVarargs() && (i >= getFirstVarargIdx()) )\n            {\n                methodParameter = stripOneArrayLevel( methodParameter );\n            }\n\n\t\t\tif (ClassInspector.primitiveType(methodParameter))\n            {\n                // varargs may be omitted, so there may not be an invocation argument\n                // corresponding to the vararg\n                if ( i < methodParms.length )\n                {\n                    methodParms[i].castToPrimitive(true);\n                }\n            }\n\t\t}\n\n        // the last routine parameter may have been a varargs. if so,\n        // casting may be needed on the trailing varargs\n        if ( hasVarargs() )\n        {\n            int     firstVarargIdx = getFirstVarargIdx();\n            int     trailingVarargCount = methodParms.length - firstVarargIdx;\n\n            // the first vararg was handled in the preceding loop\n            for ( int i = 1; i < trailingVarargCount; i++ )\n            {\n                if (ClassInspector.primitiveType(methodParameter))\n                {\n                    methodParms[ i + firstVarargIdx ].castToPrimitive(true);\n                }\n            }\n        }\n\n\t\t/* Set type info for any null parameters */\n\t\tif ( someParametersAreNull() )\n\t\t{\n\t\t\tsetNullParameterInfo(methodParameterTypes);\n\t\t}\n\n\n    \n\t\t/* bug 4450 - if the callable statement is ? = call form, generate the metadata\n\t\tinfor for the return parameter. We don't really need that info in order to\n\t\texecute the callable statement. But with jdbc3.0, this information should be\n\t\tmade available for return parameter through ParameterMetaData class.\n\t\tParser sets a flag in compilercontext if ? = call. If the flag is set,\n\t\twe generate the metadata info for the return parameter and reset the flag\n\t\tin the compilercontext for future call statements*/\n\t\tDataTypeDescriptor dts = DataTypeDescriptor.getSQLDataTypeDescriptor(typeName);\n\t\tif (getCompilerContext().getReturnParameterFlag()) {\n\t\t\tgetCompilerContext().getParameterTypes()[0] = dts;\n\t\t}\n    }"}
{"idx": 204, "target": 0, "func": "private void    generateVarargs\n        ( ExpressionClassBuilder acb, MethodBuilder mb )\n        throws StandardException\n    {\n        // the vararg is the last declared arg of the Java method. it is always\n        // an array type. right now we only support vararg static methods.\n        // if we have to support vararg constructors in the future, then this code\n        // will need adjustment.\n        int         firstVarargIdx = getFirstVarargIdx();\n        String      arrayType = methodParameterTypes[ firstVarargIdx ];\n        String      cellType = stripOneArrayLevel( arrayType );\n        String      varargType = cellType;\n\n        // must strip another array level off of out and in/out parameters\n        if ( routineInfo != null )\n        {\n            if ( routineInfo.getParameterModes()[ firstVarargIdx ] != JDBC30Translation.PARAMETER_MODE_IN )\n            {\n                varargType = stripOneArrayLevel( varargType );\n            }\n        }\n\n        int         varargCount = methodParms.length - firstVarargIdx;\n        if ( varargCount < 0 ) { varargCount = 0; }\n\n        // allocate an array to hold the varargs\n\t\tLocalField arrayField = acb.newFieldDeclaration( Modifier.PRIVATE, arrayType );\n\t\tMethodBuilder cb = acb.getConstructor();\n\t\tcb.pushNewArray( cellType, varargCount );\n\t\tcb.setField( arrayField );\n\n        // now put the arguments into the array\n        for ( int i = 0; i < varargCount; i++ )\n        {\n\t\t\tmb.getField( arrayField ); // push the array onto the stack\n            // evaluate the parameter and push it onto the stack\n            generateAndCastOneParameter( acb, mb, i + firstVarargIdx, cellType );\n            mb.setArrayElement( i ); // move the parameter into the array, pop the stack\n        }\n        \n        // push the array onto the stack. it is the last parameter to the varargs routine.\n        mb.getField( arrayField );\n    }"}
{"idx": 205, "target": 1, "func": "void throwNoMethodFound(String receiverTypeName,\n\t\t\t\t\t\t\t\t\t  String[] parmTypeNames,\n\t\t\t\t\t\t\t\t\t  String[] primParmTypeNames)\n\t\tthrows StandardException\n\t{\n\t\t/* Put the parameter type names into a single string */\n\t\tStringBuffer\tparmTypes = new StringBuffer();\n        boolean hasVarargs = hasVarargs();\n        int     firstVarargIdx = getFirstVarargIdx();\n        int     paramCount = signature.length;\n\t\tfor (int i = 0; i < paramCount; i++)\n\t\t{\n\t\t\tif (i != 0) { parmTypes.append(\", \"); }\n            boolean isVararg = isVararg( i );\n\n\t\t\t/* RESOLVE - shouldn't be using hard coded strings for output */\n            String  parmType = parmTypeNames[ i ];\n            if ( parmTypeNames [i ].length() == 0 ) { parmType = \"UNTYPED\"; }\n            else if ( isVararg ) { parmType = getVarargTypeName( parmType ); }\n\n            parmTypes.append( parmType );\n\n\t\t\tif ((primParmTypeNames != null) &&\n\t\t\t\t! primParmTypeNames[i].equals(parmTypeNames[i]))  // has primitive\n            {\n                String  primTypeName = primParmTypeNames[ i ];\n                if ( isVararg ) { primTypeName = getVarargTypeName( primTypeName ); }\n\t\t\t\tparmTypes.append(\"(\" + primTypeName + \")\");\n            }\n\t\t}\n\n\t\tthrow StandardException.newException(SQLState.LANG_NO_METHOD_FOUND, \n\t\t\t\t\t\t\t\t\t\t\t\treceiverTypeName,\n\t\t\t\t\t\t\t\t\t\t\t\tmethodName,\n\t\t\t\t\t\t\t\t\t\t\t \tparmTypes);\n\t}"}
{"idx": 206, "target": 0, "func": "public\tClass[]\tgetMethodParameterClasses() \n\t{ \n\t\tClassInspector ci = getClassFactory().getClassInspector();\n\n\t\tClass[]\tparmTypeClasses = new Class[methodParms.length];\n\t\tfor (int i = 0; i < methodParms.length; i++)\n\t\t{\n\t\t\tString className = methodParameterTypes[i];\n\t\t\ttry\n\t\t\t{\n\t\t\t\tparmTypeClasses[i] = ci.getClass(className);\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException cnfe)\n\t\t\t{\n\t\t\t\t/* We should never get this exception since we verified \n\t\t\t\t * that the classes existed at bind time.  Just return null.\n\t\t\t\t */\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"Unexpected exception\", cnfe);\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t\treturn parmTypeClasses;\n\t}"}
{"idx": 207, "target": 0, "func": "protected void resolveMethodCall\n        (\n         String javaClassName,\n         boolean staticMethod\n         ) \n        throws StandardException\n\t{\n\t\t// only allow direct method calls through routines and internal SQL.\n\t\tif (routineInfo == null && !internalCall)\n\t\t{\n\t\t\t// See if we are being executed in an internal context\n\t\t\tif ((getCompilerContext().getReliability() & CompilerContext.INTERNAL_SQL_ILLEGAL) != 0) {\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_SYNTAX_ERROR,  javaClassName + (staticMethod ? \"::\" : \".\") + methodName);\n\t\t\t}\n\t\t}\n\n\t\tint\t\t\tcount = signature.length;\n\n\t\tClassInspector classInspector = getClassFactory().getClassInspector();\n\n\t\t\n\t\tString[]\t\tparmTypeNames;\n\t\tString[]\t\tprimParmTypeNames = null;\n\t\tboolean[]\t\tisParam = getIsParam();\n\n\t\tboolean hasDynamicResultSets = hasVarargs() ?\n            false :\n            (routineInfo != null) && (count != 0) && (count != methodParms.length);\n\n        /*\n        ** Find the matching method that is public.\n        */\n        int signatureOffset = methodName.indexOf('(');\n        \t\n        // support Java signatures by checking if the method name contains a '('\n        if (signatureOffset != -1) {\n            parmTypeNames = parseValidateSignature(methodName, signatureOffset, hasDynamicResultSets);\n            methodName = methodName.substring(0, signatureOffset);\n            \n            // If the signature is specified then Derby resolves to exactly\n            // that method. Setting this flag to false disables the method\n            // resolution from automatically optionally repeating the last\n            // parameter as needed.\n            hasDynamicResultSets = false;\n        }\n        else\n        {\n            parmTypeNames = getObjectSignature();\n        }\n\n        // the actual type of the trailing Java varargs arg is an array\n        if ( hasVarargs() )\n        {\n            parmTypeNames[ count - 1 ] = parmTypeNames[ count - 1 ] + \"[]\";\n        }\n\n        try\n        {\n            method = classInspector.findPublicMethod\n                (\n                 javaClassName,\n                 methodName,\n                 parmTypeNames,\n                 null,\n                 isParam,\n                 staticMethod,\n                 hasDynamicResultSets,\n                 hasVarargs()\n                 );\n\n            // DB2 LUW does not support Java object types for SMALLINT, INTEGER, BIGINT, REAL, DOUBLE\n            // and these are the only types that can map to a primitive or an object type according\n            // to SQL part 13. So we never have a second chance match.\n            // Also if the DDL specified a signature, then no alternate resolution\n            if (signatureOffset == -1 && routineInfo == null) {\n\n                /* If no match, then retry with combinations of object and\n                 * primitive types.\n                 */\n                if (method == null)\n                {\n                    primParmTypeNames = getPrimitiveSignature(false);\n\n                    method = classInspector.findPublicMethod\n                        (\n                         javaClassName,\n                         methodName,\n                         parmTypeNames,\n                         primParmTypeNames,\n                         isParam,\n                         staticMethod,\n                         hasDynamicResultSets,\n                         hasVarargs()\n                         );\n                }\n            }\n        }\n        catch (ClassNotFoundException e)\n        {\n            /*\n            ** If one of the classes couldn't be found, just act like the\n            ** method couldn't be found.  The error lists all the class names,\n            ** which should give the user enough info to diagnose the problem.\n            */\n            method = null;\n        }\n\t\t/* Throw exception if no matching signature found */\n\t\tif (method == null)\n\t\t{\n\t\t\tthrowNoMethodFound(javaClassName, parmTypeNames, primParmTypeNames);\n\t\t}\n\n\t\tString\ttypeName = classInspector.getType(method);\n\t\tactualMethodReturnType = typeName;\n\n\t\tif (routineInfo == null) {\n\n\t\t\t/* void methods are only okay for CALL Statements */\n\t\t\tif (typeName.equals(\"void\"))\n\t\t\t{\n\t\t\t\tif (!forCallStatement)\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_VOID_METHOD_CALL);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tString promoteName = null;\n\t\t\tTypeDescriptorImpl returnType = (TypeDescriptorImpl) routineInfo.getReturnType();\n\t\t\tString requiredType;\n\t\t\tif (returnType == null)\n\t\t\t{\n\t\t\t\t// must have a void method for a procedure call.\n\t\t\t\trequiredType = \"void\";\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tTypeId returnTypeId = TypeId.getBuiltInTypeId(returnType.getJDBCTypeId());\n\n\t\t\t\tif (\n\t\t\t\t    returnType.isRowMultiSet() &&\n\t\t\t\t    ( routineInfo.getParameterStyle() == RoutineAliasInfo.PS_DERBY_JDBC_RESULT_SET )\n\t\t\t\t)\n\t\t\t\t{\n\t\t\t\t    requiredType = ResultSet.class.getName();\n\t\t\t\t}\n                else if ( returnType.getTypeId().userType() )\n                {\n                    requiredType = ((UserDefinedTypeIdImpl) returnType.getTypeId()).getClassName();\n                }\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t \t\trequiredType = returnTypeId.getCorrespondingJavaTypeName();\n\n\t\t\t\t\tif (!requiredType.equals(typeName)) {\n\t\t\t\t\t\tswitch (returnType.getJDBCTypeId()) {\n\t\t\t\t\t\tcase java.sql.Types.BOOLEAN:\n\t\t\t\t\t\tcase java.sql.Types.SMALLINT:\n\t\t\t\t\t\tcase java.sql.Types.INTEGER:\n\t\t\t\t\t\tcase java.sql.Types.BIGINT:\n\t\t\t\t\t\tcase java.sql.Types.REAL:\n\t\t\t\t\t\tcase java.sql.Types.DOUBLE:\n\t\t\t\t\t\t\tTypeCompiler tc = getTypeCompiler(returnTypeId);\n\t\t\t\t\t\t\trequiredType = tc.getCorrespondingPrimitiveTypeName();\n\t\t\t\t\t\t\tif (!routineInfo.calledOnNullInput() && routineInfo.getParameterCount() != 0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpromoteName = returnTypeId.getCorrespondingJavaTypeName();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            boolean foundCorrectType;\n            if ( ResultSet.class.getName().equals( requiredType )  )\n            {\n                // allow subtypes of ResultSet too\n                try {\n                    Class actualType = classInspector.getClass( typeName );\n\n                    foundCorrectType = ResultSet.class.isAssignableFrom( actualType );\n                }\n                catch (ClassNotFoundException cnfe) { foundCorrectType = false; }\n            }\n            else{ foundCorrectType = requiredType.equals(typeName); }\n\n\t\t\tif (!foundCorrectType)\n\t\t\t{\n\t\t\t\tthrowNoMethodFound(requiredType + \" \" + javaClassName, parmTypeNames, primParmTypeNames);\n\t\t\t}\n\n\t\t\t// for a returns null on null input with a primitive\n\t\t\t// type we need to promote to an object so we can return null.\n\t\t\tif (promoteName != null)\n\t\t\t\ttypeName = promoteName;\n\t\t\t//propogate collation type from RoutineAliasInfo to\n\t\t\t// MethodCallNode DERBY-2972\n                        if (routineInfo.getReturnType() != null)\n                            setCollationType(routineInfo.getReturnType().getCollationType());     \n                }\n\t \tsetJavaTypeName( typeName );\n                \n\t\tmethodParameterTypes = classInspector.getParameterTypes(method);\n\n        String methodParameter = null;\n        \n\t\tfor (int i = 0; i < methodParameterTypes.length; i++)\n\t\t{\n\t\t\tmethodParameter = methodParameterTypes[i];\n\n\t\t\tif (routineInfo != null) {\n\t\t\t\tif (i < routineInfo.getParameterCount()) {\n\t\t\t\t\tint parameterMode = routineInfo.getParameterModes()[ getRoutineArgIdx( i ) ];\n\n\t\t\t\t\tswitch (parameterMode) {\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_IN:\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_IN_OUT:\n\t\t\t\t\t\t// we need to see if the type of the array is\n\t\t\t\t\t\t// primitive, not the array itself.\n\t\t\t\t\t\tmethodParameter = stripOneArrayLevel( methodParameter );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase JDBC30Translation.PARAMETER_MODE_OUT:\n\t\t\t\t\t\t// value is not obtained *from* parameter.\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            //\n            // Strip off the array type if this is a varargs arg. We are only interested in\n            // whether we need to cast to the cell type.\n            //\n            if ( hasVarargs() && (i >= getFirstVarargIdx()) )\n            {\n                methodParameter = stripOneArrayLevel( methodParameter );\n            }\n\n\t\t\tif (ClassInspector.primitiveType(methodParameter))\n            {\n                // varargs may be omitted, so there may not be an invocation argument\n                // corresponding to the vararg\n                if ( i < methodParms.length )\n                {\n                    methodParms[i].castToPrimitive(true);\n                }\n            }\n\t\t}\n\n        // the last routine parameter may have been a varargs. if so,\n        // casting may be needed on the trailing varargs\n        if ( hasVarargs() )\n        {\n            int     firstVarargIdx = getFirstVarargIdx();\n            int     trailingVarargCount = methodParms.length - firstVarargIdx;\n\n            // the first vararg was handled in the preceding loop\n            for ( int i = 1; i < trailingVarargCount; i++ )\n            {\n                if (ClassInspector.primitiveType(methodParameter))\n                {\n                    methodParms[ i + firstVarargIdx ].castToPrimitive(true);\n                }\n            }\n        }\n\n\t\t/* Set type info for any null parameters */\n\t\tif ( someParametersAreNull() )\n\t\t{\n\t\t\tsetNullParameterInfo(methodParameterTypes);\n\t\t}\n\n\n    \n\t\t/* bug 4450 - if the callable statement is ? = call form, generate the metadata\n\t\tinfor for the return parameter. We don't really need that info in order to\n\t\texecute the callable statement. But with jdbc3.0, this information should be\n\t\tmade available for return parameter through ParameterMetaData class.\n\t\tParser sets a flag in compilercontext if ? = call. If the flag is set,\n\t\twe generate the metadata info for the return parameter and reset the flag\n\t\tin the compilercontext for future call statements*/\n\t\tDataTypeDescriptor dts = DataTypeDescriptor.getSQLDataTypeDescriptor(typeName);\n\t\tif (getCompilerContext().getReturnParameterFlag()) {\n\t\t\tgetCompilerContext().getParameterTypes()[0] = dts;\n\t\t}\n    }"}
{"idx": 208, "target": 1, "func": "private int getScale(String operator,\n\t\t\t\t\t\t\tDataTypeDescriptor leftType,\n\t\t\t\t\t\t\tDataTypeDescriptor rightType)\n\t{\n\t\t// Only meaningful for decimal\n\t\tif (getStoredFormatIdFromTypeId() != StoredFormatIds.DECIMAL_TYPE_ID)\n\t\t{\n\t\t\treturn leftType.getScale();\n\t\t}\n\n\t\tlong val;\n\n\t\tlong lscale = (long)leftType.getScale();\n\t\tlong rscale = (long)rightType.getScale();\n\t\tlong lprec = (long)leftType.getPrecision();\n\t\tlong rprec = (long)rightType.getPrecision();\n\n\t\t/*\n\t\t** Retain greatest scale, take sum of left\n\t\t** of decimal\n\t\t*/\n\t\tif (TypeCompiler.TIMES_OP.equals(operator))\n\t\t{\t\n\t\t\tval = lscale + rscale;\n\t\t}\n\t\telse if (TypeCompiler.DIVIDE_OP.equals(operator))\n\t\t{\n\t\t\t/*\n\t\t\t** Take max left scale + right precision - right scale + 1, \n\t\t\t** or 4, whichever is biggest \n\t\t\t*/\n\t\t\tLanguageConnectionContext lcc = (LanguageConnectionContext)\n\t\t\t\t(ContextService.getContext(LanguageConnectionContext.CONTEXT_ID)); \n\n\t\t\t// Scale: 31 - left precision + left scale - right scale\n\t\t\t\tval = Math.max(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE - lprec + lscale - rscale, 0);\n\n\t\t}\n\t\telse if (TypeCompiler.AVG_OP.equals(operator))\n\t\t{\n\t\t\tval = Math.max(Math.max(lscale, rscale),\n\t\t\t\t\t\tNumberDataValue.MIN_DECIMAL_DIVIDE_SCALE);\n\t\t}\n\t\t/*\n\t\t** SUM, -, + all take max(lscale,rscale)\n\t\t*/\n\t\telse\n\t\t{\n\t\t\tval = Math.max(lscale, rscale);\n\t\t}\n\n\t\tif (val > Integer.MAX_VALUE)\n\t\t{\n\t\t\tval = Integer.MAX_VALUE;\n\t\t}\n\t\tval = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE, val);\n\t\treturn (int)val;\n\t}"}
{"idx": 209, "target": 0, "func": "private int getPrecision(String operator,\n\t\t\t\t\t\t\tDataTypeDescriptor leftType,\n\t\t\t\t\t\t\tDataTypeDescriptor rightType)\n\t{\n\t\t// Only meaningful for decimal\n\t\tif (getStoredFormatIdFromTypeId() != StoredFormatIds.DECIMAL_TYPE_ID)\n\t\t{\n\t\t\treturn leftType.getPrecision();\n\t\t}\n\n\t\tlong lscale = (long)leftType.getScale();\n\t\tlong rscale = (long)rightType.getScale();\n\t\tlong lprec = (long)leftType.getPrecision();\n\t\tlong rprec = (long)rightType.getPrecision();\n\t\tlong val;\n\n\t\t/*\n\t\t** Null means datatype merge.  Take the maximum\n\t \t** left of decimal digits plus the scale.\n\t\t*/\n\t\tif (operator == null)\n\t\t{\n\t\t\tval = this.getScale(operator, leftType, rightType) +\n\t\t\t\t\tMath.max(lprec - lscale, rprec - rscale);\n\t\t}\n\t\telse if (operator.equals(TypeCompiler.TIMES_OP))\n\t\t{\n\t\t\tval = lprec + rprec;\n\t\t}\n\t\telse if (operator.equals(TypeCompiler.SUM_OP))\n\t\t{\n\t\t\tval = lprec - lscale + rprec - rscale + \n\t\t\t\t\t\tthis.getScale(operator, leftType, rightType);\n\t\t}\n\t\telse if (operator.equals(TypeCompiler.DIVIDE_OP))\n\t\t{\n\t\t\tval = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE,\n\t\t\t\t\t\t   this.getScale(operator, leftType, rightType) + lprec - lscale + rprec);\n\t\t}\n\t\t/*\n\t\t** AVG, -, +\n\t\t*/\n\t\telse\n\t\t{\n\t\t\t/*\n\t\t\t** Take max scale and max left of decimal\n\t\t\t** plus one.\n\t\t\t*/\n\t\t\tval = this.getScale(operator, leftType, rightType) +\n\t\t\t\t\tMath.max(lprec - lscale, rprec - rscale) + 1;\n\n\t\t\tif (val > Limits.DB2_MAX_DECIMAL_PRECISION_SCALE)\n\t\t\t// then, like DB2, just set it to the max possible.\n\t\t\t\tval = Limits.DB2_MAX_DECIMAL_PRECISION_SCALE;\n\t\t}\n\n\t\tif (val > Integer.MAX_VALUE)\n\t\t{\n\t\t\tval = Integer.MAX_VALUE;\n\t\t}\n\t\tval = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE, val);\n\t\treturn (int)val;\n\t}"}
{"idx": 210, "target": 1, "func": "private void ruleBasedCostOptimizable(Optimizable optimizable,\n\t\t\t\t\t\t\t\t\t\t\tTableDescriptor td,\n\t\t\t\t\t\t\t\t\t\t\tConglomerateDescriptor cd,\n\t\t\t\t\t\t\t\t\t\t\tOptimizablePredicateList predList,\n\t\t\t\t\t\t\t\t\t\t\tCostEstimate outerCost)\n\t\t\t\tthrows StandardException\n\t{\n\t\t/* CHOOSE BEST CONGLOMERATE HERE */\n\t\tConglomerateDescriptor\tconglomerateDescriptor = null;\n\t\tConglomerateDescriptor\tbestConglomerateDescriptor = null;\n\t\tAccessPath bestAp = optimizable.getBestAccessPath();\n\t\tint lockMode = optimizable.getCurrentAccessPath().getLockMode();\n\n\n\t\t/*\n\t\t** If the current conglomerate better than the best so far?\n\t\t** The pecking order is:\n\t\t**\t\to  covering index useful for predicates\n\t\t**\t\t\t(if there are predicates)\n\t\t**\t\to  index useful for predicates (if there are predicates)\n\t\t**\t\to  covering index\n\t\t**\t\to  table scan\n\t\t*/\n\n\t\t/*\n\t\t** If there is more than one conglomerate descriptor\n\t\t** choose any index that is potentially useful.\n\t\t*/\n\t\tif (predList != null &&\n\t\t\tpredList.useful(optimizable, cd))\n\t\t{\n\t\t\t/*\n\t\t\t** Do not let a non-covering matching index scan supplant a\n\t\t\t** covering matching index scan.\n\t\t\t*/\n\t\t\tboolean newCoveringIndex = optimizable.isCoveringIndex(cd);\n\t\t\tif ( ( ! bestAp.getCoveringIndexScan()) ||\n\t\t\t    bestAp.getNonMatchingIndexScan() ||\n\t\t\t\tnewCoveringIndex )\n\t\t\t{\n\t\t\t\tbestAp.setCostEstimate(\n\t\t\t\t\testimateTotalCost(\n\t\t\t\t\t\t\t\t\tpredList,\n\t\t\t\t\t\t\t\t\tcd,\n\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\toptimizable\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t);\n\t\t\t\tbestAp.setConglomerateDescriptor(cd);\n\t\t\t\tbestAp.setNonMatchingIndexScan(false);\n\t\t\t\tbestAp.setCoveringIndexScan(newCoveringIndex);\n\n\t\t\t\tbestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());\n\n\t\t\t\toptimizable.rememberJoinStrategyAsBest(bestAp);\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\t/* Remember the \"last\" covering index.\n\t\t * NOTE - Since we don't have costing, we just go for the\n\t\t * last one since that's as good as any\n\t\t */\n\t\tif (optimizable.isCoveringIndex(cd))\n\t\t{\n\t\t\tbestAp.setCostEstimate(\n\t\t\t\t\t\t\t\testimateTotalCost(predList,\n\t\t\t\t\t\t\t\t\t\t\t\t\tcd,\n\t\t\t\t\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\toptimizable)\n\t\t\t\t\t\t\t\t);\n\t\t\tbestAp.setConglomerateDescriptor(cd);\n\t\t\tbestAp.setNonMatchingIndexScan(true);\n\t\t\tbestAp.setCoveringIndexScan(true);\n\n\t\t\tbestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());\n\n\t\t\toptimizable.rememberJoinStrategyAsBest(bestAp);\n\t\t\treturn;\n\t\t}\n\n\t\t/*\n\t\t** If this is the heap, and the best conglomerate so far is a\n\t\t** non-covering, non-matching index scan, pick the heap.\n\t\t*/\n\t\tif ( ( ! bestAp.getCoveringIndexScan()) &&\n\t\t\t bestAp.getNonMatchingIndexScan() &&\n\t\t\t ( ! cd.isIndex() )\n\t\t   )\n\t\t{\n\t\t\tbestAp.setCostEstimate(\n\t\t\t\t\t\t\t\t\testimateTotalCost(predList,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tcd,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\toptimizable)\n\t\t\t\t\t\t\t\t\t);\n\n\t\t\tbestAp.setConglomerateDescriptor(cd);\n\n\t\t\tbestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());\n\n\t\t\toptimizable.rememberJoinStrategyAsBest(bestAp);\n\n\t\t\t/*\n\t\t\t** No need to set non-matching index scan and covering\n\t\t\t** index scan, as these are already correct.\n\t\t\t*/\n\t\t\treturn;\n\t\t}\n\n\n\t\t/*\n\t\t** If all else fails, and no conglomerate has been picked yet,\n\t\t** pick this one.\n\t\t*/\n\t\tbestConglomerateDescriptor = bestAp.getConglomerateDescriptor();\n\t\tif (bestConglomerateDescriptor == null)\n\t\t{\n\t\t\tbestAp.setCostEstimate(\n\t\t\t\t\t\t\t\t\testimateTotalCost(predList,\n\t\t\t\t\t\t\t\t\t \t\t\t\t\tcd,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\touterCost,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\toptimizable)\n\t\t\t\t\t\t\t\t\t);\n\n\t\t\tbestAp.setConglomerateDescriptor(cd);\n\n\t\t\t/*\n\t\t\t** We have determined above that this index is neither covering\n\t\t\t** nor matching.\n\t\t\t*/\n\t\t\tbestAp.setCoveringIndexScan(false);\n\t\t\tbestAp.setNonMatchingIndexScan(cd.isIndex());\n\n\t\t\tbestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());\n\n\t\t\toptimizable.rememberJoinStrategyAsBest(bestAp);\n\t\t}\n\n\t\treturn;\n\t}"}
{"idx": 211, "target": 1, "func": "boolean isInOrderPrefix(ResultColumnList sourceRCL)\n\t{\n\t\tboolean inOrderPrefix = true;\n\t\tint rclSize = sourceRCL.size();\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (size() > sourceRCL.size())\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"size() (\" + size() + \n\t\t\t\t\t\") expected to be <= sourceRCL.size() (\" +\n\t\t\t\t\tsourceRCL.size() + \")\");\n\t\t\t}\n\t\t}\n\n\t\tint size = size();\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tif (((OrderByColumn) elementAt(index)).getResultColumn() !=\n\t\t\t\t(ResultColumn) sourceRCL.elementAt(index))\n\t\t\t{\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}"}
{"idx": 212, "target": 0, "func": "public void estimateCost(double estimatedInputRows,\n\t\t\t\t\t\t\t\tRowOrdering rowOrdering,\n\t\t\t\t\t\t\t\tCostEstimate resultCost)\n\t\t\t\t\tthrows StandardException\n\t{\n\t\t/*\n\t\t** Do a bunch of set-up the first time: get the SortCostController,\n\t\t** the template row, the ColumnOrdering array, and the estimated\n\t\t** row size.\n\t\t*/\n\t\tif (scc == null)\n\t\t{\n\t\t\tscc = getCompilerContext().getSortCostController();\n\n\t\t\tresultRow =\n\t\t\t\tresultToSort.getResultColumns().buildEmptyRow().getRowArray();\n\t\t\tcolumnOrdering = getColumnOrdering();\n\t\t\testimatedRowSize =\n\t\t\t\t\t\tresultToSort.getResultColumns().getTotalColumnSize();\n\t\t}\n\n\t\tlong inputRows = (long) estimatedInputRows;\n\t\tlong exportRows = inputRows;\n\t\tdouble sortCost;\n\n\t\tsortCost = scc.getSortCost(\n\t\t\t\t\t\t\t\t\t(DataValueDescriptor[]) resultRow,\n\t\t\t\t\t\t\t\t\tcolumnOrdering,\n\t\t\t\t\t\t\t\t\tfalse,\n\t\t\t\t\t\t\t\t\tinputRows,\n\t\t\t\t\t\t\t\t\texportRows,\n\t\t\t\t\t\t\t\t\testimatedRowSize\n\t\t\t\t\t\t\t\t\t);\n\n\t\tresultCost.setCost(sortCost, estimatedInputRows, estimatedInputRows);\n\t}"}
{"idx": 213, "target": 0, "func": "public void generateExpression(ExpressionClassBuilder acb,\n\t\t\t\t\t\t\t\t\t\t\tMethodBuilder mb)\n\t\t\t\t\t\t\t\t\tthrows StandardException\n\t{\n\t\t/* If we were given a specific ValueNode to generate then\n\t\t * just use that.  See, in particular, the preprocess method\n\t\t * of InListOperatorNode.\n\t\t */\n\t\tif (valToGenerate != null)\n\t\t{\n\t\t\tvalToGenerate.generateExpression(acb, mb);\n\t\t\treturn;\n\t\t}\n\n\t\tDataTypeDescriptor dtd = getTypeServices();\n\t\tif ((dtd != null) && dtd.getTypeId().isXMLTypeId()) {\n\t\t// We're a parameter that corresponds to an XML column/target,\n\t\t// which we don't allow.  We throw the error here instead of\n\t\t// in \"bindExpression\" because at the time of bindExpression,\n\t\t// we don't know yet what the type is going to be (only when\n\t\t// the node that points to this parameter calls\n\t\t// \"setType\" do we figure out the type).\n\t\t\tthrow StandardException.newException(\n\t\t\t\tSQLState.LANG_ATTEMPT_TO_BIND_XML);\n\t\t}\n\n        /* Generate the return value */\n\n        mb.pushThis();\n        mb.push(parameterNumber); // arg\n\n        mb.callMethod(VMOpcode.INVOKEVIRTUAL, ClassName.BaseActivation, \"getParameter\",\n                      ClassName.DataValueDescriptor, 1);\n\n\t\t// For some types perform host variable checking\n\t\t// to match DB2/JCC where if a host variable is too\n\t\t// big it is not accepted, regardless of any trailing padding.\n\n\t\tswitch (dtd.getJDBCTypeId()) {\n\t\tcase Types.BINARY:\n\t\tcase Types.VARBINARY:\n\t\tcase Types.LONGVARBINARY:\n\t\tcase Types.BLOB:\n\t\t\tmb.dup();\n\t\t\tmb.push(dtd.getMaximumWidth());\n\t\t\tmb.callMethod(VMOpcode.INVOKEINTERFACE, (String) null, \"checkHostVariable\",\n                      \"void\", 1);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n        /* Cast the result to its specific interface */\n        mb.cast(getTypeCompiler().interfaceName());\n\t}"}
{"idx": 214, "target": 1, "func": "public DataTypeDescriptor bindRowMultiSet( DataTypeDescriptor originalDTD ) throws StandardException\n    {\n        if ( !originalDTD.getCatalogType().isRowMultiSet() ) { return originalDTD; }\n\n        RowMultiSetImpl originalMultiSet = (RowMultiSetImpl) originalDTD.getTypeId().getBaseTypeId();\n        String[] columnNames = originalMultiSet.getColumnNames();\n        TypeDescriptor[] columnTypes = originalMultiSet.getTypes();\n        int columnCount = columnTypes.length;\n\n        for ( int i = 0; i < columnCount; i++ )\n        {\n            columnTypes[ i ] = bindUserCatalogType( columnTypes[ i ] );\n        }\n\n        return originalDTD;\n    }"}
{"idx": 215, "target": 0, "func": "public int compareTo(Object other)\n\t{\n\t\tResultColumn otherResultColumn = (ResultColumn) other;\n\n\t\treturn this.getColumnPosition() - otherResultColumn.getColumnPosition();\n\t}"}
{"idx": 216, "target": 1, "func": "public\tvoid\tpopulate\n\t(\n\t\tTableDescriptor\ttable,\n\t\tint[]\t\t\tcolumnIDs\n\t)\n\t\tthrows StandardException\n\t{\n\t\tif ( columnIDs == null ) { return; }\n\n\t\tint\t\t\t\t\t\tcount = columnIDs.length;\n\t\tTableName\t\t\t\ttableName = makeTableName( table.getSchemaName(), table.getName() );\n\t\tString\t\t\t\t\tcolumnName;\n\t\tint\t\t\t\t\t\tcolumnPosition;\n\t\tResultColumn\t\t\trc;\n\n\t\tfor ( int i = 0; i < count; i++ )\n\t\t{\n\t\t\tcolumnPosition = columnIDs[ i ];\n\t\t\tcolumnName = table.getColumnDescriptor( columnPosition ).getColumnName();\n\n\t\t\trc = makeColumnFromName( columnName );\n\n\t\t\taddResultColumn( rc );\n\t\t}\n\n\t}"}
{"idx": 217, "target": 1, "func": "public void\tsetUnionResultExpression(ResultColumnList otherRCL,\n                                         int tableNumber,\n                                         int level,\n                                         String operatorName)\n\t\tthrows StandardException\n\t{\n\t\tTableName\t\tdummyTN;\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (visibleSize() != otherRCL.visibleSize())\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\t\t\"visibleSize() = (\" +\n\t\t\t\t\t\t\tvisibleSize() +\n\t\t\t\t\t\t\t\") is expected to equal otherRCL.visibleSize (\" +\n\t\t\t\t\t\t\totherRCL.visibleSize() +\n\t\t\t\t\t\t\t\")\");\n\t\t\t}\n\n            // Generated grouping columns and unselected ORDER BY columns\n            // should have been removed for the RCL of a SetOperatorNode, so\n            // that size and visible size are equal (DERBY-3764).\n            SanityManager.ASSERT(size() == visibleSize(),\n                                 \"size() and visibleSize() should be equal\");\n\t\t}\n\n\t\t/* Make a dummy TableName to be shared by all new CRs */\n\t\tdummyTN = (TableName) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.TABLE_NAME,\n\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\n\t\tContextManager cm = getContextManager();\n\n\t\tint size = visibleSize();\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tboolean\t\t nullableResult;\n\t\t\tColumnReference newCR;\n\t\t\tResultColumn thisRC = (ResultColumn) elementAt(index);\n\t\t\tResultColumn otherRC = (ResultColumn) otherRCL.elementAt(index);\n\t\t\tValueNode\t thisExpr = thisRC.getExpression();\n\t\t\tValueNode\t otherExpr = otherRC.getExpression();\n\n\t\t\t// If there is one row that is not 'autoincrement', the Union should\n\t\t\t// not be 'autoincrement'.\n\t\t\tif (!otherRC.isAutoincrementGenerated() && thisRC.isAutoincrementGenerated())\n\t\t\t{\n\t\t\t\tthisRC.resetAutoincrementGenerated();\n\t\t\t}\n\t\t\t/*\n\t\t\t** If there are ? parameters in the ResultColumnList of a row\n\t\t\t** in a table constructor, their types will not be set.  Just skip\n\t\t\t** these - their types will be set later.  Each ? parameter will\n\t\t\t** get the type of the first non-? in its column, so it can't\n\t\t\t** affect the final dominant type.  It's possible that all the\n\t\t\t** rows for a particular column will have ? parameters - this is\n\t\t\t** an error condition that will be caught later.\n\t\t\t*/\n\t\t\tTypeId thisTypeId = thisExpr.getTypeId();\n\t\t\tif (thisTypeId == null)\n\t\t\t\tcontinue;\n\n\t\t\tTypeId otherTypeId = otherExpr.getTypeId();\n\t\t\tif (otherTypeId == null)\n\t\t\t\tcontinue;\n\n\t\t\t/* \n\t\t\t** Check type compatability.\n\t\t\t*/\n\t\t\tClassFactory cf = getClassFactory();\n\t\t\tif ( !unionCompatible( thisExpr, otherExpr ) )\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_UNION_COMPATIBLE, \n                                                     thisTypeId.getSQLTypeName(),\n                                                     otherTypeId.getSQLTypeName(),\n                                                     operatorName);\n\t\t\t}\n\n\t\t\tDataTypeDescriptor resultType = thisExpr.getTypeServices().getDominantType(\n\t\t\t\t\t\t\t\t\t\t\t\totherExpr.getTypeServices(),\n\t\t\t\t\t\t\t\t\t\t\t\tcf);\n\n\t\t\tnewCR = (ColumnReference) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.COLUMN_REFERENCE,\n\t\t\t\t\t\t\t\t\t\tthisRC.getName(),\n\t\t\t\t\t\t\t\t\t\tdummyTN,\n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\tnewCR.setType(resultType);\n\t\t\t/* Set the tableNumber and nesting levels in newCR.\n\t\t\t * If thisExpr is not a CR, then newCR cannot be\n\t\t\t * correlated, hence source and nesting levels are\n\t\t\t * the same.\n\t\t\t */\n\t\t\tif (thisExpr instanceof ColumnReference)\n\t\t\t{\n\t\t\t\tnewCR.copyFields((ColumnReference) thisExpr);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tnewCR.setNestingLevel(level);\n\t\t\t\tnewCR.setSourceLevel(level);\n\t\t\t}\n\t\t\tnewCR.setTableNumber(tableNumber);\n\t\t\tthisRC.setExpression(newCR);\n\t\t\tthisRC.setType(\n\t\t\t\tthisRC.getTypeServices().getDominantType(\n\t\t\t\t\totherRC.getTypeServices(), cf));\n\n\t\t\t/* DB2 requires both sides of union to have same name for the result to\n\t\t\t * have that name. Otherwise, leave it or set it to a generated name */\n\t\t\tif (thisRC.getName() != null && !thisRC.isNameGenerated() &&\n\t\t\t\totherRC.getName() != null)\n\t\t\t{\n\t\t\t\t/* Result name needs to be changed */\n\t\t\t\tif (otherRC.isNameGenerated())\n\t\t\t\t{\n\t\t\t\t\tthisRC.setName(otherRC.getName());\n\t\t\t\t\tthisRC.setNameGenerated(true);\n\t\t\t\t}\n \t\t\t\telse if (!thisRC.getName().equals(otherRC.getName()))\n\t\t\t\t{\n\t\t\t\t\t/* Both sides have user specified names that don't match */\n\t\t\t\t\tthisRC.setName(null);\n\t\t\t\t\tthisRC.guaranteeColumnName();\n\t\t\t\t\tthisRC.setNameGenerated(true);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 218, "target": 0, "func": "public boolean hasConsistentTypeInfo() throws StandardException\n\t{\n\t\tboolean isConsistent = true;\n\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\tint size = size();\n\t\tfor (int index = 0; index < size; index++)\n\t\t\t{\n\t\t\t\tResultColumn\trc = (ResultColumn) elementAt(index);\n\t\t\t\tValueNode\t \texpr = rc.getExpression();\n\t\t\t\tDataTypeDescriptor rcDTS = rc.getTypeServices();\n\t\t\t\tDataTypeDescriptor exDTS = expr.getTypeServices();\n\n\t\t\t\tif (rcDTS == null || exDTS == null)\n\t\t\t\t{\n\t\t\t\t\tisConsistent = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (rcDTS.getClass().getName() !=\n\t\t\t\t\texDTS.getClass().getName())\n\t\t\t\t{\n\t\t\t\t\tisConsistent = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn isConsistent;\n\t}"}
{"idx": 219, "target": 0, "func": "private void commonCodeForUpdatableByCursor(Vector updateColumns, boolean dealingWithSelectResultColumnList)\n\t{\n\t\t/*\n\t\t** If there is no update column list, or the list is empty, then it means that\n\t\t** all the columns which have a base table associated with them are updatable.\n\t\t*/\n\t\tif ( (updateColumns == null) || (updateColumns.size() == 0) )\n\t\t{\n\t\t\tmarkUpdatableByCursor();\n\t\t}\n\t\telse\n\t\t{\n\t\t\tint\t\t\t\tucSize = updateColumns.size();\n\t\t\tResultColumn\tresultColumn;\n\t\t\tString columnName;\n\n\t\t\tfor (int index = 0; index < ucSize; index++)\n\t\t\t{\n\t\t\t\tcolumnName = (String) updateColumns.get(index);\n\n\t\t\t\tresultColumn = getResultColumn(columnName);\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tif (resultColumn == null && !dealingWithSelectResultColumnList)\n\t\t\t\t\t{\n\t\t\t\t\t\tSanityManager.THROWASSERT(\"No result column found with name \" +\n\t\t\t\t\t\t\tcolumnName);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//Following if means the column specified in FOR UPDATE clause is not\n\t\t\t\t//part of the select list\n\t\t\t\tif (resultColumn == null && dealingWithSelectResultColumnList)\n\t\t\t\t\tcontinue;\n\t\t\t\tresultColumn.markUpdatableByCursor();\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 220, "target": 0, "func": "public int[] getStreamStorableColIds(int heapColCount) throws StandardException\n\t{\n\t\t//@#$\n\t\t//System.out.println(\"getStreamStorableColids\");\n\n\t\tint ssCount = 0;\n\t\tboolean[] isSS = new boolean[heapColCount];//Should be table length.\n\t\tint size = size();\n\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tResultColumn rc = (ResultColumn) elementAt(index);\n\n\t\t\tif (rc.getTypeId().streamStorable())\n\t\t\t{\n                //System.out.println(\"    streamStorable=true\");\n\t\t\t\tColumnDescriptor cd = rc.getTableColumnDescriptor();\n\t\t\t\tisSS[cd.getPosition()-1] = true;\n\t\t\t}\n\t\t}\n\n\t\tfor (int ix=0;ix<isSS.length;ix++) if (isSS[ix]) ssCount++;\n\n\t\tif (ssCount==0)return null;\n\n\t\tint[] result = new int[ssCount];\n\t\tint resultOffset=0;\n\t\tfor (int heapOffset=0;heapOffset<isSS.length;heapOffset++)\n\t\t{\n\t\t\tif (isSS[heapOffset])\n\t\t\t\tresult[resultOffset++]=heapOffset;\n\t\t}\n\n\t\treturn result;\n\t}"}
{"idx": 221, "target": 1, "func": "public\tValueNode\tparseDefault\n\t(\n\t\tString\t\t\t\tdefaultText\n    )\n\t\tthrows StandardException\n\t{\n\t\tParser\t\t\t\t\t\tp;\n\t\tValueNode\t\t\t\t\tdefaultTree;\n\t\tLanguageConnectionContext\tlcc = getLanguageConnectionContext();\n\t\tCompilerContext \t\t\tcompilerContext = getCompilerContext();\n\n\t\t/* Get a Statement to pass to the parser */\n\n\t\t/* We're all set up to parse. We have to build a compilable SQL statement\n\t\t * before we can parse -  So, we goober up a VALUES defaultText.\n\t\t */\n\t\tString values = \"VALUES \" + defaultText;\n\t\t\n\t\t/*\n\t\t** Get a new compiler context, so the parsing of the select statement\n\t\t** doesn't mess up anything in the current context (it could clobber\n\t\t** the ParameterValueSet, for example).\n\t\t*/\n\t\tCompilerContext newCC = lcc.pushCompilerContext();\n\n\t\tp = newCC.getParser();\n\t\t\t\t\n\t\t/* Finally, we can call the parser */\n\t\t// Since this is always nested inside another SQL statement, so topLevel flag\n\t\t// should be false\n\t\tVisitable qt = p.parseStatement(values);\n\t\tif (SanityManager.DEBUG)\n\t\t{\n\t\t\tif (! (qt instanceof CursorNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"qt expected to be instanceof CursorNode, not \" +\n\t\t\t\t\tqt.getClass().getName());\n\t\t\t}\n\t\t\tCursorNode cn = (CursorNode) qt;\n\t\t\tif (! (cn.getResultSetNode() instanceof RowResultSetNode))\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\"cn.getResultSetNode() expected to be instanceof RowResultSetNode, not \" +\n\t\t\t\t\tcn.getResultSetNode().getClass().getName());\n\t\t\t}\n\t\t}\n\n\t\tdefaultTree = ((ResultColumn) \n\t\t\t\t\t\t\t((CursorNode) qt).getResultSetNode().getResultColumns().elementAt(0)).\n\t\t\t\t\t\t\t\t\tgetExpression();\n\n\t\tlcc.popCompilerContext(newCC);\n\n\t\treturn\tdefaultTree;\n\t}"}
{"idx": 222, "target": 1, "func": "public ResultSetNode genProjectRestrict(int origFromListSize)\n\t\t\t\tthrows StandardException\n\t{\n        boolean[] eliminateSort = new boolean[orderByLists.length];\n\n\t\tResultSetNode\t\tprnRSN;\n\n\t\tprnRSN = (ResultSetNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\tC_NodeTypes.PROJECT_RESTRICT_NODE,\n\t\t\t\t\t\t\t\tfromList.elementAt(0),\t/* Child ResultSet */\n\t\t\t\t\t\t\t\tresultColumns,\t\t/* Projection */\n\t\t\t\t\t\t\t\twhereClause,\t\t\t/* Restriction */\n\t\t\t\t\t\t\t\twherePredicates,/* Restriction as PredicateList */\n\t\t\t\t\t\t\t\tselectSubquerys,/* Subquerys in Projection */\n\t\t\t\t\t\t\t\twhereSubquerys,\t/* Subquerys in Restriction */\n\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\tgetContextManager()\t );\n\n\t\t/*\n\t\t** If we have aggregates OR a select list we want\n\t\t** to generate a GroupByNode.  In the case of a\n\t\t** scalar aggregate we have no grouping columns.\n\t\t**\n\t\t** JRESOLVE: what about correlated aggregates from another\n\t\t** block.\n\t\t*/ \n\t\tif (((selectAggregates != null) && (selectAggregates.size() > 0)) \n\t\t\t|| (groupByList != null))\n\t\t{\n\t\t\tVector aggs = selectAggregates;\n\t\t\tif (havingAggregates != null && !havingAggregates.isEmpty()) {\n\t\t\t\thavingAggregates.addAll(selectAggregates);\n\t\t\t\taggs = havingAggregates;\n\t\t\t}\n\t\t\tGroupByNode gbn = (GroupByNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.GROUP_BY_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tprnRSN,\n\t\t\t\t\t\t\t\t\t\t\t\tgroupByList,\n\t\t\t\t\t\t\t\t\t\t\t\taggs,\n\t\t\t\t\t\t\t\t\t\t\t\thavingClause,\n\t\t\t\t\t\t\t\t\t\t\t\thavingSubquerys,\n\t\t\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\t\t\tnew Integer(nestingLevel),\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\tgbn.considerPostOptimizeOptimizations(originalWhereClause != null);\n\t\t\tgbn.assignCostEstimate(optimizer.getOptimizedCost());\n\n\t\t\tgroupByList = null;\n\t\t\tprnRSN  = gbn.getParent();\n\n\t\t\t// Remember whether or not we can eliminate the sort.\n            for (int i=0; i < eliminateSort.length; i++ ) {\n                eliminateSort[i] = eliminateSort[i] || gbn.getIsInSortedOrder();\n            }\n\t\t}\n\n\n\t\tif (windows != null) {\n\n\t\t\t// Now we add a window result set wrapped in a PRN on top of what\n\t\t\t// we currently have.\n\n\t\t\tif (windows.size() > 1) {\n\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\tSQLState.LANG_WINDOW_LIMIT_EXCEEDED);\n\t\t\t}\n\n\t\t\tWindowNode wn = (WindowNode)windows.elementAt(0);\n\n\t\t\tWindowResultSetNode wrsn =\n\t\t\t\t(WindowResultSetNode)getNodeFactory().getNode(\n\t\t\t\t\tC_NodeTypes.WINDOW_RESULTSET_NODE,\n\t\t\t\t\tprnRSN,\n\t\t\t\t\twn,\n\t\t\t\t\twindowFuncCalls,\n\t\t\t\t\tnew Integer(nestingLevel),\n\t\t\t\t\tgetContextManager());\n\n\t\t\tprnRSN = wrsn.getParent();\n\t\t\twrsn.assignCostEstimate(optimizer.getOptimizedCost());\n\t\t}\n\n\n\t\t// if it is distinct, that must also be taken care of.\n\t\tif (isDistinct)\n\t\t{\n\t\t\t// We first verify that a distinct is valid on the\n\t\t\t// RCL.\n\t\t\tresultColumns.verifyAllOrderable();\n\n\t\t\t/* See if we can push duplicate elimination into the store\n\t\t\t * via a hash scan.  This is possible iff:\n\t\t\t *\to  A single table query\n\t\t\t *\to  We haven't merged the order by and distinct sorts.\n\t\t\t *\t   (Results do not have to be in a particular order.)\n\t\t\t *\to  All entries in the select's RCL are ColumnReferences.\n\t\t\t *\to  No predicates (This is because we currently do not\n\t\t\t *\t   differentiate between columns referenced in the select\n\t\t\t *\t   list and columns referenced in other clauses.  In other\n\t\t\t *\t   words, the store will do duplicate elimination based on\n\t\t\t *\t   all referenced columns.)\n\t\t\t *\t   RESOLVE - We can change this to be all referenced columns\n\t\t\t *\t   have to be in the select list.  In that case, we need to\n\t\t\t *\t   refine which predicates are allowed.  Basically, all predicates\n\t\t\t *\t   must have been pushed down to the index/table scan.(If we make\n\t\t\t *\t   this change, then we need to verify that non of the columns in\n\t\t\t *\t   the predicates are correlated columns.)\n\t\t\t *\to  NOTE: The implementation of isPossibleDistinctScan() will return\n\t\t\t *\t   false if there is an IndexRowToBaseRow above the \n\t\t\t *\t   FromBaseTable.  This is because all of a table's columns must come\n\t\t\t *\t   from the same conglomerate in order to get consistent data.\n\t\t\t */\n\t\t\tboolean distinctScanPossible = false;\n\t\t\tif (origFromListSize == 1 && !orderByAndDistinctMerged)\n\t\t\t{\n\t\t\t\tboolean simpleColumns = true;\n\t\t\t\tHashSet distinctColumns = new HashSet();\n\t\t\t\tint size = resultColumns.size();\n\t\t\t\tfor (int i = 1; i <= size; i++) {\n\t\t\t\t\tBaseColumnNode bc = resultColumns.getResultColumn(i).getBaseColumnNode();\n\t\t\t\t\tif (bc == null) {\n\t\t\t\t\t\tsimpleColumns = false;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tdistinctColumns.add(bc);\n\t\t\t\t}\n\t\t\t\tif (simpleColumns && prnRSN.isPossibleDistinctScan(distinctColumns)) {\n\t\t\t\t\tprnRSN.markForDistinctScan();\n\t\t\t\t\tdistinctScanPossible = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!distinctScanPossible)\n\t\t\t{\n\t\t\t\t/* We can't do a distinct scan. Determine if we can filter out \n\t\t\t\t * duplicates without a sorter. \n\t\t\t\t */\n\t\t\t\tboolean inSortedOrder = isOrderedResult(resultColumns, prnRSN, !(orderByAndDistinctMerged));\n\t\t\t\tprnRSN = (ResultSetNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.DISTINCT_NODE,\n\t\t\t\t\t\t\t\t\t\t\tprnRSN,\n\t\t\t\t\t\t\t\t\t\t\tnew Boolean(inSortedOrder),\n\t\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\tprnRSN.costEstimate = costEstimate.cloneMe();\n\n                // Remember whether or not we can eliminate the sort.\n                for (int i=0; i < eliminateSort.length; i++) {\n                    eliminateSort[i] = eliminateSort[i] || inSortedOrder;\n                }\n\t\t\t}\n\t\t}\n\n\t\t/* Generate the OrderByNode if a sort is still required for\n\t\t * the order by.\n\t\t */\n\n        for (int i=0; i < orderByLists.length; i++) {\n            if (orderByLists[i] != null)\n            {\n                if (orderByLists[i].getSortNeeded())\n                {\n                    prnRSN = (ResultSetNode) getNodeFactory().getNode(\n                            C_NodeTypes.ORDER_BY_NODE,\n                            prnRSN,\n                            orderByLists[i],\n                            null,\n                            getContextManager());\n                    prnRSN.costEstimate = costEstimate.cloneMe();\n                }\n\n                // There may be columns added to the select projection list\n                // a query like:\n                // select a, b from t group by a,b order by a+b\n                // the expr a+b is added to the select list.\n                int orderBySelect = this.getResultColumns().getOrderBySelect();\n                if (orderBySelect > 0)\n                {\n                    // Keep the same RCL on top, since there may be references\n                    // to its result columns above us, i.e. in this query:\n                    //\n                    // select sum(j),i from t group by i having i\n                    //             in (select i from t order by j)\n                    //\n                    ResultColumnList topList = prnRSN.getResultColumns();\n                    ResultColumnList newSelectList =\n                        topList.copyListAndObjects();\n                    prnRSN.setResultColumns(newSelectList);\n\n                    topList.removeOrderByColumns();\n                    topList.genVirtualColumnNodes(prnRSN, newSelectList);\n                    prnRSN = (ResultSetNode) getNodeFactory().getNode(\n                            C_NodeTypes.PROJECT_RESTRICT_NODE,\n                            prnRSN,\n                            topList,\n                            null,\n                            null,\n                            null,\n                            null,\n                            null,\n                            getContextManager());\n                }\n            }\n\n            // Do this only after the main ORDER BY; any extra added by\n            // IntersectOrExceptNode should sit on top of us.\n            if (i == 0 && (offset != null || fetchFirst != null)) {\n                // Keep the same RCL on top, since there may be references to\n                // its result columns above us.\n                ResultColumnList topList = prnRSN.getResultColumns();\n                ResultColumnList newSelectList = topList.copyListAndObjects();\n                prnRSN.setResultColumns(newSelectList);\n                topList.genVirtualColumnNodes(prnRSN, newSelectList);\n                prnRSN = (ResultSetNode)getNodeFactory().getNode(\n                        C_NodeTypes.ROW_COUNT_NODE,\n                        prnRSN,\n                        topList,\n                        offset,\n                        fetchFirst,\n                        Boolean.valueOf( hasJDBClimitClause ),\n                        getContextManager());\n            }\n        }\n\n\n\t\tif (wasGroupBy &&\n\t\t\tresultColumns.numGeneratedColumnsForGroupBy() > 0 &&\n\t\t\twindows == null) // windows handling already added a PRN which\n\t\t\t\t\t\t\t // obviates this.\n\t\t{\n\t\t\t// This case takes care of columns generated for group by's which \n\t\t\t// will need to be removed from the final projection. Note that the\n\t\t\t// GroupByNode does remove generated columns but in certain cases\n\t\t\t// we dispense with a group by and replace it with a distinct instead.\n\t\t\t// So in a query like:\n\t\t\t// select c1 from t group by c1, c2\n\t\t\t// we would have added c2 to the projection list which will have to be \n\t\t\t// projected out.\n\t\t\t//\n\n\t\t\t// Keep the same RCL on top, since there may be\n\t\t\t// references to its result columns above us, e.g. in this query:\n\t\t\t//\n\t\t\t// select sum(j),i from t group by i having i\n\t\t\t//             in (select i from t group by i,j )\n\t\t\t//\n\t\t\tResultColumnList topList = prnRSN.getResultColumns();\n\t\t\tResultColumnList newSelectList = topList.copyListAndObjects();\n\t\t\tprnRSN.setResultColumns(newSelectList);\n\n\t\t\ttopList.removeGeneratedGroupingColumns();\n\t\t\ttopList.genVirtualColumnNodes(prnRSN, newSelectList);\n\t\t\tprnRSN = (ResultSetNode) getNodeFactory().getNode(\n\t\t\t\t\t\tC_NodeTypes.PROJECT_RESTRICT_NODE,\n\t\t\t\t\t\tprnRSN,\n\t\t\t\t\t\ttopList,\n\t\t\t\t\t\tnull,\n\t\t\t\t\t\tnull,\n\t\t\t\t\t\tnull,\n\t\t\t\t\t\tnull,\n\t\t\t\t\t\tnull,\n\t\t\t\t\t\tgetContextManager());\n\t\t}\n\n        for (int i=0; i < orderByLists.length; i++) {\n            if (!(orderByLists[i] != null && orderByLists[i].getSortNeeded()) &&\n                orderByQuery)\n            {\n                // Remember whether or not we can eliminate the sort.\n                eliminateSort[i] = true;\n            }\n\n            /* If we were able to eliminate the sort during optimization then\n             * we must tell the underlying tree.  At minimum, this means no\n             * group fetch on an index under an IndexRowToBaseRow since that\n             * that could lead to incorrect results.  (Bug 2347.)\n             */\n            if (eliminateSort[i])\n            {\n                prnRSN.adjustForSortElimination(orderByLists[i]);\n            }\n\n            /* Set the cost of this node in the generated node */\n            prnRSN.costEstimate = costEstimate.cloneMe();\n        }\n\n\t\treturn prnRSN;\n\t}"}
{"idx": 223, "target": 0, "func": "public void bindExpressions(FromList fromListParam)\n\t\t\t\t\tthrows StandardException\n\t{\n\t\tint fromListParamSize = fromListParam.size();\n\t\tint fromListSize = fromList.size();\n\t\tint numDistinctAggs;\n\n\t\tif (SanityManager.DEBUG)\n\t\tSanityManager.ASSERT(fromList != null && resultColumns != null,\n\t\t\t\"Both fromList and resultColumns are expected to be non-null\");\n\n        if (orderByLists[0] != null) {\n            orderByLists[0].pullUpOrderByColumns(this);\n        }\n\n\t\t/* NOTE - a lot of this code would be common to bindTargetExpression(),\n\t\t * so we use a private boolean to share the code instead of duplicating\n\t\t * it.  bindTargetExpression() is responsible for toggling the boolean.\n\t\t */\n\t\tif (! bindTargetListOnly)\n\t\t{\n\t\t\t/* Bind the expressions in FromSubquerys, JoinNodes, etc. */\n\t\t\tfromList.bindExpressions( fromListParam );\n\t\t}\n\n\t\tselectSubquerys = (SubqueryList) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.SUBQUERY_LIST,\n\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\tselectAggregates = new Vector();\n\n\t\t/* Splice our FromList on to the beginning of fromListParam, before binding\n\t\t * the expressions, for correlated column resolution.\n\t\t */\n\t\tfor (int index = 0; index < fromListSize; index++)\n\t\t{\n\t\t\tfromListParam.insertElementAt(fromList.elementAt(index), index);\n\t\t}\n\n\t\t// In preparation for resolving window references in expressions, we\n\t\t// make the FromList carry the set of explicit window definitions.\n\t\t//\n\t\t// E.g. \"select row_number () from r, .. from t window r as ()\"\n\t\t//\n\t\t// Here the expression \"row_number () from r\" needs to be bound to r's\n\t\t// definition. Window functions can also in-line window specifications,\n\t\t// no resolution is necessary. See also\n\t\t// WindowFunctionNode.bindExpression.\n\n\t\tfromListParam.setWindows(windows);\n\n\t\tresultColumns.bindExpressions(fromListParam, \n\t\t\t\t\t\t\t\t\t  selectSubquerys,\n\t\t\t\t\t\t\t\t\t  selectAggregates);\n\n\t\t/* We're done if we're only binding the target list.\n\t\t * (After we restore the fromList, of course.)\n\t\t */\n\t\tif (bindTargetListOnly)\n\t\t{\n\t\t\tfor (int index = 0; index < fromListSize; index++)\n\t\t\t{\n\t\t\t\tfromListParam.removeElementAt(0);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\twhereAggregates = new Vector();\n\t\twhereSubquerys = (SubqueryList) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.SUBQUERY_LIST,\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n        \n        CompilerContext cc = getCompilerContext();\n        \n\t\tif (whereClause != null)\n\t\t{\n\t\t\tcc.pushCurrentPrivType( Authorizer.SELECT_PRIV);\n\n            int previousReliability = orReliability( CompilerContext.WHERE_CLAUSE_RESTRICTION );\n\t\t\twhereClause = whereClause.bindExpression(fromListParam, \n\t\t\t\t\t\t\t\t\t\twhereSubquerys,\n\t\t\t\t\t\t\t\t\t\twhereAggregates);\n            cc.setReliability( previousReliability );\n\t\t\t\n\t\t\t/* RESOLVE - Temporarily disable aggregates in the HAVING clause.\n\t\t\t** (We may remove them in the parser anyway.)\n\t\t\t** RESOLVE - Disable aggregates in the WHERE clause.  Someday\n\t\t\t** Aggregates will be allowed iff they are in a subquery\n\t\t\t** of the having clause and they correlate to an outer\n\t\t\t** query block.  For now, aggregates are not supported\n\t\t\t** in the WHERE clause at all.\n\t\t\t** Note: a similar check is made in JoinNode.\n\t\t\t*/\n\t\t\tif (whereAggregates.size() > 0)\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NO_AGGREGATES_IN_WHERE_CLAUSE);\n\t\t\t}\n\n\t\t\t/* If whereClause is a parameter, (where ?/where -?/where +?), then we should catch it and throw exception\n\t\t\t */\n\t\t\tif (whereClause.isParameterNode())\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_UNTYPED_PARAMETER_IN_WHERE_CLAUSE );\n\t\t\t\n\t\t\twhereClause = whereClause.checkIsBoolean();\n\t\t\tgetCompilerContext().popCurrentPrivType();\n\n\t\t\tcheckNoWindowFunctions(whereClause, \"WHERE\");\n\t\t}\n\n\t\tif (havingClause != null)\n        {\n            int previousReliability = orReliability( CompilerContext.HAVING_CLAUSE_RESTRICTION );\n\n\t\t\thavingAggregates = new Vector();\n\t\t\thavingSubquerys = (SubqueryList) getNodeFactory().getNode(\n\t\t\t\t\tC_NodeTypes.SUBQUERY_LIST,\n\t\t\t\t\tgetContextManager());\n\t\t\thavingClause.bindExpression(\n\t\t\t\t\tfromListParam, havingSubquerys, havingAggregates);\n\t\t\thavingClause = havingClause.checkIsBoolean();\n\t\t\tcheckNoWindowFunctions(havingClause, \"HAVING\");\n            \n            cc.setReliability( previousReliability );\n\t\t}\n\t\t\n\t\t/* Restore fromList */\n\t\tfor (int index = 0; index < fromListSize; index++)\n\t\t{\n\t\t\tfromListParam.removeElementAt(0);\n\t\t}\n\n\t\tif (SanityManager.DEBUG) {\n\t\tSanityManager.ASSERT(fromListParam.size() == fromListParamSize,\n\t\t\t\"fromListParam.size() = \" + fromListParam.size() +\n\t\t\t\", expected to be restored to \" + fromListParamSize);\n\t\tSanityManager.ASSERT(fromList.size() == fromListSize,\n\t\t\t\"fromList.size() = \" + fromList.size() +\n\t\t\t\", expected to be restored to \" + fromListSize);\n\t\t}\n\n\t\t/* If query is grouped, bind the group by list. */\n\t\tif (groupByList != null)\n\t\t{\n\t\t\tVector gbAggregateVector = new Vector();\n\n\t\t\tgroupByList.bindGroupByColumns(this,\n\t\t\t\t\t\t\t\t\t\t   gbAggregateVector);\n\n\t\t\t/*\n\t\t\t** There should be no aggregates in the Group By list.\n\t\t\t** We don't expect any, but just to be on the safe side\n\t\t\t** we will check under sanity.\n\t\t\t*/\n\t\t\tif (SanityManager.DEBUG)\n\t\t\t{\n\t\t\t\tSanityManager.ASSERT(gbAggregateVector.size() == 0,\n\t\t\t\t\t\t\"Unexpected Aggregate vector generated by Group By clause\");\n\t\t\t}\n\n\t\t\tcheckNoWindowFunctions(groupByList, \"GROUP BY\");\n\t\t}\n\t\t/* If ungrouped query with aggregates in SELECT list, verify\n\t\t * that all result columns are valid aggregate expressions -\n\t\t * no column references outside of an aggregate.\n\t\t * If grouped query with aggregates in SELECT list, verify that all\n\t\t * result columns are either grouping expressions or valid\n\t\t * grouped aggregate expressions - the only column references\n\t\t * allowed outside of an aggregate are columns in expressions in \n\t\t * the group by list.\n\t\t */\n\t\tif (groupByList != null || selectAggregates.size() > 0)\n\t\t{\n\n  \t\t\tVerifyAggregateExpressionsVisitor visitor = \n  \t\t\t\tnew VerifyAggregateExpressionsVisitor(groupByList);\n\t\t\tresultColumns.accept(visitor);\n\t\t}       \n\n\t\t/*\n\t\t** RESOLVE: for now, only one distinct aggregate is supported\n\t\t** in the select list.\n\t\t*/\n\t\tnumDistinctAggs = numDistinctAggregates(selectAggregates);\n\t\tif (groupByList == null && numDistinctAggs > 1)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_USER_AGGREGATE_MULTIPLE_DISTINCTS);\n\t\t}\n\n        if (orderByLists[0] != null) {\n            orderByLists[0].bindOrderByColumns(this);\n        }\n\n        bindOffsetFetch(offset, fetchFirst);\n    }"}
{"idx": 224, "target": 1, "func": "int activationKind()\n    {\n        Vector parameterList = getCompilerContext().getParameterList();\n        /*\n        ** We need parameters only for those that have parameters.\n        */\n        if (type == StatementType.SET_ROLE_DYNAMIC) {\n            return StatementNode.NEED_PARAM_ACTIVATION;\n        } else {\n            return StatementNode.NEED_NOTHING_ACTIVATION;\n        }\n    }"}
{"idx": 225, "target": 1, "func": "int activationKind()\n\t{\n\t\tVector parameterList = getCompilerContext().getParameterList();\n\t\t/*\n\t\t** We need parameters \n\t\t** only for those that have parameters.\n\t\t*/\n\t\tif (type == StatementType.SET_SCHEMA_DYNAMIC)\n\t\t{\n\t\t\treturn StatementNode.NEED_PARAM_ACTIVATION;\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn StatementNode.NEED_NOTHING_ACTIVATION;\n\t\t}\n\t}"}
{"idx": 226, "target": 0, "func": "public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,\n\t\t\t\t\t\t\tVector\taggregateVector)\n\t\t\t\t\tthrows StandardException\n\t{\t\tDataTypeDescriptor dtd;\n\t\tint nodeType = getNodeType();\n\t\tswitch (nodeType)\n\t\t{\n\t\tcase C_NodeTypes.USER_NODE:\n\t\tcase C_NodeTypes.CURRENT_USER_NODE:\n\t\tcase C_NodeTypes.SYSTEM_USER_NODE:\n\t\t\tswitch (nodeType)\n\t\t\t{\n\t\t\t\tcase C_NodeTypes.USER_NODE: sqlName = \"USER\"; break;\n\t\t\t\tcase C_NodeTypes.CURRENT_USER_NODE: sqlName = \"CURRENT_USER\"; break;\n\t\t\t\tcase C_NodeTypes.SYSTEM_USER_NODE: sqlName = \"SYSTEM_USER\"; break;\n\t\t\t}\n            methodName = \"getCurrentUserId\";\n\t\t\tmethodType = \"java.lang.String\";\n            \n\t\t\t//SQL spec Section 6.4 Syntax Rule 4 says that the collation type \n\t\t\t//of these functions will be the collation of character set \n\t\t\t//SQL_IDENTIFIER. In Derby's case, that will mean, the collation of\n\t\t\t//these functions will be UCS_BASIC. The collation derivation will \n\t\t\t//be implicit. \n            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;\n\t\t\tbreak;\n\n        case C_NodeTypes.SESSION_USER_NODE:\n            methodName = \"getSessionUserId\";\n            methodType = \"java.lang.String\";\n            sqlName = \"SESSION_USER\";\n            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;\n            break;\n\n\t\tcase C_NodeTypes.CURRENT_SCHEMA_NODE:\n\t\t\tsqlName = \"CURRENT SCHEMA\";\n\t\t\tmethodName = \"getCurrentSchemaName\";\n\t\t\tmethodType = \"java.lang.String\";\n\t\t\t\n\t\t\t//This is a Derby specific function but its collation type will\n\t\t\t//be based on the same rules as for SESSION_USER/CURRENT_USER etc. \n\t\t\t//ie there collation type will be UCS_BASIC. The collation \n\t\t\t//derivation will be implicit. \n            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;\n\t\t\tbreak;\n\n\t\tcase C_NodeTypes.CURRENT_ROLE_NODE:\n\t\t\tsqlName = \"CURRENT_ROLE\";\n\t\t\tmethodName = \"getCurrentRoleIdDelimited\";\n\t\t\tmethodType = \"java.lang.String\";\n\t\t\tdtd = DataTypeDescriptor.getBuiltInDataTypeDescriptor(\n\t\t\t\t// size: 2+(2*128) start and end text quote plus max # of\n\t\t\t\t// escapes\n\t\t\t\tTypes.VARCHAR, true, 2+(2*128)); \n\t\t\t//SQL spec Section 6.4 Syntax Rule 4 says that the collation type\n\t\t\t//of these functions will be the collation of character set\n\t\t\t//SQL_IDENTIFIER. In Derby's case, that will mean, the collation of\n\t\t\t//these functions will be UCS_BASIC. The collation derivation will\n\t\t\t//be implicit. (set by default)\n\t\t\tbreak;\n\n\t\tcase C_NodeTypes.IDENTITY_VAL_NODE:\n\t\t\tsqlName = \"IDENTITY_VAL_LOCAL\";\n\t\t\tmethodName = \"getIdentityValue\";\n\t\t\tmethodType = \"java.lang.Long\";\n\t\t\tdtd = DataTypeDescriptor.getSQLDataTypeDescriptor(\"java.math.BigDecimal\", 31, 0, true, 31);\n\t\t\tbreak;\n\n\t\tcase C_NodeTypes.CURRENT_ISOLATION_NODE:\n\t\t\tsqlName = \"CURRENT ISOLATION\";\n\t\t\tmethodName = \"getCurrentIsolationLevelStr\";\n\t\t\tmethodType = \"java.lang.String\";\n\t\t\tdtd = DataTypeDescriptor.getBuiltInDataTypeDescriptor(Types.CHAR, 2);\n\t\t\t//This is a Derby specific function but it's collation type will\n\t\t\t//be based on the same rules as for SESSION_USER/CURRENT_USER etc. \n\t\t\t//ie there collation type will be UCS_BASIC. The collation \n\t\t\t//derivation will be implicit. (set by default).\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (SanityManager.DEBUG)\n\t\t\t{\n\t\t\t\tSanityManager.THROWASSERT(\"Invalid type for SpecialFunctionNode \" + nodeType);\n\t\t\t}\n\t\t\tdtd = null;\n\t\t\tbreak;\n\t\t}\n\n\t\tcheckReliability(sqlName, CompilerContext.USER_ILLEGAL );\n\t\tsetType(dtd);\n\n\t\treturn this;\n\t}"}
{"idx": 227, "target": 0, "func": "public void generateExpression(ExpressionClassBuilder acb,\n\t\t\t\t\t\t\t\t\t\t\tMethodBuilder mb)\n\t\t\t\t\t\t\t\t\tthrows StandardException\n\t{\n\t\tmb.pushThis();\n\t\tmb.callMethod(VMOpcode.INVOKEINTERFACE, ClassName.Activation, \"getLanguageConnectionContext\",\n\t\t\t\t\t\t\t\t\t\t\t ClassName.LanguageConnectionContext, 0);\n\t\tint argCount = 0;\n\n\t\tif (methodName.equals(\"getCurrentRoleIdDelimited\") ||\n                methodName.equals(\"getCurrentSchemaName\") ||\n                methodName.equals(\"getCurrentUserId\")) {\n\n\t\t\tacb.pushThisAsActivation(mb);\n\t\t\targCount++;\n\t\t}\n\n\t\tmb.callMethod(VMOpcode.INVOKEINTERFACE,\n\t\t\t\t\t  (String) null, methodName, methodType, argCount);\n\n\t\tString fieldType = getTypeCompiler().interfaceName();\n\t\tLocalField field = acb.newFieldDeclaration(Modifier.PRIVATE, fieldType);\n\n\t\tacb.generateDataValue(mb, getTypeCompiler(), \n\t\t\t\tgetTypeServices().getCollationType(), field);\n\t}"}
{"idx": 228, "target": 0, "func": "protected boolean isEquivalent(ValueNode o)\n\t{\n\t\tif (isSameNodeType(o))\n\t\t{\n\t\t\tSpecialFunctionNode other = (SpecialFunctionNode)o;\n\t\t\treturn methodName.equals(other.methodName);\n\t\t}\n\t\treturn false;\n\t}"}
{"idx": 229, "target": 1, "func": "private void changeToCorrespondingExpressionType()\n\t\tthrows StandardException\n\t{\n  \t\tBinaryOperatorNode bcon = null;\n\n  \t\tswitch (subqueryType)\n  \t\t{\n  \t\t\tcase EQ_ANY_SUBQUERY:\n  \t\t\tcase IN_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\t\t\tC_NodeTypes.BINARY_EQUALS_OPERATOR_NODE,\n  \t\t\t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n\n  \t\t\tcase NE_ANY_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\t\tC_NodeTypes.BINARY_NOT_EQUALS_OPERATOR_NODE,\n  \t\t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n\n  \t\t\tcase LE_ANY_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\t\tC_NodeTypes.BINARY_LESS_EQUALS_OPERATOR_NODE,\n  \t\t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n\n  \t\t\tcase LT_ANY_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\tC_NodeTypes.BINARY_LESS_THAN_OPERATOR_NODE,\n  \t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n\n  \t\t\tcase GE_ANY_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\tC_NodeTypes.BINARY_GREATER_EQUALS_OPERATOR_NODE,\n  \t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n\n  \t\t\tcase GT_ANY_SUBQUERY:\n  \t\t\t\tbcon = (BinaryOperatorNode) getNodeFactory().getNode(\n  \t\t\t\t\t\t\t\tC_NodeTypes.BINARY_GREATER_THAN_OPERATOR_NODE,\n  \t\t\t\t\t\t\t\tleftOperand,\n  \t\t\t\t\t\t\t\tthis,\n  \t\t\t\t\t\t\t\tgetContextManager());\n  \t\t\t\tbreak;\n  \t\t}\n\n  \t\t// clean up the state of the tree to reflect a bound expression subquery\n  \t\tsubqueryType = EXPRESSION_SUBQUERY;\n  \t\tsetDataTypeServices(resultSet.getResultColumns());\n\n  \t\tparentComparisonOperator = (BinaryComparisonOperatorNode) bcon;\n  \t\t/* Set type info for the operator node */\n  \t\tparentComparisonOperator.bindComparisonOperator();\n  \t\tleftOperand = null;\n   }"}
{"idx": 230, "target": 1, "func": "private UnaryComparisonOperatorNode pushNewPredicate(\n\t\t\t\tint numTables)\n\t\t\tthrows StandardException\n\t{\n\t\tAndNode\t\t\t\t\t\tandNode;\n\t\tBinaryComparisonOperatorNode bcoNode = null;\n\t\tJBitSet\t\t\t\t\t\ttableMap;\n\t\tPredicate\t\t\t\t\tpredicate;\n\t\tResultColumn\t\t\t\tfirstRC;\n\t\tResultColumnList\t\t\tresultColumns;\n\t\tUnaryComparisonOperatorNode\tucoNode = null;\n\t\tValueNode\t\t\t\t\toldWhereClause;\n\t\tValueNode\t\t\t\t\trightOperand;\n\n\t\t/* We have to ensure that the resultSet immediately under us has\n\t\t * a PredicateList, otherwise we can't push the predicate down.\n\t\t */\n\t\tresultSet = resultSet.ensurePredicateList(numTables);\n\n\t\t/* RESOLVE - once we understand how correlated columns will work, \n\t\t * we probably want to mark leftOperand as a correlated column\n\t\t */\n\t\tresultColumns = resultSet.getResultColumns();\n\n\t\t/*\n\t\t** Create a new PR node.  Put it over the original subquery.  resulSet\n\t\t** is now the new PR.  We give the chance that things under the PR node\n\t\t** can be materialized.  See beetle 4373.\n\t\t*/\n\t\tResultColumnList newRCL = resultColumns.copyListAndObjects();\n\t\tnewRCL.genVirtualColumnNodes(resultSet, resultColumns);\n\t\tresultSet = (ResultSetNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.PROJECT_RESTRICT_NODE,\n\t\t\t\t\t\t\t\t\t\tresultSet,\t// child\n\t\t\t\t\t\t\t\t\t\tnewRCL,\t\t\t// result columns\n\t\t\t\t\t\t\t\t\t\tnull,\t\t\t// restriction\n\t\t\t\t\t\t\t\t\t\tnull, \t\t\t// restriction list\n\t\t\t\t\t\t\t\t\t\tnull,\t\t\t// project subqueries\n\t\t\t\t\t\t\t\t\t\tnull,\t\t\t// restrict subqueries\t\n\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\tresultColumns = newRCL;\n\t\n\t\tfirstRC = (ResultColumn) resultColumns.elementAt(0);\n\t\trightOperand = firstRC.getExpression();\n\n\t\tbcoNode = getNewJoinCondition(leftOperand, rightOperand);\n\n\t\tValueNode andLeft = bcoNode;\n\n\t\t/* For NOT IN or ALL, and if either side of the comparison is nullable, and the\n\t\t * subquery can not be flattened (because of that), we need to add IS NULL node\n\t\t * on top of the nullables, such that the behavior is (beetle 5173):\n\t\t *\n\t\t *    (1) If we have nulls in right operand, no row is returned.\n\t\t *    (2) If subquery result is empty before applying join predicate, every\n\t\t *\t\t  left row (including NULLs) is returned.\n\t\t *\t  (3) Otherwise, return {all left row} - {NULLs}\n\t\t */\n\t\tif (isNOT_IN() || isALL())\n\t\t{\n\t\t\tboolean leftNullable = leftOperand.getTypeServices().isNullable();\n\t\t\tboolean rightNullable = rightOperand.getTypeServices().isNullable();\n\t\t\tif (leftNullable || rightNullable)\n\t\t\t{\n\t\t\t\t/* Create a normalized structure.\n\t\t\t\t */\n\t\t\t\tBooleanConstantNode falseNode = (BooleanConstantNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.BOOLEAN_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tBoolean.FALSE,\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\tOrNode newOr = (OrNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.OR_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tbcoNode,\n\t\t\t\t\t\t\t\t\t\t\t\tfalseNode,\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\tnewOr.postBindFixup();\n\t\t\t\tandLeft = newOr;\n\n\t\t\t\tif (leftNullable)\n\t\t\t\t{\n\t\t\t\t\tUnaryComparisonOperatorNode leftIsNull = (UnaryComparisonOperatorNode)\n\t\t\t\t\t\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.IS_NULL_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tleftOperand,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\tleftIsNull.bindComparisonOperator();\n\t\t\t\t\tnewOr = (OrNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.OR_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\tleftIsNull,\n\t\t\t\t\t\t\t\t\t\t\t\t\tandLeft,\n\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\tnewOr.postBindFixup();\n\t\t\t\t\tandLeft = newOr;\n\t\t\t\t}\n\t\t\t\tif (rightNullable)\n\t\t\t\t{\n\t\t\t\t\tUnaryComparisonOperatorNode rightIsNull = (UnaryComparisonOperatorNode)\n\t\t\t\t\t\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.IS_NULL_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\trightOperand,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\trightIsNull.bindComparisonOperator();\n\t\t\t\t\tnewOr = (OrNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.OR_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\trightIsNull,\n\t\t\t\t\t\t\t\t\t\t\t\t\tandLeft,\n\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\t\tnewOr.postBindFixup();\n\t\t\t\t\tandLeft = newOr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Place an AndNode above the <BinaryComparisonOperator> */\n\t\tandNode = (AndNode) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.AND_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\tandLeft,\n\t\t\t\t\t\t\t\t\t\t\t\t\tgetTrueNode(),\n\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\n\t\t/* Build the referenced table map for the new predicate */\n\t\ttableMap = new JBitSet(numTables);\n\t\tandNode.postBindFixup();\n\n\t\t/* Put the AndNode under a Predicate */\n\t\tpredicate = (Predicate) getNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.PREDICATE,\n\t\t\t\t\t\t\t\t\t\tandNode,\n\t\t\t\t\t\t\t\t\t\ttableMap,\n\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\tpredicate.categorize();\n\n\t\t/* Push the new Predicate to the subquery's list */\n\t\tresultSet = resultSet.addNewPredicate(predicate);\n\n\t\t/* Clean up the leftOperand and subquery ResultColumn */\n\t\tleftOperand = null;\n\t\tfirstRC.setType(getTypeServices());\n\t\tfirstRC.setExpression(getTrueNode());\n\n\t\t/* Add the IS [NOT] NULL above the SubqueryNode */\n\t\tswitch (subqueryType)\n\t\t{\n\t\t\tcase IN_SUBQUERY:\n\t\t\tcase EQ_ANY_SUBQUERY:\n\t\t\tcase NE_ANY_SUBQUERY:\n\t\t\tcase LE_ANY_SUBQUERY:\n\t\t\tcase LT_ANY_SUBQUERY:\n\t\t\tcase GE_ANY_SUBQUERY:\n\t\t\tcase GT_ANY_SUBQUERY:\n\t\t\t\tucoNode = (UnaryComparisonOperatorNode) \n\t\t\t\t\t\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.IS_NOT_NULL_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\tthis,\n\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\tbreak;\n\n\t\t\tcase NOT_IN_SUBQUERY:\n\t\t\tcase EQ_ALL_SUBQUERY:\n\t\t\tcase NE_ALL_SUBQUERY:\n\t\t\tcase LE_ALL_SUBQUERY:\n\t\t\tcase LT_ALL_SUBQUERY:\n\t\t\tcase GE_ALL_SUBQUERY:\n\t\t\tcase GT_ALL_SUBQUERY:\n\t\t\t\tucoNode = (UnaryComparisonOperatorNode) \n\t\t\t\t\t\t\t\t\tgetNodeFactory().getNode(\n\t\t\t\t\t\t\t\t\t\t\t\t\tC_NodeTypes.IS_NULL_NODE,\n\t\t\t\t\t\t\t\t\t\t\t\t\tthis,\n\t\t\t\t\t\t\t\t\t\t\t\t\tgetContextManager());\n\t\t\t\tbreak;\n\t\t}\n\t\tucoNode.bindComparisonOperator();\n\t\treturn ucoNode;\n\t}"}
{"idx": 231, "target": 0, "func": "void genConstraintActions(boolean forCreateTable,\n\t\t\t\tConstraintConstantAction[] conActions,\n\t\t\t\tString tableName,\n\t\t\t\tSchemaDescriptor tableSd,\n\t\t\t\tDataDictionary dd)\n\t\tthrows StandardException\n\t{\n\t\tint size = size();\n\t\tint conActionIndex = 0;\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tString[]\tcolumnNames = null;\n\t\t\tTableElementNode ten = (TableElementNode) elementAt(index);\n\t\t\tIndexConstantAction indexAction = null;\n\n\t\t\tif (! ten.hasConstraint())\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (ten instanceof ColumnDefinitionNode)\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tConstraintDefinitionNode constraintDN = (ConstraintDefinitionNode) ten;\n\n\t\t\tif (constraintDN.getColumnList() != null)\n\t\t\t{\n\t\t\t\tcolumnNames = new String[constraintDN.getColumnList().size()];\n\t\t\t\tconstraintDN.getColumnList().exportNames(columnNames);\n\t\t\t}\n\n\t\t\tint constraintType = constraintDN.getConstraintType();\n\t\t\tString constraintText = constraintDN.getConstraintText();\n\n\t\t\t/*\n\t\t\t** If the constraint is not named (e.g.\n\t\t\t** create table x (x int primary key)), then\n\t\t\t** the constraintSd is the same as the table.\n\t\t\t*/\n\t\t\tString constraintName = constraintDN.getConstraintMoniker();\n\n\t\t\t/* At execution time, we will generate a unique name for the backing\n\t\t\t * index (for CREATE CONSTRAINT) and we will look up the conglomerate\n\t\t\t * name (for DROP CONSTRAINT).\n\t\t\t */\n\t\t\tif (constraintDN.requiresBackingIndex())\n\t\t\t{\n                // implement unique constraints using a unique backing index \n                // unless it is soft upgrade in version before 10.4, or if \n                // constraint contains no nullable columns.  In 10.4 use \n                // \"unique with duplicate null\" backing index for constraints \n                // that contain at least one nullable column.\n\n\t\t\t\tif (constraintDN.constraintType ==\n\t\t\t\t\tDataDictionary.UNIQUE_CONSTRAINT && \n\t\t\t\t\t(dd.checkVersion(\n                         DataDictionary.DD_VERSION_DERBY_10_4, null))) \n                {\n                    boolean contains_nullable_columns = \n                        areColumnsNullable(constraintDN, td);\n\n                    // if all the columns are non nullable, continue to use\n                    // a unique backing index.\n                    boolean unique = \n                        !contains_nullable_columns;\n\n                    // Only use a \"unique with duplicate nulls\" backing index\n                    // for constraints with nullable columns.\n                    boolean uniqueWithDuplicateNulls = \n                        contains_nullable_columns;\n\n\t\t\t\t\tindexAction = genIndexAction(\n\t\t\t\t\t\tforCreateTable,\n\t\t\t\t\t\tunique,\n                        uniqueWithDuplicateNulls,\n\t\t\t\t\t\tnull, constraintDN,\n\t\t\t\t\t\tcolumnNames, true, tableSd, tableName,\n\t\t\t\t\t\tconstraintType, dd);\n\t\t\t\t} \n                else \n                {\n\t\t\t\t\tindexAction = genIndexAction(\n\t\t\t\t\t\tforCreateTable,\n\t\t\t\t\t\tconstraintDN.requiresUniqueIndex(), false,\n\t\t\t\t\t\tnull, constraintDN,\n\t\t\t\t\t\tcolumnNames, true, tableSd, tableName,\n\t\t\t\t\t\tconstraintType, dd);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (constraintType == DataDictionary.DROP_CONSTRAINT)\n\t\t\t{\n                if (SanityManager.DEBUG)\n                {\n                    // Can't drop constraints on a create table.\n                    SanityManager.ASSERT(!forCreateTable);\n                }\n\t\t\t\tconActions[conActionIndex] = \n\t\t\t\t\tgetGenericConstantActionFactory().\n\t\t\t\t\t\tgetDropConstraintConstantAction(\n\t\t\t\t\t\t\t\t\t\t\t\t constraintName, \n\t\t\t\t\t\t\t\t\t\t\t\t constraintDN.getDropSchemaName(), /// FiX\n\t\t\t\t\t\t\t\t\t\t\t\t tableName,\n\t\t\t\t\t\t\t\t\t\t\t\t td.getUUID(),\n\t\t\t\t\t\t\t\t\t\t\t\t tableSd.getSchemaName(),\n\t\t\t\t\t\t\t\t\t\t\t\t indexAction,\n\t\t\t\t\t\t\t\t\t\t\t\t constraintDN.getDropBehavior(),\n                                                 constraintDN.getVerifyType());\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tProviderList apl = constraintDN.getAuxiliaryProviderList();\n\t\t\t\tConstraintInfo refInfo = null;\n\t\t\t\tProviderInfo[]\tproviderInfos = null;\n\n\t\t\t\tif (constraintDN instanceof FKConstraintDefinitionNode)\n\t\t\t\t{\n\t\t\t\t\trefInfo = ((FKConstraintDefinitionNode)constraintDN).getReferencedConstraintInfo();\n\t\t\t\t}\t\t\t\t\n\n\t\t\t\t/* Create the ProviderInfos, if the constraint is dependent on any Providers */\n\t\t\t\tif (apl != null && apl.size() > 0)\n\t\t\t\t{\n\t\t\t\t\t/* Get all the dependencies for the current statement and transfer\n\t\t\t\t\t * them to this view.\n\t\t\t\t\t */\n\t\t\t\t\tDependencyManager dm = dd.getDependencyManager();\n\t\t\t\t\tproviderInfos = dm.getPersistentProviderInfos(apl);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tproviderInfos = new ProviderInfo[0];\n\t\t\t\t\t// System.out.println(\"TABLE ELEMENT LIST EMPTY\");\n\t\t\t\t}\n\n\t\t\t\tconActions[conActionIndex++] = \n\t\t\t\t\tgetGenericConstantActionFactory().\n\t\t\t\t\t\tgetCreateConstraintConstantAction(\n\t\t\t\t\t\t\t\t\t\t\t\t constraintName, \n\t\t\t\t\t\t\t\t\t\t\t     constraintType,\n                                                 forCreateTable,\n\t\t\t\t\t\t\t\t\t\t\t\t tableName, \n\t\t\t\t\t\t\t\t\t\t\t\t ((td != null) ? td.getUUID() : (UUID) null),\n\t\t\t\t\t\t\t\t\t\t\t\t tableSd.getSchemaName(),\n\t\t\t\t\t\t\t\t\t\t\t\t columnNames,\n\t\t\t\t\t\t\t\t\t\t\t\t indexAction,\n\t\t\t\t\t\t\t\t\t\t\t\t constraintText,\n\t\t\t\t\t\t\t\t\t\t\t\t true, \t\t// enabled\n\t\t\t\t\t\t\t\t\t\t\t\t refInfo,\n\t\t\t\t\t\t\t\t\t\t\t\t providerInfos);\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 232, "target": 0, "func": "void validate(DDLStatementNode ddlStmt,\n\t\t\t\t\t     DataDictionary dd,\n\t\t\t\t\t\t TableDescriptor td)\n\t\t\t\t\tthrows StandardException\n\t{\n \t\tthis.td = td;\n\t\tint numAutoCols = 0;\n\n\t\tint\t\t\tsize = size();\n\t\tHashtable\tcolumnHT = new Hashtable(size + 2, (float) .999);\n\t\tHashtable\tconstraintHT = new Hashtable(size + 2, (float) .999);\n\t\t//all the primary key/unique key constraints for this table\n\t\tVector constraintsVector = new Vector();\n\n\t\t//special case for alter table (td is not null in case of alter table)\n\t\tif (td != null)\n\t\t{\n\t\t\t//In case of alter table, get the already existing primary key and unique\n\t\t\t//key constraints for this table. And then we will compare them with  new\n\t\t\t//primary key/unique key constraint column lists.\n\t\t\tConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);\n\t\t\tConstraintDescriptor cd;\n\n\t\t\tif (cdl != null) //table does have some pre-existing constraints defined on it\n\t\t\t{\n\t\t\t\tfor (int i=0; i<cdl.size();i++)\n\t\t\t\t{\n\t\t\t\t\tcd = cdl.elementAt(i);\n\t\t\t\t\t//if the constraint type is not primary key or unique key, ignore it.\n\t\t\t\t\tif (cd.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\t\t\tcd.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)\n\t\t\t\t\t\tconstraintsVector.addElement(cd);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tint tableType = TableDescriptor.BASE_TABLE_TYPE;\n\t\tif (ddlStmt instanceof CreateTableNode)\n\t\t\ttableType = ((CreateTableNode)ddlStmt).tableType;\n\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tTableElementNode tableElement = (TableElementNode) elementAt(index);\n\n\t\t\tif (tableElement instanceof ColumnDefinitionNode)\n\t\t\t{\n\t\t\t\tColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);\n\t\t\t\tif (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE &&\n\t\t\t\t\t(cdn.getType().getTypeId().isLongConcatableTypeId() ||\n\t\t\t\t\tcdn.getType().getTypeId().isUserDefinedTypeId()))\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_LONG_DATA_TYPE_NOT_ALLOWED, cdn.getColumnName());\n\t\t\t\t}\n\t\t\t\tcheckForDuplicateColumns(ddlStmt, columnHT, cdn.getColumnName());\n\t\t\t\tcdn.checkUserType(td);\n\t\t\t\tcdn.bindAndValidateDefault(dd, td);\n\n\t\t\t\tcdn.validateAutoincrement(dd, td, tableType);\n\n\t\t\t\tif (tableElement instanceof ModifyColumnNode)\n\t\t\t\t{\n\t\t\t\t\tModifyColumnNode mcdn = (ModifyColumnNode)cdn;\n\t\t\t\t\tmcdn.checkExistingConstraints(td);\n\t\t\t\t\tmcdn.useExistingCollation(td);\n\n\t\t\t\t} else if (cdn.isAutoincrementColumn())\n                { numAutoCols ++; }\n\t\t\t}\n\t\t\telse if (tableElement.getElementType() == TableElementNode.AT_DROP_COLUMN)\n\t\t\t{\n\t\t\t\tString colName = tableElement.getName();\n\t\t\t\tif (td.getColumnDescriptor(colName) == null)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\t\t\t\t\t\tSQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,\n\t\t\t\t\t\t\t\t\t\t\t\tcolName,\n\t\t\t\t\t\t\t\t\t\t\t\ttd.getQualifiedName());\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* The rest of this method deals with validating constraints */\n\t\t\tif (! (tableElement.hasConstraint()))\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tConstraintDefinitionNode cdn = (ConstraintDefinitionNode) tableElement;\n\n\t\t\tcdn.bind(ddlStmt, dd);\n\n\t\t\t//if constraint is primary key or unique key, add it to the vector\n\t\t\tif (cdn.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\tcdn.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)\n\t\t\t{\n\t\t\t\t/* In case of create table, the vector can have only ConstraintDefinitionNode\n\t\t\t\t* elements. In case of alter table, it can have both ConstraintDefinitionNode\n\t\t\t\t* (for new constraints) and ConstraintDescriptor(for pre-existing constraints).\n\t\t\t\t*/\n\n\t\t\t\tObject destConstraint;\n\t\t\t\tString destName = null;\n\t\t\t\tString[] destColumnNames = null;\n\n\t\t\t\tfor (int i=0; i<constraintsVector.size();i++)\n\t\t\t\t{\n\n\t\t\t\t\tdestConstraint = constraintsVector.elementAt(i);\n\t\t\t\t\tif (destConstraint instanceof ConstraintDefinitionNode)\n\t\t\t\t\t{\n\t\t\t\t\t\tConstraintDefinitionNode destCDN = (ConstraintDefinitionNode)destConstraint;\n\t\t\t\t\t\tdestName = destCDN.getConstraintMoniker();\n\t\t\t\t\t\tdestColumnNames = destCDN.getColumnList().getColumnNames();\n\t\t\t\t\t}\n\t\t\t\t\telse if (destConstraint instanceof ConstraintDescriptor)\n\t\t\t\t\t{\n\t\t\t\t\t\t//will come here only for pre-existing constraints in case of alter table\n\t\t\t\t\t\tConstraintDescriptor destCD = (ConstraintDescriptor)destConstraint;\n\t\t\t\t\t\tdestName = destCD.getConstraintName();\n\t\t\t\t\t\tdestColumnNames = destCD.getColumnDescriptors().getColumnNames();\n\t\t\t\t\t}\n\t\t\t\t\t//check if there are multiple constraints with same set of columns\n\t\t\t\t\tif (columnsMatch(cdn.getColumnList().getColumnNames(), destColumnNames))\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_MULTIPLE_CONSTRAINTS_WITH_SAME_COLUMNS,\n\t\t\t\t\t\tcdn.getConstraintMoniker(), destName);\n\t\t\t\t}\n\t\t\t\tconstraintsVector.addElement(cdn);\n\t\t\t}\n\n\t\t\t/* Make sure that there are no duplicate constraint names in the list */\n            checkForDuplicateConstraintNames(ddlStmt, constraintHT, cdn.getConstraintMoniker());\n\n\t\t\t/* Make sure that the constraint we are trying to drop exists */\n\t\t\tif (cdn.getConstraintType() == DataDictionary.DROP_CONSTRAINT)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t** If no schema descriptor, then must be an invalid\n\t\t\t\t** schema name.\n\t\t\t\t*/\n\n\t\t\t\tString dropConstraintName = cdn.getConstraintMoniker();\n\n\t\t\t\tif (dropConstraintName != null) {\n\n\t\t\t\t\tString dropSchemaName = cdn.getDropSchemaName();\n\n\t\t\t\t\tSchemaDescriptor sd = dropSchemaName == null ? td.getSchemaDescriptor() :\n\t\t\t\t\t\t\t\t\t\t\tgetSchemaDescriptor(dropSchemaName);\n\n\t\t\t\t\tConstraintDescriptor cd =\n\t\t\t\t\t\t\t\tdd.getConstraintDescriptorByName(\n\t\t\t\t\t\t\t\t\t\ttd, sd, dropConstraintName,\n\t\t\t\t\t\t\t\t\t\tfalse);\n\t\t\t\t\tif (cd == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_DROP_NON_EXISTENT_CONSTRAINT,\n\t\t\t\t\t\t\t\t(sd.getSchemaName() + \".\"+ dropConstraintName),\n\t\t\t\t\t\t\t\ttd.getQualifiedName());\n\t\t\t\t\t}\n\t\t\t\t\t/* Statement is dependendent on the ConstraintDescriptor */\n\t\t\t\t\tgetCompilerContext().createDependency(cd);\n\t\t\t\t}\n\t\t\t}\n\n            // validation of primary key nullability moved to validatePrimaryKeyNullability().\n            if (cdn.hasPrimaryKeyConstraint())\n            {\n                // for PRIMARY KEY, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n            }\n            else if (cdn.hasUniqueKeyConstraint())\n            {\n                // for UNIQUE, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n\n                // unique constraints on nullable columns added in 10.4, \n                // disallow until database hard upgraded at least to 10.4.\n                if (!dd.checkVersion(\n                        DataDictionary.DD_VERSION_DERBY_10_4, null))\n                {\n                    checkForNullColumns(cdn, td);\n                }\n            }\n            else if (cdn.hasForeignKeyConstraint())\n            {\n                // for FOREIGN KEY, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n            }\n\t\t}\n\n\t\t/* Can have only one autoincrement column in DB2 mode */\n\t\tif (numAutoCols > 1)\n\t\t\tthrow StandardException.newException(SQLState.LANG_MULTIPLE_AUTOINCREMENT_COLUMNS);\n\n\t}"}
{"idx": 233, "target": 0, "func": "void validate(DDLStatementNode ddlStmt,\n\t\t\t\t\t     DataDictionary dd,\n\t\t\t\t\t\t TableDescriptor td)\n\t\t\t\t\tthrows StandardException\n\t{\n \t\tthis.td = td;\n\t\tint numAutoCols = 0;\n\n\t\tint\t\t\tsize = size();\n\t\tHashtable\tcolumnHT = new Hashtable(size + 2, (float) .999);\n\t\tHashtable\tconstraintHT = new Hashtable(size + 2, (float) .999);\n\t\t//all the primary key/unique key constraints for this table\n\t\tVector constraintsVector = new Vector();\n\n\t\t//special case for alter table (td is not null in case of alter table)\n\t\tif (td != null)\n\t\t{\n\t\t\t//In case of alter table, get the already existing primary key and unique\n\t\t\t//key constraints for this table. And then we will compare them with  new\n\t\t\t//primary key/unique key constraint column lists.\n\t\t\tConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);\n\t\t\tConstraintDescriptor cd;\n\n\t\t\tif (cdl != null) //table does have some pre-existing constraints defined on it\n\t\t\t{\n\t\t\t\tfor (int i=0; i<cdl.size();i++)\n\t\t\t\t{\n\t\t\t\t\tcd = cdl.elementAt(i);\n\t\t\t\t\t//if the constraint type is not primary key or unique key, ignore it.\n\t\t\t\t\tif (cd.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\t\t\tcd.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)\n\t\t\t\t\t\tconstraintsVector.addElement(cd);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tint tableType = TableDescriptor.BASE_TABLE_TYPE;\n\t\tif (ddlStmt instanceof CreateTableNode)\n\t\t\ttableType = ((CreateTableNode)ddlStmt).tableType;\n\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tTableElementNode tableElement = (TableElementNode) elementAt(index);\n\n\t\t\tif (tableElement instanceof ColumnDefinitionNode)\n\t\t\t{\n\t\t\t\tColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);\n\t\t\t\tif (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE &&\n\t\t\t\t\t(cdn.getType().getTypeId().isLongConcatableTypeId() ||\n\t\t\t\t\tcdn.getType().getTypeId().isUserDefinedTypeId()))\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_LONG_DATA_TYPE_NOT_ALLOWED, cdn.getColumnName());\n\t\t\t\t}\n\t\t\t\tcheckForDuplicateColumns(ddlStmt, columnHT, cdn.getColumnName());\n\t\t\t\tcdn.checkUserType(td);\n\t\t\t\tcdn.bindAndValidateDefault(dd, td);\n\n\t\t\t\tcdn.validateAutoincrement(dd, td, tableType);\n\n\t\t\t\tif (tableElement instanceof ModifyColumnNode)\n\t\t\t\t{\n\t\t\t\t\tModifyColumnNode mcdn = (ModifyColumnNode)cdn;\n\t\t\t\t\tmcdn.checkExistingConstraints(td);\n\t\t\t\t\tmcdn.useExistingCollation(td);\n\n\t\t\t\t} else if (cdn.isAutoincrementColumn())\n                { numAutoCols ++; }\n\t\t\t}\n\t\t\telse if (tableElement.getElementType() == TableElementNode.AT_DROP_COLUMN)\n\t\t\t{\n\t\t\t\tString colName = tableElement.getName();\n\t\t\t\tif (td.getColumnDescriptor(colName) == null)\n\t\t\t\t{\n\t\t\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\t\t\t\t\t\tSQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,\n\t\t\t\t\t\t\t\t\t\t\t\tcolName,\n\t\t\t\t\t\t\t\t\t\t\t\ttd.getQualifiedName());\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* The rest of this method deals with validating constraints */\n\t\t\tif (! (tableElement.hasConstraint()))\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tConstraintDefinitionNode cdn = (ConstraintDefinitionNode) tableElement;\n\n\t\t\tcdn.bind(ddlStmt, dd);\n\n\t\t\t//if constraint is primary key or unique key, add it to the vector\n\t\t\tif (cdn.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||\n\t\t\tcdn.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)\n\t\t\t{\n\t\t\t\t/* In case of create table, the vector can have only ConstraintDefinitionNode\n\t\t\t\t* elements. In case of alter table, it can have both ConstraintDefinitionNode\n\t\t\t\t* (for new constraints) and ConstraintDescriptor(for pre-existing constraints).\n\t\t\t\t*/\n\n\t\t\t\tObject destConstraint;\n\t\t\t\tString destName = null;\n\t\t\t\tString[] destColumnNames = null;\n\n\t\t\t\tfor (int i=0; i<constraintsVector.size();i++)\n\t\t\t\t{\n\n\t\t\t\t\tdestConstraint = constraintsVector.elementAt(i);\n\t\t\t\t\tif (destConstraint instanceof ConstraintDefinitionNode)\n\t\t\t\t\t{\n\t\t\t\t\t\tConstraintDefinitionNode destCDN = (ConstraintDefinitionNode)destConstraint;\n\t\t\t\t\t\tdestName = destCDN.getConstraintMoniker();\n\t\t\t\t\t\tdestColumnNames = destCDN.getColumnList().getColumnNames();\n\t\t\t\t\t}\n\t\t\t\t\telse if (destConstraint instanceof ConstraintDescriptor)\n\t\t\t\t\t{\n\t\t\t\t\t\t//will come here only for pre-existing constraints in case of alter table\n\t\t\t\t\t\tConstraintDescriptor destCD = (ConstraintDescriptor)destConstraint;\n\t\t\t\t\t\tdestName = destCD.getConstraintName();\n\t\t\t\t\t\tdestColumnNames = destCD.getColumnDescriptors().getColumnNames();\n\t\t\t\t\t}\n\t\t\t\t\t//check if there are multiple constraints with same set of columns\n\t\t\t\t\tif (columnsMatch(cdn.getColumnList().getColumnNames(), destColumnNames))\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_MULTIPLE_CONSTRAINTS_WITH_SAME_COLUMNS,\n\t\t\t\t\t\tcdn.getConstraintMoniker(), destName);\n\t\t\t\t}\n\t\t\t\tconstraintsVector.addElement(cdn);\n\t\t\t}\n\n\t\t\t/* Make sure that there are no duplicate constraint names in the list */\n            checkForDuplicateConstraintNames(ddlStmt, constraintHT, cdn.getConstraintMoniker());\n\n\t\t\t/* Make sure that the constraint we are trying to drop exists */\n\t\t\tif (cdn.getConstraintType() == DataDictionary.DROP_CONSTRAINT)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t** If no schema descriptor, then must be an invalid\n\t\t\t\t** schema name.\n\t\t\t\t*/\n\n\t\t\t\tString dropConstraintName = cdn.getConstraintMoniker();\n\n\t\t\t\tif (dropConstraintName != null) {\n\n\t\t\t\t\tString dropSchemaName = cdn.getDropSchemaName();\n\n\t\t\t\t\tSchemaDescriptor sd = dropSchemaName == null ? td.getSchemaDescriptor() :\n\t\t\t\t\t\t\t\t\t\t\tgetSchemaDescriptor(dropSchemaName);\n\n\t\t\t\t\tConstraintDescriptor cd =\n\t\t\t\t\t\t\t\tdd.getConstraintDescriptorByName(\n\t\t\t\t\t\t\t\t\t\ttd, sd, dropConstraintName,\n\t\t\t\t\t\t\t\t\t\tfalse);\n\t\t\t\t\tif (cd == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_DROP_NON_EXISTENT_CONSTRAINT,\n\t\t\t\t\t\t\t\t(sd.getSchemaName() + \".\"+ dropConstraintName),\n\t\t\t\t\t\t\t\ttd.getQualifiedName());\n\t\t\t\t\t}\n\t\t\t\t\t/* Statement is dependendent on the ConstraintDescriptor */\n\t\t\t\t\tgetCompilerContext().createDependency(cd);\n\t\t\t\t}\n\t\t\t}\n\n            // validation of primary key nullability moved to validatePrimaryKeyNullability().\n            if (cdn.hasPrimaryKeyConstraint())\n            {\n                // for PRIMARY KEY, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n            }\n            else if (cdn.hasUniqueKeyConstraint())\n            {\n                // for UNIQUE, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n\n                // unique constraints on nullable columns added in 10.4, \n                // disallow until database hard upgraded at least to 10.4.\n                if (!dd.checkVersion(\n                        DataDictionary.DD_VERSION_DERBY_10_4, null))\n                {\n                    checkForNullColumns(cdn, td);\n                }\n            }\n            else if (cdn.hasForeignKeyConstraint())\n            {\n                // for FOREIGN KEY, check that columns are unique\n                verifyUniqueColumnList(ddlStmt, cdn);\n            }\n\t\t}\n\n\t\t/* Can have only one autoincrement column in DB2 mode */\n\t\tif (numAutoCols > 1)\n\t\t\tthrow StandardException.newException(SQLState.LANG_MULTIPLE_AUTOINCREMENT_COLUMNS);\n\n\t}"}
{"idx": 234, "target": 1, "func": "void setCollationTypesOnCharacterStringColumns(SchemaDescriptor sd)\n        throws StandardException\n    {\n\t\tint\t\t\tsize = size();\n\t\tint collationType = sd.getCollationType();\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tTableElementNode tableElement = (TableElementNode) elementAt(index);\n\n\t\t\tif (tableElement instanceof ColumnDefinitionNode)\n\t\t\t{\n\t\t\t\tColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);\n\n                setCollationTypeOnCharacterStringColumn( sd, cdn );\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 235, "target": 0, "func": "static TypeCompiler staticGetTypeCompiler(TypeId typeId)\n        {\n                String sqlTypeName;\n\n                switch (typeId.getJDBCTypeId())\n                {\n                  case Types.BINARY:\n                        return bitTypeCompiler =\n                                        getAnInstance(PACKAGE_NAME + \"BitTypeCompiler\",\n                                                                        bitTypeCompiler,\n                                                                        typeId);\n\n                  case Types.BIT:\n                  case Types.BOOLEAN:\n                        return booleanTypeCompiler =\n                                        getAnInstance(PACKAGE_NAME + \"BooleanTypeCompiler\",\n                                                                booleanTypeCompiler,\n                                                                typeId);\n\n                  case Types.CHAR:\n                          sqlTypeName = typeId.getSQLTypeName();\n                          return charTypeCompiler =\n                              getAnInstance(PACKAGE_NAME + \"CharTypeCompiler\",\n                                                      charTypeCompiler,\n                                                      typeId);\n\n                  case Types.NUMERIC:\n                  case Types.DECIMAL:\n                        return decimalTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                decimalTypeCompiler,\n                                                                typeId);\n\n                  case Types.DOUBLE:\n                        return doubleTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                doubleTypeCompiler,\n                                                                typeId);\n\n                  case Types.INTEGER:\n                        return intTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                intTypeCompiler,\n                                                                typeId);\n\n                  case Types.BIGINT:\n                        return longintTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                longintTypeCompiler,\n                                                                typeId);\n\n                  case Types.BLOB:\n                        return blobTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"LOBTypeCompiler\",\n                                                          blobTypeCompiler,\n                                                          typeId);\n\n                  case Types.LONGVARBINARY:\n                        return longvarbitTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"BitTypeCompiler\",\n                                                          longvarbitTypeCompiler,\n                                                          typeId);\n\n                  case Types.CLOB:\n                      sqlTypeName = typeId.getSQLTypeName();\n                      return clobTypeCompiler =\n                          getAnInstance(PACKAGE_NAME + \"CLOBTypeCompiler\",\n                                        clobTypeCompiler,\n                                        typeId);\n                  case Types.LONGVARCHAR:\n                          sqlTypeName = typeId.getSQLTypeName();\n                          return longvarcharTypeCompiler =\n                              getAnInstance(PACKAGE_NAME + \"CharTypeCompiler\",\n                                                      longvarcharTypeCompiler,\n                                                      typeId);\n\n                  case Types.REAL:\n                        return realTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                realTypeCompiler,\n                                                                typeId);\n\n                  case Types.SMALLINT:\n                        return smallintTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                smallintTypeCompiler,\n                                                                typeId);\n\n                  case Types.TINYINT:\n                    return tinyintTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"NumericTypeCompiler\",\n                                                                tinyintTypeCompiler,\n                                                                typeId);\n\n                  case Types.DATE:\n                        return dateTypeCompiler =\n                                        getAnInstance(PACKAGE_NAME + \"DateTypeCompiler\",\n                                                                        dateTypeCompiler,\n                                                                        typeId);\n\n                  case Types.TIME:\n                        return timeTypeCompiler =\n                                        getAnInstance(PACKAGE_NAME + \"TimeTypeCompiler\",\n                                                                        timeTypeCompiler,\n                                                                        typeId);\n                  case Types.TIMESTAMP:\n                        return timestampTypeCompiler =\n                                        getAnInstance(PACKAGE_NAME + \"TimestampTypeCompiler\",\n                                                                        timestampTypeCompiler,\n                                                                        typeId);\n                  case Types.VARBINARY:\n                        return varbitTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"BitTypeCompiler\",\n                                                                varbitTypeCompiler,\n                                                                typeId);\n\n                  case Types.VARCHAR:\n                          sqlTypeName = typeId.getSQLTypeName();\n                          return varcharTypeCompiler =\n                              getAnInstance(PACKAGE_NAME + \"CharTypeCompiler\",\n                                                      varcharTypeCompiler,\n                                                      typeId);\n\n                  case Types.JAVA_OBJECT:\n                  case Types.OTHER:\n                        if (typeId.isRefTypeId())\n                        {\n                                return refTypeCompiler = getAnInstance(\n                                                                                        PACKAGE_NAME + \"RefTypeCompiler\",\n                                                                                        refTypeCompiler,\n                                                                                        typeId);\n                        }\n                        else\n                        {\n                                // Cannot re-use instances of user-defined type compilers,\n                                // because they contain the class name\n                                BaseTypeCompiler btc = new UserDefinedTypeCompiler();\n                                btc.setTypeId(typeId);\n                                return btc;\n                        }\n\n                  case JDBC40Translation.SQLXML:\n                        return xmlTypeCompiler =\n                                getAnInstance(PACKAGE_NAME + \"XMLTypeCompiler\",\n                                                                xmlTypeCompiler,\n                                                                typeId);\n\n                }\n\n                if (SanityManager.DEBUG)\n                {\n                        SanityManager.THROWASSERT(\"Unexpected JDBC type id \" +\n                                                                                typeId.getJDBCTypeId() +\n                                                                                \" for typeId of class \" +\n                                                                                typeId.getClass().getName());\n                }\n\n                return null;\n        }"}
{"idx": 236, "target": 1, "func": "public void comparable(ValueNode leftOperand) throws StandardException\n\t{\n\t\tint\t\t\t size = size();\n\t\tTypeId\tleftType;\n\t\tValueNode\t\tvalueNode;\n\n\t\tleftType = leftOperand.getTypeId();\n\n\t\tfor (int index = 0; index < size; index++)\n\t\t{\n\t\t\tvalueNode = (ValueNode) elementAt(index);\n\n\t\t\t/*\n\t\t\t** Can the types be compared to each other?  If not, throw an\n\t\t\t** exception.\n\t\t\t*/\n\t\t\tif (! leftOperand.getTypeServices().comparable(valueNode.getTypeServices(),\n\t\t\t\t\t\t\t\t\tfalse,\n\t\t\t\t\t\t\t\t\tgetClassFactory()))\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_NOT_COMPARABLE, \n\t\t\t\t\t\tleftOperand.getTypeServices().getSQLTypeNameWithCollation(),\n\t\t\t\t\t\tvalueNode.getTypeServices().getSQLTypeNameWithCollation()\n\t\t\t\t\t\t);\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 237, "target": 1, "func": "private void addNewColumns() throws StandardException {\n        /*\n         * Now process all of the window function calls.  Replace every\n         * call with an RC.  We toss out the list of RCs, we need to get\n         * each RC as we process its corresponding window function.\n         */\n        LanguageFactory lf =\n            getLanguageConnectionContext().getLanguageFactory();\n\n        ResultColumnList bottomRCL  = childResult.getResultColumns();\n        ResultColumnList windowingRCL = resultColumns;\n\n        ReplaceWindowFuncCallsWithCRVisitor replaceCallsVisitor =\n            new ReplaceWindowFuncCallsWithCRVisitor(\n                (ResultColumnList) getNodeFactory().getNode(\n                    C_NodeTypes.RESULT_COLUMN_LIST,\n                    getContextManager()),\n                ((FromTable) childResult).getTableNumber(),\n                ResultSetNode.class);\n        parent.getResultColumns().accept(replaceCallsVisitor);\n\n        for (int i=0; i < windowFuncCalls.size(); i++) {\n            WindowFunctionNode winFunc =\n                (WindowFunctionNode)windowFuncCalls.elementAt(i);\n\n            if (SanityManager.DEBUG) {\n                SanityManager.ASSERT(\n                    !(winFunc.getWindow() instanceof WindowReferenceNode),\n                    \"unresolved window-reference: \" +\n                    winFunc.getWindow().getName());\n            }\n\n            WindowDefinitionNode funcWindow =\n                (WindowDefinitionNode)winFunc.getWindow();\n\n            if (funcWindow == wdn) {\n                ResultColumn newRC = (ResultColumn) getNodeFactory().getNode(\n                    C_NodeTypes.RESULT_COLUMN,\n                    \"##winFuncResult\",\n                    winFunc.getNewNullResultExpression(),\n                    getContextManager());\n\n                newRC.markGenerated();\n                newRC.bindResultColumnToExpression();\n                bottomRCL.addElement(newRC);\n                newRC.setVirtualColumnId(bottomRCL.size());\n                int winFuncResultVColId = newRC.getVirtualColumnId();\n\n                /*\n                ** Set the WindowResultSetNode result column to point to this.\n                ** The Windowing Node result was created when we called\n                ** ReplaceWindowFuncCallsWithCRVisitor.\n                */\n                ColumnReference newColumnRef =\n                    (ColumnReference) getNodeFactory().getNode(\n                        C_NodeTypes.COLUMN_REFERENCE,\n                        newRC.getName(),\n                        null,\n                        getContextManager());\n\n                newColumnRef.setSource(newRC);\n                newColumnRef.setNestingLevel(this.getLevel());\n                newColumnRef.setSourceLevel(this.getLevel());\n                newColumnRef.markGeneratedToReplaceWindowFunctionCall();\n\n                ResultColumn tmpRC = (ResultColumn) getNodeFactory().getNode(\n                    C_NodeTypes.RESULT_COLUMN,\n                    newRC.getColumnName(),\n                    newColumnRef,\n                    getContextManager());\n\n                tmpRC.markGenerated();\n                tmpRC.bindResultColumnToExpression();\n                windowingRCL.addElement(tmpRC);\n                tmpRC.setVirtualColumnId(windowingRCL.size());\n\n                /*\n                ** Set the column reference to point to\n                ** this.\n                */\n                newColumnRef = winFunc.getGeneratedRef();\n\n                if (newColumnRef != null) {\n                    newColumnRef.setSource(tmpRC);\n                } // Not generated, meaning it's no longer in use\n            }\n        }\n    }"}
{"idx": 238, "target": 1, "func": "private void addNewPRNode()\n        throws StandardException\n    {\n        /*\n        ** Get the new PR, put above the WindowResultSetNode.\n        */\n        ResultColumnList rclNew = (ResultColumnList)getNodeFactory().\n            getNode(C_NodeTypes.RESULT_COLUMN_LIST,\n                    getContextManager());\n\n        int sz = resultColumns.size();\n        for (int i = 0; i < sz; i++)\n        {\n            ResultColumn rc = (ResultColumn) resultColumns.elementAt(i);\n            if (!rc.isGenerated()) {\n                rclNew.addElement(rc);\n            }\n        }\n\n        // if any columns in the source RCL were generated for an order by\n        // remember it in the new RCL as well. After the sort is done it will\n        // have to be projected out upstream.\n        rclNew.copyOrderBySelect(resultColumns);\n\n        parent = (FromTable) getNodeFactory().getNode(\n                                        C_NodeTypes.PROJECT_RESTRICT_NODE,\n                                        this, // child\n                                        rclNew,\n                                        null, // havingClause,\n                                        null, // restriction list\n                                        null, // project subqueries\n                                        null, // havingSubquerys,\n                                        null, // tableProperties,\n                                        getContextManager());\n\n\n        /*\n         * Reset the bottom RCL to be empty.\n         */\n        childResult.setResultColumns((ResultColumnList)\n                                            getNodeFactory().getNode(\n                                                C_NodeTypes.RESULT_COLUMN_LIST,\n                                                getContextManager()));\n\n        /*\n         * Set the Windowing RCL to be empty\n         */\n        resultColumns = (ResultColumnList) getNodeFactory().getNode(\n                                            C_NodeTypes.RESULT_COLUMN_LIST,\n                                            getContextManager());\n\n\n        // Add all referenced columns in select list to windowing node's RCL\n        // and substitute references in original node to point to the Windowing\n        // result set. (modelled on GroupByNode's action for addUnAggColumns)\n        CollectNodesVisitor getCRVisitor =\n            new CollectNodesVisitor(ColumnReference.class);\n\n        ResultColumnList prcl = parent.getResultColumns();\n\n        parent.getResultColumns().accept(getCRVisitor);\n\n        Vector colRefs = getCRVisitor.getList();\n\n        // Find all unique columns referenced and add those to windowing result\n        // set.\n        Vector uniqueCols = new Vector();\n        for (int i= 0; i< colRefs.size(); i++) {\n            ColumnReference cr = (ColumnReference)colRefs.elementAt(i);\n            if (!colRefAlreadySeen(uniqueCols, cr)) {\n                uniqueCols.add(cr);\n            }\n        }\n\n        // Add all virtual column select list to windowing node's RCL and\n        // substitute references in original node to point to the Windowing\n        // result set. Happens for example when we have a window over a group\n        // by.\n        CollectNodesVisitor getVCVisitor =\n            new CollectNodesVisitor(VirtualColumnNode.class);\n\n        parent.getResultColumns().accept(getVCVisitor);\n        Vector vcs = getVCVisitor.getList();\n\n        // Add any virtual columns to windowing result.\n        for (int i= 0; i< vcs.size(); i++) {\n            uniqueCols.add(vcs.elementAt(i));\n        }\n\n        ResultColumnList bottomRCL  = childResult.getResultColumns();\n        ResultColumnList windowingRCL = resultColumns;\n\n        for (int i= 0; i< uniqueCols.size(); i++) {\n            ValueNode crOrVcn = (ValueNode)uniqueCols.elementAt(i);\n\n            ResultColumn newRC = (ResultColumn) getNodeFactory().getNode(\n                    C_NodeTypes.RESULT_COLUMN,\n                    \"##UnWindowingColumn\",\n                    crOrVcn,\n                    getContextManager());\n\n            // add this result column to the bottom rcl\n            bottomRCL.addElement(newRC);\n            newRC.markGenerated();\n            newRC.bindResultColumnToExpression();\n            newRC.setVirtualColumnId(bottomRCL.size());\n\n            // now add this column to the windowing result column list\n            ResultColumn wRC = (ResultColumn) getNodeFactory().getNode(\n                    C_NodeTypes.RESULT_COLUMN,\n                    \"##UnWindowingColumn\",\n                    crOrVcn,\n                    getContextManager());\n            windowingRCL.addElement(wRC);\n            wRC.markGenerated();\n            wRC.bindResultColumnToExpression();\n            wRC.setVirtualColumnId(windowingRCL.size());\n\n            /*\n             ** Reset the original node to point to the\n             ** Windowing result set.\n             */\n            VirtualColumnNode vc = (VirtualColumnNode) getNodeFactory().getNode(\n                    C_NodeTypes.VIRTUAL_COLUMN_NODE,\n                    this, // source result set.\n                    wRC,\n                    new Integer(windowingRCL.size()),\n                    getContextManager());\n\n            SubstituteExpressionVisitor seVis =\n                new SubstituteExpressionVisitor(crOrVcn, vc, null);\n            parent.getResultColumns().accept(seVis);\n        }\n    }"}
{"idx": 239, "target": 0, "func": "public void clearIdentity() {\n\n\t\tif (SanityManager.DEBUG)\n\t\t\tSanityManager.DEBUG(\"StatementCacheInfo\",\"CLEARING IDENTITY: \"+ps.getSource());\n\t\tps.setCacheHolder(null);\n\n\t\tidentity = null;\n\t\tps = null;\n\t}"}
{"idx": 240, "target": 1, "func": "protected SchemaDescriptor initDefaultSchemaDescriptor()\n        throws StandardException {\n        /*\n        ** - If the database supports schemas and a schema with the\n        ** same name as the user's name exists (has been created using\n        ** create schema already) the database will set the users\n        ** default schema to the the schema with the same name as the\n        ** user.\n        ** - Else Set the default schema to APP.\n        */\n        if (cachedInitialDefaultSchemaDescr == null) {\n            DataDictionary dd = getDataDictionary();\n            String authorizationId = getSessionUserId();\n            SchemaDescriptor sd =\n                dd.getSchemaDescriptor(\n                    getSessionUserId(), getTransactionCompile(), false);\n\n            if (sd == null) {\n                sd = new SchemaDescriptor(\n                    dd,\n                    getSessionUserId(),\n                    getSessionUserId(),\n                    (UUID) null,\n                    false);\n            }\n\n            cachedInitialDefaultSchemaDescr = sd;\n        }\n        return cachedInitialDefaultSchemaDescr;\n    }"}
{"idx": 241, "target": 0, "func": "public boolean verifyAllHeldResultSetsAreClosed()\n            throws StandardException\n    {\n        boolean seenOpenResultSets = false;\n\n        /* For every activation */\n        for (int i = acts.size() - 1; i >= 0; i--) {\n\n            Activation a = (Activation) acts.get(i);\n\n            if (SanityManager.DEBUG)\n            {\n                SanityManager.ASSERT(a instanceof CursorActivation, \"a is not a CursorActivation\");\n            }\n\n            if (!a.isInUse())\n            {\n                continue;\n            }\n\n            if (!a.getResultSetHoldability())\n            {\n                continue;\n            }\n\n            ResultSet rs = ((CursorActivation) a).getResultSet();\n\n            /* is there an open result set? */\n            if ((rs != null) && !rs.isClosed() && rs.returnsRows())\n            {\n                seenOpenResultSets = true;\n                break;\n            }\n        }\n\n        if (!seenOpenResultSets)\n            return(true);\n\n        // There may be open ResultSet's that are yet to be garbage collected\n        // let's try and force these out rather than throw an error\n        System.gc();\n        System.runFinalization();\n\n\n        /* For every activation */\n        for (int i = acts.size() - 1; i >= 0; i--) {\n                \n            Activation a = (Activation) acts.get(i);\n\n            if (SanityManager.DEBUG)\n            {\n                SanityManager.ASSERT(a instanceof CursorActivation, \"a is not a CursorActivation\");\n            }\n\n            if (!a.isInUse())\n            {\n                continue;\n            }\n\n            if (!a.getResultSetHoldability())\n            {\n                continue;\n            }\n\n            ResultSet rs = ((CursorActivation) a).getResultSet();\n\n            /* is there an open held result set? */\n            if ((rs != null) && !rs.isClosed() && rs.returnsRows())\n            {\n                return(false);\n            }\n        }\n        return(true);\n    }"}
{"idx": 242, "target": 0, "func": "public boolean verifyNoOpenResultSets(PreparedStatement pStmt, Provider provider,\n                                       int action)\n            throws StandardException\n    {\n        /*\n        ** It is not a problem to create an index when there is an open\n        ** result set, since it doesn't invalidate the access path that was\n        ** chosen for the result set.\n        */\n        boolean seenOpenResultSets = false;\n\n        /* For every activation */\n\n        // synchronize on acts as other threads may be closing activations\n        // in this list, thus invalidating the Enumeration\n        for (int i = acts.size() - 1; i >= 0; i--) {\n                \n            Activation a = (Activation) acts.get(i);\n\n            if (!a.isInUse())\n            {\n                continue;\n            }\n            \n            /* for this prepared statement */\n            if (pStmt == a.getPreparedStatement()) {\n                ResultSet rs = a.getResultSet();\n\n                /* is there an open result set? */\n                if (rs != null && ! rs.isClosed())\n                {\n                    if (!rs.returnsRows())\n                        continue;\n                    seenOpenResultSets = true;\n                    break;\n                }\n                \n            }\n        }\n\n        if (!seenOpenResultSets)\n            return false;\n\n        // There may be open ResultSet's that are yet to be garbage collected\n        // let's try and force these out rather than throw an error\n        System.gc();\n        System.runFinalization();\n\n\n        /* For every activation */\n        // synchronize on acts as other threads may be closing activations\n        // in this list, thus invalidating the Enumeration\n        for (int i = acts.size() - 1; i >= 0; i--) {\n                \n            Activation a = (Activation) acts.get(i);\n\n            if (!a.isInUse())\n            {\n                continue;\n            }\n\n            /* for this prepared statement */\n            if (pStmt == a.getPreparedStatement()) {\n                ResultSet rs = a.getResultSet();\n\n                /* is there an open result set? */\n                if (rs != null && ! rs.isClosed())\n                {\n                    if ((provider != null) && rs.returnsRows()) {\n                    DependencyManager dmgr = getDataDictionary().getDependencyManager();\n\n                    throw StandardException.newException(SQLState.LANG_CANT_INVALIDATE_OPEN_RESULT_SET, \n                                    dmgr.getActionString(action), \n                                    provider.getObjectName());\n\n                    }\n                    return true;\n                }\n            }\n        }\n        return false;\n    }"}
{"idx": 243, "target": 0, "func": "public void autoincrementFlushCache(UUID tableUUID)\n        throws StandardException\n    {\n        if (autoincrementCacheHashtable == null)\n            return;\n\n        if (autoincrementHT == null)\n            autoincrementHT = new HashMap();\n\n        DataDictionary dd = getDataDictionary();\n        for (Iterator it = autoincrementCacheHashtable.keySet().iterator();\n             it.hasNext(); )\n        {\n            Object key = it.next();\n            AutoincrementCounter aic = \n                (AutoincrementCounter)autoincrementCacheHashtable.get(key);\n            Long value = aic.getCurrentValue();\n            aic.flushToDisk(getTransactionExecute(), dd, tableUUID);\n            if (value != null)\n            {\n                autoincrementHT.put(key, value);\n            }\n        }\n        autoincrementCacheHashtable.clear();\n    }"}
{"idx": 244, "target": 0, "func": "public boolean validate(String key,\n\t\t\t\t\t\t Serializable value,\n\t\t\t\t\t\t Dictionary p)\n\t\tthrows StandardException {\n\t\tif (value == null)\n\t\t\treturn true;\n\t\telse if (key.equals(Property.DEFAULT_CONNECTION_MODE_PROPERTY))\n\t\t{\n\t\t\tString value_s = (String)value;\n\t\t\tif (value_s != null &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.NO_ACCESS) &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.READ_ONLY_ACCESS) &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.FULL_ACCESS))\n\t\t\t\tthrow StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, key, value_s);\n\n\t\t\treturn true;\n\t\t}\n\t\telse if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY) ||\n\t\t\t\t key.equals(Property.FULL_ACCESS_USERS_PROPERTY))\n\t\t{\n\t\t\tString value_s = (String)value;\n\n\t\t\t/** Parse the new userIdList to verify its syntax. */\n\t\t\tString[] newList_a;\n\t\t\ttry {newList_a = IdUtil.parseIdList(value_s);}\n\t\t\tcatch (StandardException se) {\n                throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, se, key,value_s);\n\t\t\t}\n\n\t\t\t/** Check the new list userIdList for duplicates. */\n\t\t\tString dups = IdUtil.dups(newList_a);\n\t\t\tif (dups != null) throw StandardException.newException(SQLState.AUTH_DUPLICATE_USERS, key,dups);\n\n\t\t\t/** Check for users with both read and full access permission. */\n\t\t\tString[] otherList_a;\n\t\t\tString otherList;\n\t\t\tif (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY))\n\t\t\t\totherList = (String)p.get(Property.FULL_ACCESS_USERS_PROPERTY);\n\t\t\telse\n\t\t\t\totherList = (String)p.get(Property.READ_ONLY_ACCESS_USERS_PROPERTY);\n\t\t\totherList_a = IdUtil.parseIdList(otherList);\n\t\t\tString both = IdUtil.intersect(newList_a,otherList_a);\n\t\t\tif (both != null) throw StandardException.newException(SQLState.AUTH_USER_IN_READ_AND_WRITE_LISTS, both);\n\t\t\t\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}"}
{"idx": 245, "target": 0, "func": "public boolean validate(String key,\n\t\t\t\t\t\t Serializable value,\n\t\t\t\t\t\t Dictionary p)\n\t\tthrows StandardException {\n\t\tif (value == null)\n\t\t\treturn true;\n\t\telse if (key.equals(Property.DEFAULT_CONNECTION_MODE_PROPERTY))\n\t\t{\n\t\t\tString value_s = (String)value;\n\t\t\tif (value_s != null &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.NO_ACCESS) &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.READ_ONLY_ACCESS) &&\n\t\t\t\t!StringUtil.SQLEqualsIgnoreCase(value_s, Property.FULL_ACCESS))\n\t\t\t\tthrow StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, key, value_s);\n\n\t\t\treturn true;\n\t\t}\n\t\telse if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY) ||\n\t\t\t\t key.equals(Property.FULL_ACCESS_USERS_PROPERTY))\n\t\t{\n\t\t\tString value_s = (String)value;\n\n\t\t\t/** Parse the new userIdList to verify its syntax. */\n\t\t\tString[] newList_a;\n\t\t\ttry {newList_a = IdUtil.parseIdList(value_s);}\n\t\t\tcatch (StandardException se) {\n                throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, se, key,value_s);\n\t\t\t}\n\n\t\t\t/** Check the new list userIdList for duplicates. */\n\t\t\tString dups = IdUtil.dups(newList_a);\n\t\t\tif (dups != null) throw StandardException.newException(SQLState.AUTH_DUPLICATE_USERS, key,dups);\n\n\t\t\t/** Check for users with both read and full access permission. */\n\t\t\tString[] otherList_a;\n\t\t\tString otherList;\n\t\t\tif (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY))\n\t\t\t\totherList = (String)p.get(Property.FULL_ACCESS_USERS_PROPERTY);\n\t\t\telse\n\t\t\t\totherList = (String)p.get(Property.READ_ONLY_ACCESS_USERS_PROPERTY);\n\t\t\totherList_a = IdUtil.parseIdList(otherList);\n\t\t\tString both = IdUtil.intersect(newList_a,otherList_a);\n\t\t\tif (both != null) throw StandardException.newException(SQLState.AUTH_USER_IN_READ_AND_WRITE_LISTS, both);\n\t\t\t\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}"}
{"idx": 246, "target": 1, "func": "private void modifyColumnDefault(int ix)\n\t\t\tthrows StandardException\t\t\t\t\t\t \n\t{\n\t\tColumnDescriptor columnDescriptor = \n\t\t\ttd.getColumnDescriptor(columnInfo[ix].name);\n\t\tDataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\t\tint columnPosition = columnDescriptor.getPosition();\n\n\t\t// Clean up after the old default, if non-null\n\t\tif (columnDescriptor.hasNonNullDefault())\n\t\t{\n\t\t\t// Invalidate off of the old default\n\t\t\tDefaultDescriptor defaultDescriptor = new DefaultDescriptor(dd, columnInfo[ix].oldDefaultUUID, \n\t\t\t\t\t\t\t\t\t\t td.getUUID(), columnPosition);\n\n\t\t\n\t\t\tdm.invalidateFor(defaultDescriptor, DependencyManager.MODIFY_COLUMN_DEFAULT, lcc);\n\t\t\n\t\t\t// Drop any dependencies\n\t\t\tdm.clearDependencies(lcc, defaultDescriptor);\n\t\t}\n\n\t\tUUID defaultUUID = columnInfo[ix].newDefaultUUID;\n\n\t\t/* Generate a UUID for the default, if one exists\n\t\t * and there is no default id yet.\n\t\t */\n\t\tif (columnInfo[ix].defaultInfo != null &&\n\t\t\tdefaultUUID == null)\n\t\t{\t\n\t\t\tdefaultUUID = dd.getUUIDFactory().createUUID();\n\t\t}\n\n\t\t/* Get a ColumnDescriptor reflecting the new default */\n\t\tcolumnDescriptor = new ColumnDescriptor(\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].name,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnPosition,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].dataType,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].defaultValue,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].defaultInfo,\n\t\t\t\t\t\t\t\t\t\t\t\t   td,\n\t\t\t\t\t\t\t\t\t\t\t\t   defaultUUID,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].autoincStart,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].autoincInc,\n\t\t\t\t\t\t\t\t\t\t\t\t   columnInfo[ix].autoinc_create_or_modify_Start_Increment\n\t\t\t\t\t\t\t\t\t\t\t\t   );\n\n\t\t// Update the ColumnDescriptor with new default info\n\t\tdd.dropColumnDescriptor(td.getUUID(), columnInfo[ix].name, tc);\n\t\tdd.addDescriptor(columnDescriptor, td,\n\t\t\t\t\t\t DataDictionary.SYSCOLUMNS_CATALOG_NUM, false, tc);\n\t\n\t\tif (columnInfo[ix].action == ColumnInfo.MODIFY_COLUMN_DEFAULT_INCREMENT)\n\t\t{\n\t\t\t// adding an autoincrement default-- calculate the maximum value \n\t\t\t// of the autoincrement column.\n            long maxValue = getColumnMax(td, columnInfo[ix].name,\n                                         columnInfo[ix].autoincInc);\n\t\t\tdd.setAutoincrementValue(tc, td.getUUID(), columnInfo[ix].name,\n\t\t\t\t\t\t\t\t\t maxValue, true);\n\t\t} else if (columnInfo[ix].action == ColumnInfo.MODIFY_COLUMN_DEFAULT_RESTART)\n\t\t{\n\t\t\tdd.setAutoincrementValue(tc, td.getUUID(), columnInfo[ix].name,\n\t\t\t\t\t columnInfo[ix].autoincStart, false);\n\t\t} \n\t\t// else we are simply changing the default value\n\t}"}
{"idx": 247, "target": 1, "func": "public String[] getAutoGeneratedKeysColumnNames()\n\t{\n\t\treturn autoGeneratedKeysColumnNames;\n\t}"}
{"idx": 248, "target": 1, "func": "public int[] getAutoGeneratedKeysColumnIndexes()\n\t{\n\t\treturn autoGeneratedKeysColumnIndexes;\n\t}"}
{"idx": 249, "target": 1, "func": "public void setAutoGeneratedKeysResultsetInfo(int[] columnIndexes, String[] columnNames)\n\t{\n\t\tautoGeneratedKeysResultSetMode = true;\n\t\tautoGeneratedKeysColumnIndexes = columnIndexes;\n\t\tautoGeneratedKeysColumnNames = columnNames;\n\t}"}
{"idx": 250, "target": 1, "func": "public void setAutoGeneratedKeysResultsetInfo(int[] columnIndexes, String[] columnNames)\n\t{\n\t\tautoGeneratedKeysResultSetMode = true;\n\t\tautoGeneratedKeysColumnIndexes = columnIndexes;\n\t\tautoGeneratedKeysColumnNames = columnNames;\n\t}"}
{"idx": 251, "target": 0, "func": "protected final DataValueDescriptor getColumnFromRow(int rsNumber, int colId)\n\t\tthrows StandardException {\n\n        if (row[rsNumber] == null) {\n            /* This actually happens. NoPutResultSetImpl.clearOrderableCache\n             * attempts to prefetch invariant values into a cache. This fails\n             * in some deeply nested joins. See Beetle 4736 and 4880.*/\n\n            /*\n             * Update: DERBY-4798 shows a query for which we get an NPE unless\n             * this escape is in place (once removed by DERBY-3097, but\n             * reintroduced by DERBY-4798 until we understand how we can get\n             * rid of this anomaly). Thus, for now,\n             * OuterJoinTest#testDerby_4798_NPE will provoke an NPE if this\n             * code is removed.\n             */\n            return null;\n        }\n\n        return row[rsNumber].getColumn(colId);\n\t}"}
{"idx": 252, "target": 0, "func": "public Row getCurrentRow(int resultSetNumber)\n\t{\n        return row[resultSetNumber];\n\t}"}
{"idx": 253, "target": 0, "func": "public long[] getCardinality() { return cardinality; }"}
{"idx": 254, "target": 1, "func": "static boolean validateConstraint\n\t(\n\t\tString\t\t\t\t\t\t\tconstraintName,\n\t\tString\t\t\t\t\t\t\tconstraintText,\n\t\tTableDescriptor\t\t\t\t\ttd,\n\t\tLanguageConnectionContext\t\tlcc,\n\t\tboolean\t\t\t\t\t\t\tisCheckConstraint\n\t)\n\t\tthrows StandardException\n\t{\n\t\tStringBuffer checkStmt = new StringBuffer();\n\t\t/* should not use select sum(not(<check-predicate>) ? 1: 0) because\n\t\t * that would generate much more complicated code and may exceed Java\n\t\t * limits if we have a large number of check constraints, beetle 4347\n\t\t */\n\t\tcheckStmt.append(\"SELECT COUNT(*) FROM \");\n\t\tcheckStmt.append(td.getQualifiedName());\n\t\tcheckStmt.append(\" WHERE NOT(\");\n\t\tcheckStmt.append(constraintText);\n\t\tcheckStmt.append(\")\");\n\t\n\t\tResultSet rs = null;\n\t\ttry\n\t\t{\n\t\t\tPreparedStatement ps = lcc.prepareInternalStatement(checkStmt.toString());\n\n            // This is a substatement; for now, we do not set any timeout\n            // for it. We might change this behaviour later, by linking\n            // timeout to its parent statement's timeout settings.\n\t\t\trs = ps.executeSubStatement(lcc, false, 0L);\n\t\t\tExecRow row = rs.getNextRow();\n\t\t\tif (SanityManager.DEBUG)\n\t\t\t{\n\t\t\t\tif (row == null)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"did not get any rows back from query: \"+checkStmt.toString());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tDataValueDescriptor[] rowArray = row.getRowArray();\n\t\t\tNumber value = ((Number)((NumberDataValue)row.getRowArray()[0]).getObject());\n\t\t\t/*\n\t\t\t** Value may be null if there are no rows in the\n\t\t\t** table.\n\t\t\t*/\n\t\t\tif ((value != null) && (value.longValue() != 0))\n\t\t\t{\t\n\t\t\t\t//check constraint violated\n\t\t\t\tif (isCheckConstraint)\n\t\t\t\t\tthrow StandardException.newException(SQLState.LANG_ADD_CHECK_CONSTRAINT_FAILED, \n\t\t\t\t\t\tconstraintName, td.getQualifiedName(), value.toString());\n\t\t\t\t/*\n\t\t\t\t * for not null constraint violations exception will be thrown in caller\n\t\t\t\t * check constraint will not get here since exception is thrown\n\t\t\t\t * above\n\t\t\t\t */\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tfinally\n\t\t{\n\t\t\tif (rs != null)\n\t\t\t{\n\t\t\t\trs.close();\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}"}
{"idx": 255, "target": 1, "func": "public String[] getReferencedColumnNames()\n\t{ return columnNames; }"}
{"idx": 256, "target": 0, "func": "public String toString()\n\t{\n\t\t// Do not put this under SanityManager.DEBUG - it is needed for\n\t\t// error reporting.\n\t\tStringBuffer strbuf = new StringBuffer();\n\t\tstrbuf.append( \"CREATE CONSTRAINT \" + constraintName );\n\t\tstrbuf.append(\"\\n=========================\\n\");\n\n\t\tif (columnNames == null)\n\t\t{\n\t\t\tstrbuf.append(\"columnNames == null\\n\");\n\t\t}\n\t\telse\n\t\t{\n\t\t\tfor (int ix=0; ix < columnNames.length; ix++)\n\t\t\t{\n\t\t\t\tstrbuf.append(\"\\n\\tcol[\"+ix+\"]\"+columnNames[ix].toString());\n\t\t\t}\n\t\t}\n\t\t\n\t\tstrbuf.append(\"\\n\");\n\t\tstrbuf.append(constraintText);\n\t\tstrbuf.append(\"\\n\");\n\t\tif (otherConstraintInfo != null)\n\t\t{\n\t\t\tstrbuf.append(otherConstraintInfo.toString());\n\t\t}\n\t\tstrbuf.append(\"\\n\");\n\t\treturn strbuf.toString();\n\t}"}
{"idx": 257, "target": 0, "func": "public void\texecuteConstantAction( Activation activation )\n\t\t\t\t\t\tthrows StandardException\n\t{\n\t\tTableDescriptor \t\t\ttd;\n\t\tUUID \t\t\t\t\t\ttoid;\n\t\tColumnDescriptor\t\t\tcolumnDescriptor;\n\t\tint[]\t\t\t\t\t\tbaseColumnPositions;\n\t\tIndexRowGenerator\t\t\tindexRowGenerator = null;\n\t\tExecRow[]\t\t\t\t\tbaseRows;\n\t\tExecIndexRow[]\t\t\t\tindexRows;\n\t\tExecRow[]\t\t\t\t\tcompactBaseRows;\n\t\tGroupFetchScanController    scan;\n\t\tRowLocationRetRowSource\t    rowSource;\n\t\tlong\t\t\t\t\t\tsortId;\n\t\tint\t\t\t\t\t\t\tmaxBaseColumnPosition = -1;\n\n\t\tLanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tDependencyManager dm = dd.getDependencyManager();\n\t\tTransactionController tc = lcc.getTransactionExecute();\n\n\t\t/*\n\t\t** Inform the data dictionary that we are about to write to it.\n\t\t** There are several calls to data dictionary \"get\" methods here\n\t\t** that might be done in \"read\" mode in the data dictionary, but\n\t\t** it seemed safer to do this whole operation in \"write\" mode.\n\t\t**\n\t\t** We tell the data dictionary we're done writing at the end of\n\t\t** the transaction.\n\t\t*/\n\t\tdd.startWriting(lcc);\n\n\t\t/*\n\t\t** If the schema descriptor is null, then\n\t\t** we must have just read ourselves in.  \n\t\t** So we will get the corresponding schema\n\t\t** descriptor from the data dictionary.\n\t\t*/\n\t\tSchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;\n\n\n\t\t/* Get the table descriptor. */\n\t\t/* See if we can get the TableDescriptor \n\t\t * from the Activation.  (Will be there\n\t\t * for backing indexes.)\n\t\t */\n\t\ttd = activation.getDDLTableDescriptor();\n\n\t\tif (td == null)\n\t\t{\n\t\t\t/* tableId will be non-null if adding an index to\n\t\t\t * an existing table (as opposed to creating a\n\t\t\t * table with a constraint with a backing index).\n\t\t\t */\n\t\t\tif (tableId != null)\n\t\t\t{\n\t\t\t\ttd = dd.getTableDescriptor(tableId);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\ttd = dd.getTableDescriptor(tableName, sd, tc);\n\t\t\t}\n\t\t}\n\n\t\tif (td == null)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, \n\t\t\t\t\t\tindexName, tableName);\n\t\t}\n\n\t\tif (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, \n\t\t\t\t\t\tindexName, tableName);\n\t\t}\n\n\t\t/* Get a shared table lock on the table. We need to lock table before\n\t\t * invalidate dependents, otherwise, we may interfere with the\n\t\t * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/\n\t\t * docs/language/SolutionsToConcurrencyIssues.txt (point f).\n\t\t */\n\t\tlockTableForDDL(tc, td.getHeapConglomerateId(), false);\n\n\t\t// invalidate any prepared statements that\n\t\t// depended on this table (including this one)\n\t\tif (! forCreateTable)\n\t\t{\n\t\t\tdm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);\n\t\t}\n\n\t\t// Translate the base column names to column positions\n\t\tbaseColumnPositions = new int[columnNames.length];\n\t\tfor (int i = 0; i < columnNames.length; i++)\n\t\t{\n\t\t\t// Look up the column in the data dictionary\n\t\t\tcolumnDescriptor = td.getColumnDescriptor(columnNames[i]);\n\t\t\tif (columnDescriptor == null)\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolumnNames[i],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttableName);\n\t\t\t}\n\n\t\t\tTypeId typeId = columnDescriptor.getType().getTypeId();\n\n\t\t\t// Don't allow a column to be created on a non-orderable type\n\t\t\tClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();\n\t\t\tboolean isIndexable = typeId.orderable(cf);\n\n\t\t\tif (isIndexable && typeId.userType()) {\n\t\t\t\tString userClass = typeId.getCorrespondingJavaTypeName();\n\n\t\t\t\t// Don't allow indexes to be created on classes that\n\t\t\t\t// are loaded from the database. This is because recovery\n\t\t\t\t// won't be able to see the class and it will need it to\n\t\t\t\t// run the compare method.\n\t\t\t\ttry {\n\t\t\t\t\tif (cf.isApplicationClass(cf.loadApplicationClass(userClass)))\n\t\t\t\t\t\tisIndexable = false;\n\t\t\t\t} catch (ClassNotFoundException cnfe) {\n\t\t\t\t\t// shouldn't happen as we just check the class is orderable\n\t\t\t\t\tisIndexable = false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!isIndexable) {\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, \n\t\t\t\t\ttypeId.getSQLTypeName());\n\t\t\t}\n\n\t\t\t// Remember the position in the base table of each column\n\t\t\tbaseColumnPositions[i] = columnDescriptor.getPosition();\n\n\t\t\tif (maxBaseColumnPosition < baseColumnPositions[i])\n\t\t\t\tmaxBaseColumnPosition = baseColumnPositions[i];\n\t\t}\n\n\t\t/* The code below tries to determine if the index that we're about\n\t\t * to create can \"share\" a conglomerate with an existing index.\n\t\t * If so, we will use a single physical conglomerate--namely, the\n\t\t * one that already exists--to support both indexes. I.e. we will\n\t\t * *not* create a new conglomerate as part of this constant action.\n\t\t */ \n\n\t\t// check if we have similar indices already for this table\n\t\tConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();\n\t\tboolean shareExisting = false;\n\t\tfor (int i = 0; i < congDescs.length; i++)\n\t\t{\n\t\t\tConglomerateDescriptor cd = congDescs[i];\n\t\t\tif ( ! cd.isIndex())\n\t\t\t\tcontinue;\n\n\t\t\tif (droppedConglomNum == cd.getConglomerateNumber())\n\t\t\t{\n\t\t\t\t/* We can't share with any conglomerate descriptor\n\t\t\t\t * whose conglomerate number matches the dropped\n\t\t\t\t * conglomerate number, because that descriptor's\n\t\t\t\t * backing conglomerate was dropped, as well.  If\n\t\t\t\t * we're going to share, we have to share with a\n\t\t\t\t * descriptor whose backing physical conglomerate\n\t\t\t\t * is still around.\n\t\t\t\t */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tIndexRowGenerator irg = cd.getIndexDescriptor();\n\t\t\tint[] bcps = irg.baseColumnPositions();\n\t\t\tboolean[] ia = irg.isAscending();\n\t\t\tint j = 0;\n\n\t\t\t/* The conditions which allow an index to share an existing\n\t\t\t * conglomerate are as follows:\n\t\t\t *\n\t\t\t * 1. the set of columns (both key and include columns) and their \n\t\t\t *  order in the index is the same as that of an existing index AND \n\t\t\t *\n\t\t\t * 2. the ordering attributes are the same AND \n\t\t\t *\n\t\t\t * 3. one of the following is true:\n\t\t\t *    a) the existing index is unique, OR\n\t\t\t *    b) the existing index is non-unique with uniqueWhenNotNulls\n\t\t\t *       set to TRUE and the index being created is non-unique, OR\n\t\t\t *    c) both the existing index and the one being created are\n\t\t\t *       non-unique and have uniqueWithDuplicateNulls set to FALSE.\n\t\t\t */ \n\t\t\tboolean possibleShare = (irg.isUnique() || !unique) &&\n\t\t\t    (bcps.length == baseColumnPositions.length);\n\n\t\t\t//check if existing index is non unique and uniqueWithDuplicateNulls\n\t\t\t//is set to true (backing index for unique constraint)\n\t\t\tif (possibleShare && !irg.isUnique ())\n\t\t\t{\n\t\t\t\t/* If the existing index has uniqueWithDuplicateNulls set to\n\t\t\t\t * TRUE it can be shared by other non-unique indexes; otherwise\n\t\t\t\t * the existing non-unique index has uniqueWithDuplicateNulls\n\t\t\t\t * set to FALSE, which means the new non-unique conglomerate\n\t\t\t\t * can only share if it has uniqueWithDuplicateNulls set to\n\t\t\t\t * FALSE, as well.\n\t\t\t\t */\n\t\t\t\tpossibleShare = (irg.isUniqueWithDuplicateNulls() ||\n\t\t\t\t\t\t\t\t! uniqueWithDuplicateNulls);\n\t\t\t}\n\n\t\t\tif (possibleShare && indexType.equals(irg.indexType()))\n\t\t\t{\n\t\t\t\tfor (; j < bcps.length; j++)\n\t\t\t\t{\n\t\t\t\t\tif ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (j == baseColumnPositions.length)\t// share\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Don't allow users to create a duplicate index. Allow if being done internally\n\t\t\t\t * for a constraint\n\t\t\t\t */\n\t\t\t\tif (!isConstraint)\n\t\t\t\t{\n\t\t\t\t\tactivation.addWarning(\n\t\t\t\t\t\t\tStandardException.newWarning(\n\t\t\t\t\t\t\t\tSQLState.LANG_INDEX_DUPLICATE,\n\t\t\t\t\t\t\t\tcd.getConglomerateName()));\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\t/* Sharing indexes share the physical conglomerate\n\t\t\t\t * underneath, so pull the conglomerate number from\n\t\t\t\t * the existing conglomerate descriptor.\n\t\t\t\t */\n\t\t\t\tconglomId = cd.getConglomerateNumber();\n\n\t\t\t\t/* We create a new IndexRowGenerator because certain\n\t\t\t\t * attributes--esp. uniqueness--may be different between\n\t\t\t\t * the index we're creating and the conglomerate that\n\t\t\t\t * already exists.  I.e. even though we're sharing a\n\t\t\t\t * conglomerate, the new index is not necessarily\n\t\t\t\t * identical to the existing conglomerate. We have to\n\t\t\t\t * keep track of that info so that if we later drop\n\t\t\t\t * the shared physical conglomerate, we can figure out\n\t\t\t\t * what this index (the one we're creating now) is\n\t\t\t\t * really supposed to look like.\n\t\t\t\t */\n\t\t\t\tindexRowGenerator =\n\t\t\t\t\tnew IndexRowGenerator(\n\t\t\t\t\t\tindexType, unique, uniqueWithDuplicateNulls,\n\t\t\t\t\t\tbaseColumnPositions,\n\t\t\t\t\t\tisAscending,\n\t\t\t\t\t\tbaseColumnPositions.length);\n\n\t\t\t\t//DERBY-655 and DERBY-1343  \n\t\t\t\t// Sharing indexes will have unique logical conglomerate UUIDs.\n\t\t\t\tconglomerateUUID = dd.getUUIDFactory().createUUID();\n\t\t\t\tshareExisting = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If we have a droppedConglomNum then the index we're about to\n\t\t * \"create\" already exists--i.e. it has an index descriptor and\n\t\t * the corresponding information is already in the system catalogs.\n\t\t * The only thing we're missing, then, is the physical conglomerate\n\t\t * to back the index (because the old conglomerate was dropped).\n\t\t */\n\t\tboolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);\n\n\t\t/* If this index already has an essentially same one, we share the\n\t\t * conglomerate with the old one, and just simply add a descriptor\n\t\t * entry into SYSCONGLOMERATES--unless we already have a descriptor,\n\t\t * in which case we don't even need to do that.\n\t\t */\n\t\tDataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\t\tif (shareExisting && !alreadyHaveConglomDescriptor)\n\t\t{\n\t\t\tConglomerateDescriptor cgd =\n\t\t\t\tddg.newConglomerateDescriptor(conglomId, indexName, true,\n\t\t\t\t\t\t\t\t\t\t  indexRowGenerator, isConstraint,\n\t\t\t\t\t\t\t\t\t\t  conglomerateUUID, td.getUUID(), sd.getUUID() );\n\t\t\tdd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);\n\t\t\t// add newly added conglomerate to the list of conglomerate \n\t\t\t// descriptors in the td.\n\t\t\tConglomerateDescriptorList cdl = \n\t\t\t\ttd.getConglomerateDescriptorList();\n\t\t\tcdl.add(cgd);\n\n\t\t\t// can't just return yet, need to get member \"indexTemplateRow\"\n\t\t\t// because create constraint may use it\n\t\t}\n\n\t\t// Describe the properties of the index to the store using Properties\n\t\t// RESOLVE: The following properties assume a BTREE index.\n\t\tProperties\tindexProperties;\n\t\t\n\t\tif (properties != null)\n\t\t{\n\t\t\tindexProperties = properties;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tindexProperties = new Properties();\n\t\t}\n\n\t\t// Tell it the conglomerate id of the base table\n\t\tindexProperties.put(\"baseConglomerateId\",\n\t\t\t\t\t\t\tLong.toString(td.getHeapConglomerateId()));\n        \n\t\tif (uniqueWithDuplicateNulls) \n        {\n            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))\n            {\n\t\t\t\tindexProperties.put(\n                    \"uniqueWithDuplicateNulls\", Boolean.toString(true));\n\t\t\t}\n\t\t\telse \n            {\n\t\t\t\t// for lower version of DD there is no unique with nulls \n                // index creating a unique index instead.\n\t\t\t\tif (uniqueWithDuplicateNulls) \n                {\n\t\t\t\t\tunique = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// All indexes are unique because they contain the RowLocation.\n\t\t// The number of uniqueness columns must include the RowLocation\n\t\t// if the user did not specify a unique index.\n\t\tindexProperties.put(\"nUniqueColumns\",\n\t\t\t\t\tInteger.toString(unique ? baseColumnPositions.length :\n\t\t\t\t\t\t\t\t\t\t\t\tbaseColumnPositions.length + 1)\n\t\t\t\t\t\t\t);\n\t\t// By convention, the row location column is the last column\n\t\tindexProperties.put(\"rowLocationColumn\",\n\t\t\t\t\t\t\tInteger.toString(baseColumnPositions.length));\n\n\t\t// For now, all columns are key fields, including the RowLocation\n\t\tindexProperties.put(\"nKeyFields\",\n\t\t\t\t\t\t\tInteger.toString(baseColumnPositions.length + 1));\n\n\t\t// For now, assume that all index columns are ordered columns\n\t\tif (! shareExisting)\n\t\t{\n            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))\n            {\n                indexRowGenerator = new IndexRowGenerator(\n                                            indexType, \n                                            unique, \n                                            uniqueWithDuplicateNulls,\n                                            baseColumnPositions,\n                                            isAscending,\n                                            baseColumnPositions.length);\n\t\t\t}\n\t\t\telse \n            {\n\t\t\t\tindexRowGenerator = new IndexRowGenerator(\n                                            indexType, \n                                            unique,\n                                            baseColumnPositions,\n                                            isAscending,\n                                            baseColumnPositions.length);\n\t\t\t}\n\t\t}\n\n\t\t/* Now add the rows from the base table to the conglomerate.\n\t\t * We do this by scanning the base table and inserting the\n\t\t * rows into a sorter before inserting from the sorter\n\t\t * into the index.  This gives us better performance\n\t\t * and a more compact index.\n\t\t */\n\n\t\trowSource = null;\n\t\tsortId = 0;\n\t\tboolean needToDropSort = false;\t// set to true once the sorter is created\n\n\t\t/* bulkFetchSIze will be 16 (for now) unless\n\t\t * we are creating the table in which case it\n\t\t * will be 1.  Too hard to remove scan when\n\t\t * creating index on new table, so minimize\n\t\t * work where we can.\n\t\t */\n\t\tint bulkFetchSize = (forCreateTable) ? 1 : 16;\t\n\t\tint numColumns = td.getNumberOfColumns();\n\t\tint approximateRowSize = 0;\n\n\t\t// Create the FormatableBitSet for mapping the partial to full base row\n\t\tFormatableBitSet bitSet = new FormatableBitSet(numColumns+1);\n\t\tfor (int index = 0; index < baseColumnPositions.length; index++)\n\t\t{\n\t\t\tbitSet.set(baseColumnPositions[index]);\n\t\t}\n\t\tFormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);\n\n\t\t// Start by opening a full scan on the base table.\n\t\tscan = tc.openGroupFetchScan(\n                            td.getHeapConglomerateId(),\n\t\t\t\t\t\t\tfalse,\t// hold\n\t\t\t\t\t\t\t0,\t// open base table read only\n                            TransactionController.MODE_TABLE,\n                            TransactionController.ISOLATION_SERIALIZABLE,\n\t\t\t\t\t\t\tzeroBasedBitSet,    // all fields as objects\n\t\t\t\t\t\t\t(DataValueDescriptor[]) null,\t// startKeyValue\n\t\t\t\t\t\t\t0,\t\t// not used when giving null start posn.\n\t\t\t\t\t\t\tnull,\t// qualifier\n\t\t\t\t\t\t\t(DataValueDescriptor[]) null,\t// stopKeyValue\n\t\t\t\t\t\t\t0);\t\t// not used when giving null stop posn.\n\n\t\t// Create an array to put base row template\n\t\tbaseRows = new ExecRow[bulkFetchSize];\n\t\tindexRows = new ExecIndexRow[bulkFetchSize];\n\t\tcompactBaseRows = new ExecRow[bulkFetchSize];\n\n\t\ttry\n\t\t{\n\t\t\t// Create the array of base row template\n\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t{\n\t\t\t\t// create a base row template\n\t\t\t\tbaseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);\n\n\t\t\t\t// create an index row template\n\t\t\t\tindexRows[i] = indexRowGenerator.getIndexRowTemplate();\n\n\t\t\t\t// create a compact base row template\n\t\t\t\tcompactBaseRows[i] = activation.getExecutionFactory().getValueRow(\n\t\t\t\t\t\t\t\t\t\t\t\t\tbaseColumnPositions.length);\n\t\t\t}\n\n\t\t\tindexTemplateRow = indexRows[0];\n\n\t\t\t// Fill the partial row with nulls of the correct type\n\t\t\tColumnDescriptorList cdl = td.getColumnDescriptorList();\n\t\t\tint\t\t\t\t\t cdlSize = cdl.size();\n\t\t\tfor (int index = 0, numSet = 0; index < cdlSize; index++)\n\t\t\t{\n\t\t\t\tif (! zeroBasedBitSet.get(index))\n\t\t\t\t{\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tnumSet++;\n\t\t\t\tColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);\n\t\t\t\tDataTypeDescriptor dts = cd.getType();\n\n\n\t\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t\t{\n\t\t\t\t\t// Put the column in both the compact and sparse base rows\n\t\t\t\t\tbaseRows[i].setColumn(index + 1,\n\t\t\t\t\t\t\t\t  dts.getNull());\n\t\t\t\t\tcompactBaseRows[i].setColumn(numSet,\n\t\t\t\t\t\t\t\t  baseRows[i].getColumn(index + 1));\n\t\t\t\t}\n\n\t\t\t\t// Calculate the approximate row size for the index row\n\t\t\t\tapproximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);\n\t\t\t}\n\n\t\t\t// Get an array of RowLocation template\n\t\t\tRowLocation rl[] = new RowLocation[bulkFetchSize];\n\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t{\n\t\t\t\trl[i] = scan.newRowLocationTemplate();\n\n\t\t\t\t// Get an index row based on the base row\n\t\t\t\tindexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);\n\t\t\t}\n\n\t\t\t/* now that we got indexTemplateRow, done for sharing index\n\t\t\t */\n\t\t\tif (shareExisting)\n\t\t\t\treturn;\n\n\t\t\t/* For non-unique indexes, we order by all columns + the RID.\n\t\t\t * For unique indexes, we just order by the columns.\n\t\t\t * We create a unique index observer for unique indexes\n\t\t\t * so that we can catch duplicate key.\n\t\t\t * We create a basic sort observer for non-unique indexes\n\t\t\t * so that we can reuse the wrappers during an external\n\t\t\t * sort.\n\t\t\t */\n\t\t\tint             numColumnOrderings;\n\t\t\tSortObserver    sortObserver   = null;\n            Properties      sortProperties = null;\n\t\t\tif (unique || uniqueWithDuplicateNulls)\n\t\t\t{\n\t\t\t\t// if the index is a constraint, use constraintname in \n                // possible error message\n\t\t\t\tString indexOrConstraintName = indexName;\n\t\t\t\tif  (conglomerateUUID != null)\n\t\t\t\t{\n\t\t\t\t\tConglomerateDescriptor cd = \n                        dd.getConglomerateDescriptor(conglomerateUUID);\n\t\t\t\t\tif ((isConstraint) && \n                        (cd != null && cd.getUUID() != null && td != null))\n\t\t\t\t\t{\n\t\t\t\t\t\tConstraintDescriptor conDesc = \n                            dd.getConstraintDescriptor(td, cd.getUUID());\n\t\t\t\t\t\tindexOrConstraintName = conDesc.getConstraintName();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (unique) \n\t\t\t\t{\n                    numColumnOrderings = baseColumnPositions.length;\n\n\t\t\t\t\tsortObserver = \n                        new UniqueIndexSortObserver(\n                                true, \n                                isConstraint, \n                                indexOrConstraintName,\n                                indexTemplateRow,\n                                true,\n                                td.getName());\n\t\t\t\t}\n\t\t\t\telse \n                {\n                    // unique with duplicate nulls allowed.\n\n\t\t\t\t\tnumColumnOrderings = baseColumnPositions.length + 1;\n\n                    // tell transaction controller to use the unique with \n                    // duplicate nulls sorter, when making createSort() call.\n\t\t\t\t\tsortProperties = new Properties();\n\t\t\t\t\tsortProperties.put(\n                        AccessFactoryGlobals.IMPL_TYPE, \n                        AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);\n\t\t\t\t\t//use sort operator which treats nulls unequal\n\t\t\t\t\tsortObserver = \n                        new UniqueWithDuplicateNullsIndexSortObserver(\n                                true, \n                                isConstraint, \n                                indexOrConstraintName,\n                                indexTemplateRow,\n                                true,\n                                td.getName());\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tnumColumnOrderings = baseColumnPositions.length + 1;\n\t\t\t\tsortObserver = new BasicSortObserver(true, false, \n\t\t\t\t\t\t\t\t\t\t\t\t\t indexTemplateRow,\n\t\t\t\t\t\t\t\t\t\t\t\t\t true);\n\t\t\t}\n\n\t\t\tColumnOrdering[]\torder = new ColumnOrdering[numColumnOrderings];\n\t\t\tfor (int i=0; i < numColumnOrderings; i++) \n\t\t\t{\n\t\t\t\torder[i] = \n                    new IndexColumnOrder(\n                        i, \n                        unique || i < numColumnOrderings - 1 ? \n                            isAscending[i] : true);\n\t\t\t}\n\n\t\t\t// create the sorter\n\t\t\tsortId = tc.createSort((Properties)sortProperties, \n\t\t\t\t\tindexTemplateRow.getRowArrayClone(),\n\t\t\t\t\torder,\n\t\t\t\t\tsortObserver,\n\t\t\t\t\tfalse,\t\t\t// not in order\n\t\t\t\t\tscan.getEstimatedRowCount(),\n\t\t\t\t\tapproximateRowSize\t// est row size, -1 means no idea\t\n\t\t\t\t\t);\n\n\t\t\tneedToDropSort = true;\n\n\t\t\t// Populate sorter and get the output of the sorter into a row\n\t\t\t// source.  The sorter has the indexed columns only and the columns\n\t\t\t// are in the correct order. \n\t\t\trowSource = loadSorter(baseRows, indexRows, tc,\n\t\t\t\t\t\t\t\t   scan, sortId, rl);\n\n\t\t\tconglomId = \n                tc.createAndLoadConglomerate(\n\t\t\t\t\tindexType,\n\t\t\t\t\tindexTemplateRow.getRowArray(),\t// index row template\n\t\t\t\t\torder, //colums sort order\n                    indexRowGenerator.getColumnCollationIds(\n                        td.getColumnDescriptorList()),\n\t\t\t\t\tindexProperties,\n\t\t\t\t\tTransactionController.IS_DEFAULT, // not temporary\n\t\t\t\t\trowSource,\n\t\t\t\t\t(long[]) null);\n\t\t\t\n\t\t}\n\t\tfinally\n\t\t{\n\n\t\t\t/* close the table scan */\n\t\t\tif (scan != null)\n\t\t\t\tscan.close();\n\n\t\t\t/* close the sorter row source before throwing exception */\n\t\t\tif (rowSource != null)\n\t\t\t\trowSource.closeRowSource();\n\n\t\t\t/*\n\t\t\t** drop the sort so that intermediate external sort run can be\n\t\t\t** removed from disk\n\t\t\t*/\n\t\t\tif (needToDropSort)\n\t\t\t \ttc.dropSort(sortId);\n\t\t}\n\n\t\tConglomerateController indexController =\n\t\t\ttc.openConglomerate(\n                conglomId, false, 0, TransactionController.MODE_TABLE,\n                TransactionController.ISOLATION_SERIALIZABLE);\n\n\t\t// Check to make sure that the conglomerate can be used as an index\n\t\tif ( ! indexController.isKeyed())\n\t\t{\n\t\t\tindexController.close();\n\t\t\tthrow StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t   indexType);\n\t\t}\n\t\tindexController.close();\n\n\t\t//\n\t\t// Create a conglomerate descriptor with the conglomId filled\n\t\t// in and add it--if we don't have one already.\n\t\t//\n\t\tif (!alreadyHaveConglomDescriptor)\n\t\t{\n\t\t\tConglomerateDescriptor cgd =\n\t\t\t\tddg.newConglomerateDescriptor(\n\t\t\t\t\tconglomId, indexName, true,\n\t\t\t\t\tindexRowGenerator, isConstraint,\n\t\t\t\t\tconglomerateUUID, td.getUUID(), sd.getUUID() );\n\n\t\t\tdd.addDescriptor(cgd, sd,\n\t\t\t\tDataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);\n\n\t\t\t// add newly added conglomerate to the list of conglomerate\n\t\t\t// descriptors in the td.\n\t\t\tConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();\n\t\t\tcdl.add(cgd);\n\n\t\t\t/* Since we created a new conglomerate descriptor, load\n\t\t\t * its UUID into the corresponding field, to ensure that\n\t\t\t * it is properly set in the StatisticsDescriptor created\n\t\t\t * below.\n\t\t\t */\n\t\t\tconglomerateUUID = cgd.getUUID();\n\t\t}\n\n\t\tCardinalityCounter cCount = (CardinalityCounter)rowSource;\n\n        long numRows = cCount.getRowCount();\n        if (addStatistics(dd, indexRowGenerator, numRows))\n\t\t{\n\t\t\tlong[] c = cCount.getCardinality();\n\t\t\tfor (int i = 0; i < c.length; i++)\n\t\t\t{\n\t\t\t\tStatisticsDescriptor statDesc = \n\t\t\t\t\tnew StatisticsDescriptor(dd,\n\t\t\t\t\t\tdd.getUUIDFactory().createUUID(),\n\t\t\t\t\t\tconglomerateUUID, td.getUUID(), \"I\",\n\t\t\t\t\t\tnew StatisticsImpl(numRows, c[i]), i + 1);\n\n\t\t\t\tdd.addDescriptor(statDesc, null, \n\t\t\t\t\t\t\t\t DataDictionary.SYSSTATISTICS_CATALOG_NUM,\n\t\t\t\t\t\t\t\t true, tc);\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 258, "target": 0, "func": "public void\texecuteConstantAction( Activation activation )\n\t\t\t\t\t\tthrows StandardException\n\t{\n\t\tTableDescriptor \t\t\ttd;\n\t\tUUID \t\t\t\t\t\ttoid;\n\t\tColumnDescriptor\t\t\tcolumnDescriptor;\n\t\tint[]\t\t\t\t\t\tbaseColumnPositions;\n\t\tIndexRowGenerator\t\t\tindexRowGenerator = null;\n\t\tExecRow[]\t\t\t\t\tbaseRows;\n\t\tExecIndexRow[]\t\t\t\tindexRows;\n\t\tExecRow[]\t\t\t\t\tcompactBaseRows;\n\t\tGroupFetchScanController    scan;\n\t\tRowLocationRetRowSource\t    rowSource;\n\t\tlong\t\t\t\t\t\tsortId;\n\t\tint\t\t\t\t\t\t\tmaxBaseColumnPosition = -1;\n\n\t\tLanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tDependencyManager dm = dd.getDependencyManager();\n\t\tTransactionController tc = lcc.getTransactionExecute();\n\n\t\t/*\n\t\t** Inform the data dictionary that we are about to write to it.\n\t\t** There are several calls to data dictionary \"get\" methods here\n\t\t** that might be done in \"read\" mode in the data dictionary, but\n\t\t** it seemed safer to do this whole operation in \"write\" mode.\n\t\t**\n\t\t** We tell the data dictionary we're done writing at the end of\n\t\t** the transaction.\n\t\t*/\n\t\tdd.startWriting(lcc);\n\n\t\t/*\n\t\t** If the schema descriptor is null, then\n\t\t** we must have just read ourselves in.  \n\t\t** So we will get the corresponding schema\n\t\t** descriptor from the data dictionary.\n\t\t*/\n\t\tSchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;\n\n\n\t\t/* Get the table descriptor. */\n\t\t/* See if we can get the TableDescriptor \n\t\t * from the Activation.  (Will be there\n\t\t * for backing indexes.)\n\t\t */\n\t\ttd = activation.getDDLTableDescriptor();\n\n\t\tif (td == null)\n\t\t{\n\t\t\t/* tableId will be non-null if adding an index to\n\t\t\t * an existing table (as opposed to creating a\n\t\t\t * table with a constraint with a backing index).\n\t\t\t */\n\t\t\tif (tableId != null)\n\t\t\t{\n\t\t\t\ttd = dd.getTableDescriptor(tableId);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\ttd = dd.getTableDescriptor(tableName, sd, tc);\n\t\t\t}\n\t\t}\n\n\t\tif (td == null)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, \n\t\t\t\t\t\tindexName, tableName);\n\t\t}\n\n\t\tif (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)\n\t\t{\n\t\t\tthrow StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, \n\t\t\t\t\t\tindexName, tableName);\n\t\t}\n\n\t\t/* Get a shared table lock on the table. We need to lock table before\n\t\t * invalidate dependents, otherwise, we may interfere with the\n\t\t * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/\n\t\t * docs/language/SolutionsToConcurrencyIssues.txt (point f).\n\t\t */\n\t\tlockTableForDDL(tc, td.getHeapConglomerateId(), false);\n\n\t\t// invalidate any prepared statements that\n\t\t// depended on this table (including this one)\n\t\tif (! forCreateTable)\n\t\t{\n\t\t\tdm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);\n\t\t}\n\n\t\t// Translate the base column names to column positions\n\t\tbaseColumnPositions = new int[columnNames.length];\n\t\tfor (int i = 0; i < columnNames.length; i++)\n\t\t{\n\t\t\t// Look up the column in the data dictionary\n\t\t\tcolumnDescriptor = td.getColumnDescriptor(columnNames[i]);\n\t\t\tif (columnDescriptor == null)\n\t\t\t{\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolumnNames[i],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttableName);\n\t\t\t}\n\n\t\t\tTypeId typeId = columnDescriptor.getType().getTypeId();\n\n\t\t\t// Don't allow a column to be created on a non-orderable type\n\t\t\tClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();\n\t\t\tboolean isIndexable = typeId.orderable(cf);\n\n\t\t\tif (isIndexable && typeId.userType()) {\n\t\t\t\tString userClass = typeId.getCorrespondingJavaTypeName();\n\n\t\t\t\t// Don't allow indexes to be created on classes that\n\t\t\t\t// are loaded from the database. This is because recovery\n\t\t\t\t// won't be able to see the class and it will need it to\n\t\t\t\t// run the compare method.\n\t\t\t\ttry {\n\t\t\t\t\tif (cf.isApplicationClass(cf.loadApplicationClass(userClass)))\n\t\t\t\t\t\tisIndexable = false;\n\t\t\t\t} catch (ClassNotFoundException cnfe) {\n\t\t\t\t\t// shouldn't happen as we just check the class is orderable\n\t\t\t\t\tisIndexable = false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!isIndexable) {\n\t\t\t\tthrow StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, \n\t\t\t\t\ttypeId.getSQLTypeName());\n\t\t\t}\n\n\t\t\t// Remember the position in the base table of each column\n\t\t\tbaseColumnPositions[i] = columnDescriptor.getPosition();\n\n\t\t\tif (maxBaseColumnPosition < baseColumnPositions[i])\n\t\t\t\tmaxBaseColumnPosition = baseColumnPositions[i];\n\t\t}\n\n\t\t/* The code below tries to determine if the index that we're about\n\t\t * to create can \"share\" a conglomerate with an existing index.\n\t\t * If so, we will use a single physical conglomerate--namely, the\n\t\t * one that already exists--to support both indexes. I.e. we will\n\t\t * *not* create a new conglomerate as part of this constant action.\n\t\t */ \n\n\t\t// check if we have similar indices already for this table\n\t\tConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();\n\t\tboolean shareExisting = false;\n\t\tfor (int i = 0; i < congDescs.length; i++)\n\t\t{\n\t\t\tConglomerateDescriptor cd = congDescs[i];\n\t\t\tif ( ! cd.isIndex())\n\t\t\t\tcontinue;\n\n\t\t\tif (droppedConglomNum == cd.getConglomerateNumber())\n\t\t\t{\n\t\t\t\t/* We can't share with any conglomerate descriptor\n\t\t\t\t * whose conglomerate number matches the dropped\n\t\t\t\t * conglomerate number, because that descriptor's\n\t\t\t\t * backing conglomerate was dropped, as well.  If\n\t\t\t\t * we're going to share, we have to share with a\n\t\t\t\t * descriptor whose backing physical conglomerate\n\t\t\t\t * is still around.\n\t\t\t\t */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tIndexRowGenerator irg = cd.getIndexDescriptor();\n\t\t\tint[] bcps = irg.baseColumnPositions();\n\t\t\tboolean[] ia = irg.isAscending();\n\t\t\tint j = 0;\n\n\t\t\t/* The conditions which allow an index to share an existing\n\t\t\t * conglomerate are as follows:\n\t\t\t *\n\t\t\t * 1. the set of columns (both key and include columns) and their \n\t\t\t *  order in the index is the same as that of an existing index AND \n\t\t\t *\n\t\t\t * 2. the ordering attributes are the same AND \n\t\t\t *\n\t\t\t * 3. one of the following is true:\n\t\t\t *    a) the existing index is unique, OR\n\t\t\t *    b) the existing index is non-unique with uniqueWhenNotNulls\n\t\t\t *       set to TRUE and the index being created is non-unique, OR\n\t\t\t *    c) both the existing index and the one being created are\n\t\t\t *       non-unique and have uniqueWithDuplicateNulls set to FALSE.\n\t\t\t */ \n\t\t\tboolean possibleShare = (irg.isUnique() || !unique) &&\n\t\t\t    (bcps.length == baseColumnPositions.length);\n\n\t\t\t//check if existing index is non unique and uniqueWithDuplicateNulls\n\t\t\t//is set to true (backing index for unique constraint)\n\t\t\tif (possibleShare && !irg.isUnique ())\n\t\t\t{\n\t\t\t\t/* If the existing index has uniqueWithDuplicateNulls set to\n\t\t\t\t * TRUE it can be shared by other non-unique indexes; otherwise\n\t\t\t\t * the existing non-unique index has uniqueWithDuplicateNulls\n\t\t\t\t * set to FALSE, which means the new non-unique conglomerate\n\t\t\t\t * can only share if it has uniqueWithDuplicateNulls set to\n\t\t\t\t * FALSE, as well.\n\t\t\t\t */\n\t\t\t\tpossibleShare = (irg.isUniqueWithDuplicateNulls() ||\n\t\t\t\t\t\t\t\t! uniqueWithDuplicateNulls);\n\t\t\t}\n\n\t\t\tif (possibleShare && indexType.equals(irg.indexType()))\n\t\t\t{\n\t\t\t\tfor (; j < bcps.length; j++)\n\t\t\t\t{\n\t\t\t\t\tif ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (j == baseColumnPositions.length)\t// share\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Don't allow users to create a duplicate index. Allow if being done internally\n\t\t\t\t * for a constraint\n\t\t\t\t */\n\t\t\t\tif (!isConstraint)\n\t\t\t\t{\n\t\t\t\t\tactivation.addWarning(\n\t\t\t\t\t\t\tStandardException.newWarning(\n\t\t\t\t\t\t\t\tSQLState.LANG_INDEX_DUPLICATE,\n\t\t\t\t\t\t\t\tcd.getConglomerateName()));\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\t/* Sharing indexes share the physical conglomerate\n\t\t\t\t * underneath, so pull the conglomerate number from\n\t\t\t\t * the existing conglomerate descriptor.\n\t\t\t\t */\n\t\t\t\tconglomId = cd.getConglomerateNumber();\n\n\t\t\t\t/* We create a new IndexRowGenerator because certain\n\t\t\t\t * attributes--esp. uniqueness--may be different between\n\t\t\t\t * the index we're creating and the conglomerate that\n\t\t\t\t * already exists.  I.e. even though we're sharing a\n\t\t\t\t * conglomerate, the new index is not necessarily\n\t\t\t\t * identical to the existing conglomerate. We have to\n\t\t\t\t * keep track of that info so that if we later drop\n\t\t\t\t * the shared physical conglomerate, we can figure out\n\t\t\t\t * what this index (the one we're creating now) is\n\t\t\t\t * really supposed to look like.\n\t\t\t\t */\n\t\t\t\tindexRowGenerator =\n\t\t\t\t\tnew IndexRowGenerator(\n\t\t\t\t\t\tindexType, unique, uniqueWithDuplicateNulls,\n\t\t\t\t\t\tbaseColumnPositions,\n\t\t\t\t\t\tisAscending,\n\t\t\t\t\t\tbaseColumnPositions.length);\n\n\t\t\t\t//DERBY-655 and DERBY-1343  \n\t\t\t\t// Sharing indexes will have unique logical conglomerate UUIDs.\n\t\t\t\tconglomerateUUID = dd.getUUIDFactory().createUUID();\n\t\t\t\tshareExisting = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If we have a droppedConglomNum then the index we're about to\n\t\t * \"create\" already exists--i.e. it has an index descriptor and\n\t\t * the corresponding information is already in the system catalogs.\n\t\t * The only thing we're missing, then, is the physical conglomerate\n\t\t * to back the index (because the old conglomerate was dropped).\n\t\t */\n\t\tboolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);\n\n\t\t/* If this index already has an essentially same one, we share the\n\t\t * conglomerate with the old one, and just simply add a descriptor\n\t\t * entry into SYSCONGLOMERATES--unless we already have a descriptor,\n\t\t * in which case we don't even need to do that.\n\t\t */\n\t\tDataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\t\tif (shareExisting && !alreadyHaveConglomDescriptor)\n\t\t{\n\t\t\tConglomerateDescriptor cgd =\n\t\t\t\tddg.newConglomerateDescriptor(conglomId, indexName, true,\n\t\t\t\t\t\t\t\t\t\t  indexRowGenerator, isConstraint,\n\t\t\t\t\t\t\t\t\t\t  conglomerateUUID, td.getUUID(), sd.getUUID() );\n\t\t\tdd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);\n\t\t\t// add newly added conglomerate to the list of conglomerate \n\t\t\t// descriptors in the td.\n\t\t\tConglomerateDescriptorList cdl = \n\t\t\t\ttd.getConglomerateDescriptorList();\n\t\t\tcdl.add(cgd);\n\n\t\t\t// can't just return yet, need to get member \"indexTemplateRow\"\n\t\t\t// because create constraint may use it\n\t\t}\n\n\t\t// Describe the properties of the index to the store using Properties\n\t\t// RESOLVE: The following properties assume a BTREE index.\n\t\tProperties\tindexProperties;\n\t\t\n\t\tif (properties != null)\n\t\t{\n\t\t\tindexProperties = properties;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tindexProperties = new Properties();\n\t\t}\n\n\t\t// Tell it the conglomerate id of the base table\n\t\tindexProperties.put(\"baseConglomerateId\",\n\t\t\t\t\t\t\tLong.toString(td.getHeapConglomerateId()));\n        \n\t\tif (uniqueWithDuplicateNulls) \n        {\n            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))\n            {\n\t\t\t\tindexProperties.put(\n                    \"uniqueWithDuplicateNulls\", Boolean.toString(true));\n\t\t\t}\n\t\t\telse \n            {\n\t\t\t\t// for lower version of DD there is no unique with nulls \n                // index creating a unique index instead.\n\t\t\t\tif (uniqueWithDuplicateNulls) \n                {\n\t\t\t\t\tunique = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// All indexes are unique because they contain the RowLocation.\n\t\t// The number of uniqueness columns must include the RowLocation\n\t\t// if the user did not specify a unique index.\n\t\tindexProperties.put(\"nUniqueColumns\",\n\t\t\t\t\tInteger.toString(unique ? baseColumnPositions.length :\n\t\t\t\t\t\t\t\t\t\t\t\tbaseColumnPositions.length + 1)\n\t\t\t\t\t\t\t);\n\t\t// By convention, the row location column is the last column\n\t\tindexProperties.put(\"rowLocationColumn\",\n\t\t\t\t\t\t\tInteger.toString(baseColumnPositions.length));\n\n\t\t// For now, all columns are key fields, including the RowLocation\n\t\tindexProperties.put(\"nKeyFields\",\n\t\t\t\t\t\t\tInteger.toString(baseColumnPositions.length + 1));\n\n\t\t// For now, assume that all index columns are ordered columns\n\t\tif (! shareExisting)\n\t\t{\n            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))\n            {\n                indexRowGenerator = new IndexRowGenerator(\n                                            indexType, \n                                            unique, \n                                            uniqueWithDuplicateNulls,\n                                            baseColumnPositions,\n                                            isAscending,\n                                            baseColumnPositions.length);\n\t\t\t}\n\t\t\telse \n            {\n\t\t\t\tindexRowGenerator = new IndexRowGenerator(\n                                            indexType, \n                                            unique,\n                                            baseColumnPositions,\n                                            isAscending,\n                                            baseColumnPositions.length);\n\t\t\t}\n\t\t}\n\n\t\t/* Now add the rows from the base table to the conglomerate.\n\t\t * We do this by scanning the base table and inserting the\n\t\t * rows into a sorter before inserting from the sorter\n\t\t * into the index.  This gives us better performance\n\t\t * and a more compact index.\n\t\t */\n\n\t\trowSource = null;\n\t\tsortId = 0;\n\t\tboolean needToDropSort = false;\t// set to true once the sorter is created\n\n\t\t/* bulkFetchSIze will be 16 (for now) unless\n\t\t * we are creating the table in which case it\n\t\t * will be 1.  Too hard to remove scan when\n\t\t * creating index on new table, so minimize\n\t\t * work where we can.\n\t\t */\n\t\tint bulkFetchSize = (forCreateTable) ? 1 : 16;\t\n\t\tint numColumns = td.getNumberOfColumns();\n\t\tint approximateRowSize = 0;\n\n\t\t// Create the FormatableBitSet for mapping the partial to full base row\n\t\tFormatableBitSet bitSet = new FormatableBitSet(numColumns+1);\n\t\tfor (int index = 0; index < baseColumnPositions.length; index++)\n\t\t{\n\t\t\tbitSet.set(baseColumnPositions[index]);\n\t\t}\n\t\tFormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);\n\n\t\t// Start by opening a full scan on the base table.\n\t\tscan = tc.openGroupFetchScan(\n                            td.getHeapConglomerateId(),\n\t\t\t\t\t\t\tfalse,\t// hold\n\t\t\t\t\t\t\t0,\t// open base table read only\n                            TransactionController.MODE_TABLE,\n                            TransactionController.ISOLATION_SERIALIZABLE,\n\t\t\t\t\t\t\tzeroBasedBitSet,    // all fields as objects\n\t\t\t\t\t\t\t(DataValueDescriptor[]) null,\t// startKeyValue\n\t\t\t\t\t\t\t0,\t\t// not used when giving null start posn.\n\t\t\t\t\t\t\tnull,\t// qualifier\n\t\t\t\t\t\t\t(DataValueDescriptor[]) null,\t// stopKeyValue\n\t\t\t\t\t\t\t0);\t\t// not used when giving null stop posn.\n\n\t\t// Create an array to put base row template\n\t\tbaseRows = new ExecRow[bulkFetchSize];\n\t\tindexRows = new ExecIndexRow[bulkFetchSize];\n\t\tcompactBaseRows = new ExecRow[bulkFetchSize];\n\n\t\ttry\n\t\t{\n\t\t\t// Create the array of base row template\n\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t{\n\t\t\t\t// create a base row template\n\t\t\t\tbaseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);\n\n\t\t\t\t// create an index row template\n\t\t\t\tindexRows[i] = indexRowGenerator.getIndexRowTemplate();\n\n\t\t\t\t// create a compact base row template\n\t\t\t\tcompactBaseRows[i] = activation.getExecutionFactory().getValueRow(\n\t\t\t\t\t\t\t\t\t\t\t\t\tbaseColumnPositions.length);\n\t\t\t}\n\n\t\t\tindexTemplateRow = indexRows[0];\n\n\t\t\t// Fill the partial row with nulls of the correct type\n\t\t\tColumnDescriptorList cdl = td.getColumnDescriptorList();\n\t\t\tint\t\t\t\t\t cdlSize = cdl.size();\n\t\t\tfor (int index = 0, numSet = 0; index < cdlSize; index++)\n\t\t\t{\n\t\t\t\tif (! zeroBasedBitSet.get(index))\n\t\t\t\t{\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tnumSet++;\n\t\t\t\tColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);\n\t\t\t\tDataTypeDescriptor dts = cd.getType();\n\n\n\t\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t\t{\n\t\t\t\t\t// Put the column in both the compact and sparse base rows\n\t\t\t\t\tbaseRows[i].setColumn(index + 1,\n\t\t\t\t\t\t\t\t  dts.getNull());\n\t\t\t\t\tcompactBaseRows[i].setColumn(numSet,\n\t\t\t\t\t\t\t\t  baseRows[i].getColumn(index + 1));\n\t\t\t\t}\n\n\t\t\t\t// Calculate the approximate row size for the index row\n\t\t\t\tapproximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);\n\t\t\t}\n\n\t\t\t// Get an array of RowLocation template\n\t\t\tRowLocation rl[] = new RowLocation[bulkFetchSize];\n\t\t\tfor (int i = 0; i < bulkFetchSize; i++)\n\t\t\t{\n\t\t\t\trl[i] = scan.newRowLocationTemplate();\n\n\t\t\t\t// Get an index row based on the base row\n\t\t\t\tindexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);\n\t\t\t}\n\n\t\t\t/* now that we got indexTemplateRow, done for sharing index\n\t\t\t */\n\t\t\tif (shareExisting)\n\t\t\t\treturn;\n\n\t\t\t/* For non-unique indexes, we order by all columns + the RID.\n\t\t\t * For unique indexes, we just order by the columns.\n\t\t\t * We create a unique index observer for unique indexes\n\t\t\t * so that we can catch duplicate key.\n\t\t\t * We create a basic sort observer for non-unique indexes\n\t\t\t * so that we can reuse the wrappers during an external\n\t\t\t * sort.\n\t\t\t */\n\t\t\tint             numColumnOrderings;\n\t\t\tSortObserver    sortObserver   = null;\n            Properties      sortProperties = null;\n\t\t\tif (unique || uniqueWithDuplicateNulls)\n\t\t\t{\n\t\t\t\t// if the index is a constraint, use constraintname in \n                // possible error message\n\t\t\t\tString indexOrConstraintName = indexName;\n\t\t\t\tif  (conglomerateUUID != null)\n\t\t\t\t{\n\t\t\t\t\tConglomerateDescriptor cd = \n                        dd.getConglomerateDescriptor(conglomerateUUID);\n\t\t\t\t\tif ((isConstraint) && \n                        (cd != null && cd.getUUID() != null && td != null))\n\t\t\t\t\t{\n\t\t\t\t\t\tConstraintDescriptor conDesc = \n                            dd.getConstraintDescriptor(td, cd.getUUID());\n\t\t\t\t\t\tindexOrConstraintName = conDesc.getConstraintName();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (unique) \n\t\t\t\t{\n                    numColumnOrderings = baseColumnPositions.length;\n\n\t\t\t\t\tsortObserver = \n                        new UniqueIndexSortObserver(\n                                true, \n                                isConstraint, \n                                indexOrConstraintName,\n                                indexTemplateRow,\n                                true,\n                                td.getName());\n\t\t\t\t}\n\t\t\t\telse \n                {\n                    // unique with duplicate nulls allowed.\n\n\t\t\t\t\tnumColumnOrderings = baseColumnPositions.length + 1;\n\n                    // tell transaction controller to use the unique with \n                    // duplicate nulls sorter, when making createSort() call.\n\t\t\t\t\tsortProperties = new Properties();\n\t\t\t\t\tsortProperties.put(\n                        AccessFactoryGlobals.IMPL_TYPE, \n                        AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);\n\t\t\t\t\t//use sort operator which treats nulls unequal\n\t\t\t\t\tsortObserver = \n                        new UniqueWithDuplicateNullsIndexSortObserver(\n                                true, \n                                isConstraint, \n                                indexOrConstraintName,\n                                indexTemplateRow,\n                                true,\n                                td.getName());\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tnumColumnOrderings = baseColumnPositions.length + 1;\n\t\t\t\tsortObserver = new BasicSortObserver(true, false, \n\t\t\t\t\t\t\t\t\t\t\t\t\t indexTemplateRow,\n\t\t\t\t\t\t\t\t\t\t\t\t\t true);\n\t\t\t}\n\n\t\t\tColumnOrdering[]\torder = new ColumnOrdering[numColumnOrderings];\n\t\t\tfor (int i=0; i < numColumnOrderings; i++) \n\t\t\t{\n\t\t\t\torder[i] = \n                    new IndexColumnOrder(\n                        i, \n                        unique || i < numColumnOrderings - 1 ? \n                            isAscending[i] : true);\n\t\t\t}\n\n\t\t\t// create the sorter\n\t\t\tsortId = tc.createSort((Properties)sortProperties, \n\t\t\t\t\tindexTemplateRow.getRowArrayClone(),\n\t\t\t\t\torder,\n\t\t\t\t\tsortObserver,\n\t\t\t\t\tfalse,\t\t\t// not in order\n\t\t\t\t\tscan.getEstimatedRowCount(),\n\t\t\t\t\tapproximateRowSize\t// est row size, -1 means no idea\t\n\t\t\t\t\t);\n\n\t\t\tneedToDropSort = true;\n\n\t\t\t// Populate sorter and get the output of the sorter into a row\n\t\t\t// source.  The sorter has the indexed columns only and the columns\n\t\t\t// are in the correct order. \n\t\t\trowSource = loadSorter(baseRows, indexRows, tc,\n\t\t\t\t\t\t\t\t   scan, sortId, rl);\n\n\t\t\tconglomId = \n                tc.createAndLoadConglomerate(\n\t\t\t\t\tindexType,\n\t\t\t\t\tindexTemplateRow.getRowArray(),\t// index row template\n\t\t\t\t\torder, //colums sort order\n                    indexRowGenerator.getColumnCollationIds(\n                        td.getColumnDescriptorList()),\n\t\t\t\t\tindexProperties,\n\t\t\t\t\tTransactionController.IS_DEFAULT, // not temporary\n\t\t\t\t\trowSource,\n\t\t\t\t\t(long[]) null);\n\t\t\t\n\t\t}\n\t\tfinally\n\t\t{\n\n\t\t\t/* close the table scan */\n\t\t\tif (scan != null)\n\t\t\t\tscan.close();\n\n\t\t\t/* close the sorter row source before throwing exception */\n\t\t\tif (rowSource != null)\n\t\t\t\trowSource.closeRowSource();\n\n\t\t\t/*\n\t\t\t** drop the sort so that intermediate external sort run can be\n\t\t\t** removed from disk\n\t\t\t*/\n\t\t\tif (needToDropSort)\n\t\t\t \ttc.dropSort(sortId);\n\t\t}\n\n\t\tConglomerateController indexController =\n\t\t\ttc.openConglomerate(\n                conglomId, false, 0, TransactionController.MODE_TABLE,\n                TransactionController.ISOLATION_SERIALIZABLE);\n\n\t\t// Check to make sure that the conglomerate can be used as an index\n\t\tif ( ! indexController.isKeyed())\n\t\t{\n\t\t\tindexController.close();\n\t\t\tthrow StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t   indexType);\n\t\t}\n\t\tindexController.close();\n\n\t\t//\n\t\t// Create a conglomerate descriptor with the conglomId filled\n\t\t// in and add it--if we don't have one already.\n\t\t//\n\t\tif (!alreadyHaveConglomDescriptor)\n\t\t{\n\t\t\tConglomerateDescriptor cgd =\n\t\t\t\tddg.newConglomerateDescriptor(\n\t\t\t\t\tconglomId, indexName, true,\n\t\t\t\t\tindexRowGenerator, isConstraint,\n\t\t\t\t\tconglomerateUUID, td.getUUID(), sd.getUUID() );\n\n\t\t\tdd.addDescriptor(cgd, sd,\n\t\t\t\tDataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);\n\n\t\t\t// add newly added conglomerate to the list of conglomerate\n\t\t\t// descriptors in the td.\n\t\t\tConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();\n\t\t\tcdl.add(cgd);\n\n\t\t\t/* Since we created a new conglomerate descriptor, load\n\t\t\t * its UUID into the corresponding field, to ensure that\n\t\t\t * it is properly set in the StatisticsDescriptor created\n\t\t\t * below.\n\t\t\t */\n\t\t\tconglomerateUUID = cgd.getUUID();\n\t\t}\n\n\t\tCardinalityCounter cCount = (CardinalityCounter)rowSource;\n\n        long numRows = cCount.getRowCount();\n        if (addStatistics(dd, indexRowGenerator, numRows))\n\t\t{\n\t\t\tlong[] c = cCount.getCardinality();\n\t\t\tfor (int i = 0; i < c.length; i++)\n\t\t\t{\n\t\t\t\tStatisticsDescriptor statDesc = \n\t\t\t\t\tnew StatisticsDescriptor(dd,\n\t\t\t\t\t\tdd.getUUIDFactory().createUUID(),\n\t\t\t\t\t\tconglomerateUUID, td.getUUID(), \"I\",\n\t\t\t\t\t\tnew StatisticsImpl(numRows, c[i]), i + 1);\n\n\t\t\t\tdd.addDescriptor(statDesc, null, \n\t\t\t\t\t\t\t\t DataDictionary.SYSSTATISTICS_CATALOG_NUM,\n\t\t\t\t\t\t\t\t true, tc);\n\t\t\t}\n\t\t}\n\t}"}
{"idx": 259, "target": 0, "func": "public void\texecuteConstantAction( Activation activation )\n\t\tthrows StandardException\n\t{\n\t\tTableDescriptor \t\t\ttd;\n\t\tUUID \t\t\t\t\t\ttoid;\n\t\tSchemaDescriptor\t\t\tschemaDescriptor;\n\t\tColumnDescriptor\t\t\tcolumnDescriptor;\n\t\tExecRow\t\t\t\t\t\ttemplate;\n\n\t\tLanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tDependencyManager dm = dd.getDependencyManager();\n\t\tTransactionController tc = lcc.getTransactionExecute();\n\n\t\t/* Mark the activation as being for create table */\n\t\tactivation.setForCreateTable();\n\n        // setup for create conglomerate call:\n        //   o create row template to tell the store what type of rows this\n        //     table holds.\n        //   o create array of collation id's to tell collation id of each\n        //     column in table.\n\t\ttemplate            = RowUtil.getEmptyValueRow(columnInfo.length, lcc);\n        int[] collation_ids = new int[columnInfo.length];\n\n\t\tfor (int ix = 0; ix < columnInfo.length; ix++)\n\t\t{\n            ColumnInfo  col_info = columnInfo[ix];\n\n            // Get a template value for each column\n\n\t\t\tif (col_info.defaultValue != null)\n            {\n                /* If there is a default value, use it, otherwise use null */\n\t\t\t\ttemplate.setColumn(ix + 1, col_info.defaultValue);\n            }\n\t\t\telse\n            {\n\t\t\t\ttemplate.setColumn(ix + 1, col_info.dataType.getNull());\n            }\n\n            // get collation info for each column.\n\n            collation_ids[ix] = col_info.dataType.getCollationType();\n\t\t}\n\n\n\t\t/* create the conglomerate to hold the table's rows\n\t\t * RESOLVE - If we ever have a conglomerate creator\n\t\t * that lets us specify the conglomerate number then\n\t\t * we will need to handle it here.\n\t\t */\n\t\tlong conglomId = tc.createConglomerate(\n\t\t\t\t\"heap\", // we're requesting a heap conglomerate\n\t\t\t\ttemplate.getRowArray(), // row template\n\t\t\t\tnull, //column sort order - not required for heap\n                collation_ids,\n\t\t\t\tproperties, // properties\n\t\t\t\ttableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE ?\n                    (TransactionController.IS_TEMPORARY | \n                     TransactionController.IS_KEPT) : \n                        TransactionController.IS_DEFAULT);\n\n\t\t/*\n\t\t** Inform the data dictionary that we are about to write to it.\n\t\t** There are several calls to data dictionary \"get\" methods here\n\t\t** that might be done in \"read\" mode in the data dictionary, but\n\t\t** it seemed safer to do this whole operation in \"write\" mode.\n\t\t**\n\t\t** We tell the data dictionary we're done writing at the end of\n\t\t** the transaction.\n\t\t*/\n\t\tif ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )\n\t\t\tdd.startWriting(lcc);\n\n\t\tSchemaDescriptor sd;\n\t\tif (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)\n\t\t\tsd = dd.getSchemaDescriptor(schemaName, tc, true);\n\t\telse\n\t\t\tsd = DDLConstantAction.getSchemaDescriptorForCreate(dd, activation, schemaName);\n\n\t\t//\n\t\t// Create a new table descriptor.\n\t\t// \n\t\tDataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\n\t\tif ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )\n\t\t{\n\t\t\ttd = ddg.newTableDescriptor(tableName, sd, tableType, lockGranularity);\n\t\t\tdd.addDescriptor(td, sd, DataDictionary.SYSTABLES_CATALOG_NUM, false, tc);\n\t\t} else\n\t\t{\n\t\t\ttd = ddg.newTableDescriptor(tableName, sd, tableType, onCommitDeleteRows, onRollbackDeleteRows);\n\t\t\ttd.setUUID(dd.getUUIDFactory().createUUID());\n\t\t}\n\t\ttoid = td.getUUID();\n\n\t\t// Save the TableDescriptor off in the Activation\n\t\tactivation.setDDLTableDescriptor(td);\n\n\t\t/* NOTE: We must write the columns out to the system\n\t\t * tables before any of the conglomerates, including\n\t\t * the heap, since we read the columns before the\n\t\t * conglomerates when building a TableDescriptor.\n\t\t * This will hopefully reduce the probability of\n\t\t * a deadlock involving those system tables.\n\t\t */\n\t\t\n\t\t// for each column, stuff system.column\n\t\tint index = 1;\n\n\t\tColumnDescriptor[] cdlArray = new ColumnDescriptor[columnInfo.length];\n\t\tfor (int ix = 0; ix < columnInfo.length; ix++)\n\t\t{\n\t\t\tUUID defaultUUID = columnInfo[ix].newDefaultUUID;\n\n\t\t\t/* Generate a UUID for the default, if one exists\n\t\t\t * and there is no default id yet.\n\t\t\t */\n\t\t\tif (columnInfo[ix].defaultInfo != null &&\n\t\t\t\tdefaultUUID == null)\n\t\t\t{\n\t\t\t\tdefaultUUID = dd.getUUIDFactory().createUUID();\n\t\t\t}\n\n\t\t\tif (columnInfo[ix].autoincInc != 0)//dealing with autoinc column\n\t\t\tcolumnDescriptor = new ColumnDescriptor(\n\t\t\t\t                   columnInfo[ix].name,\n\t\t\t\t\t\t\t\t   index++,\n\t\t\t\t\t\t\t\t   columnInfo[ix].dataType,\n\t\t\t\t\t\t\t\t   columnInfo[ix].defaultValue,\n\t\t\t\t\t\t\t\t   columnInfo[ix].defaultInfo,\n\t\t\t\t\t\t\t\t   td,\n\t\t\t\t\t\t\t\t   defaultUUID,\n\t\t\t\t\t\t\t\t   columnInfo[ix].autoincStart,\n\t\t\t\t\t\t\t\t   columnInfo[ix].autoincInc,\n\t\t\t\t\t\t\t\t   columnInfo[ix].autoinc_create_or_modify_Start_Increment\n\t\t\t\t\t\t\t   );\n\t\t\telse\n\t\t\t\tcolumnDescriptor = new ColumnDescriptor(\n\t\t                   columnInfo[ix].name,\n\t\t\t\t\t\t   index++,\n\t\t\t\t\t\t   columnInfo[ix].dataType,\n\t\t\t\t\t\t   columnInfo[ix].defaultValue,\n\t\t\t\t\t\t   columnInfo[ix].defaultInfo,\n\t\t\t\t\t\t   td,\n\t\t\t\t\t\t   defaultUUID,\n\t\t\t\t\t\t   columnInfo[ix].autoincStart,\n\t\t\t\t\t\t   columnInfo[ix].autoincInc\n\t\t\t\t\t   );\n\n\t\t\tcdlArray[ix] = columnDescriptor;\n\t\t}\n\n\t\tif ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )\n\t\t{\n\t\t\tdd.addDescriptorArray(cdlArray, td,\n\t\t\t\t\t\t\t  DataDictionary.SYSCOLUMNS_CATALOG_NUM,\n\t\t\t\t\t\t\t  false, tc);\n\t\t}\n\n\t\t// now add the column descriptors to the table.\n\t\tColumnDescriptorList cdl = td.getColumnDescriptorList();\n\t\tfor (int i = 0; i < cdlArray.length; i++)\n\t\t\tcdl.add(cdlArray[i]);\n\t\t\t\t \n\t\t//\n\t\t// Create a conglomerate desciptor with the conglomId filled in and\n\t\t// add it.\n\t\t//\n\t\t// RESOLVE: Get information from the conglomerate descriptor which\n\t\t//          was provided. \n\t\t//\n\t\tConglomerateDescriptor cgd =\n\t\t\tddg.newConglomerateDescriptor(conglomId, null, false, null, false, null, toid,\n\t\t\t\t\t\t\t\t\t\t  sd.getUUID());\n\t\tif ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )\n\t\t{\n\t\t\tdd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM,\n\t\t\t\t\t\t false, tc);\n\t\t}\n\n\t\t// add the newly added conglomerate to the table descriptor\n\t\tConglomerateDescriptorList conglomList = td.getConglomerateDescriptorList();\n\t\tconglomList.add(cgd);\n\n\t\t/* Create any constraints */\n\t\tif (constraintActions != null)\n\t\t{\n\t\t\t/*\n\t\t\t** Do everything but FK constraints first,\n\t\t\t** then FK constraints on 2nd pass.\n\t\t\t*/\n\t\t\tfor (int conIndex = 0; conIndex < constraintActions.length; conIndex++)\n\t\t\t{\n\t\t\t\t// skip fks\n\t\t\t\tif (!constraintActions[conIndex].isForeignKeyConstraint())\n\t\t\t\t{\n\t\t\t\t\tconstraintActions[conIndex].executeConstantAction(activation);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (int conIndex = 0; conIndex < constraintActions.length; conIndex++)\n\t\t\t{\n\t\t\t\t// only foreign keys\n\t\t\t\tif (constraintActions[conIndex].isForeignKeyConstraint())\n\t\t\t\t{\n\t\t\t\t\tconstraintActions[conIndex].executeConstantAction(activation);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n        //\n        // Add dependencies. These can arise if a generated column depends\n        // on a user created function.\n        //\n\t\tfor (int ix = 0; ix < columnInfo.length; ix++)\n\t\t{\n            addColumnDependencies( lcc, dd, td, columnInfo[ ix ] );\n        }\n\n        //\n        // The table itself can depend on the user defined types of its columns.\n        //\n        adjustUDTDependencies( lcc, dd, td, columnInfo, false );\n        \n\t\tif ( tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )\n\t\t{\n\t\t\tlcc.addDeclaredGlobalTempTable(td);\n\t\t}\n\n\t\t// Indicate that the CREATE TABLE statement itself depends on the\n\t\t// table it is creating. Normally such statement dependencies are\n\t\t// added during compilation, but here we have a bootstrapping issue\n\t\t// because the table doesn't exist until the CREATE TABLE statement\n\t\t// has been executed, so we had to defer the creation of this\n\t\t// dependency until now. (DERBY-4479)\n\t\tdd.getDependencyManager().addDependency(\n\t\t\tactivation.getPreparedStatement(), td, lcc.getContextManager());\n\n\t}"}
{"idx": 260, "target": 1, "func": "public void\texecuteConstantAction(Activation activation)\n\t\t\t\t\t\tthrows StandardException\n\t{\n\t\tSPSDescriptor\t\t\t\twhenspsd = null;\n\t\tSPSDescriptor\t\t\t\tactionspsd;\n\n\t\tLanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tDependencyManager dm = dd.getDependencyManager();\n\t\tTransactionController tc = lcc.getTransactionExecute();\n\n\t\t/*\n\t\t** Indicate that we are about to modify the data dictionary.\n\t\t** \n\t\t** We tell the data dictionary we're done writing at the end of\n\t\t** the transaction.\n\t\t*/\n\t\tdd.startWriting(lcc);\n\n\t\tSchemaDescriptor triggerSd = getSchemaDescriptorForCreate(dd, activation, triggerSchemaName);\n\n\t\tif (spsCompSchemaId == null) {\n\t\t\tSchemaDescriptor def = lcc.getDefaultSchema();\n\t\t\tif (def.getUUID() == null) {\n\t\t\t\t// Descriptor for default schema is stale,\n\t\t\t\t// look it up in the dictionary\n\t\t\t\tdef = dd.getSchemaDescriptor(def.getDescriptorName(), tc, \n\t\t\t\t\t\t\t\t\t\t\t false);\n\t\t\t}\n\t\t\t\n\t\t\t/* \n\t\t\t** It is possible for spsCompSchemaId to be null.  For instance, \n\t\t\t** the current schema may not have been physically created yet but \n\t\t\t** it exists \"virtually\".  In this case, its UUID will have the \n\t\t\t** value of null meaning that it is not persistent.  e.g.:   \n\t\t\t**\n\t\t\t** CONNECT 'db;create=true' user 'ernie';\n\t\t\t** CREATE TABLE bert.t1 (i INT);\n\t\t\t** CREATE TRIGGER bert.tr1 AFTER INSERT ON bert.t1 \n\t\t\t**    FOR EACH STATEMENT MODE DB2SQL \n\t\t\t**    SELECT * FROM SYS.SYSTABLES;\n\t\t\t**\n\t\t\t** Note that in the above case, the trigger action statement have a \n\t\t\t** null compilation schema.  A compilation schema with null value \n\t\t\t** indicates that the trigger action statement text does not have \n\t\t\t** any dependencies with the CURRENT SCHEMA.  This means:\n\t\t\t**\n\t\t\t** o  It is safe to compile this statement in any schema since \n\t\t\t**    there is no dependency with the CURRENT SCHEMA. i.e.: All \n\t\t\t**    relevent identifiers are qualified with a specific schema.\n\t\t\t**\n\t\t\t** o  The statement cache mechanism can utilize this piece of \n\t\t\t**    information to enable better statement plan sharing across \n\t\t\t**    connections in different schemas; thus, avoiding unnecessary \n\t\t\t**    statement compilation.\n\t\t\t*/ \n\t\t\tif (def != null)\n\t\t\t\tspsCompSchemaId = def.getUUID();\n\t\t}\n\n\t\tString tabName;\n\t\tif (triggerTable != null)\n\t\t{\n\t\t\ttriggerTableId = triggerTable.getUUID();\n\t\t\ttabName = triggerTable.getName();\n\t\t}\n\t\telse\n\t\t\ttabName = \"with UUID \" + triggerTableId;\n\n\t\t/* We need to get table descriptor again.  We simply can't trust the\n\t\t * one we got at compile time, the lock on system table was released\n\t\t * when compile was done, and the table might well have been dropped.\n\t\t */\n\t\ttriggerTable = dd.getTableDescriptor(triggerTableId);\n\t\tif (triggerTable == null)\n\t\t{\n\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\t\tSQLState.LANG_TABLE_NOT_FOUND_DURING_EXECUTION,\n\t\t\t\t\t\t\t\ttabName);\n\t\t}\n\t\t/* Lock the table for DDL.  Otherwise during our execution, the table\n\t\t * might be changed, even dropped.  Beetle 4269\n\t\t */\n\t\tlockTableForDDL(tc, triggerTable.getHeapConglomerateId(), true);\n\t\t/* get triggerTable again for correctness, in case it's changed before\n\t\t * the lock is aquired\n\t\t */\n\t\ttriggerTable = dd.getTableDescriptor(triggerTableId);\n\t\tif (triggerTable == null)\n\t\t{\n\t\t\tthrow StandardException.newException(\n\t\t\t\t\t\t\t\tSQLState.LANG_TABLE_NOT_FOUND_DURING_EXECUTION,\n\t\t\t\t\t\t\t\ttabName);\n\t\t}\n\n\t\t/*\n\t\t** Send an invalidate on the table from which\n\t\t** the triggering event emanates.  This it\n\t\t** to make sure that DML statements on this table\n\t\t** will be recompiled.  Do this before we create\n\t\t** our trigger spses lest we invalidate them just\n\t\t** after creating them.\n\t\t*/\n\t\tdm.invalidateFor(triggerTable, DependencyManager.CREATE_TRIGGER, lcc);\n\n\t\t/*\n\t\t** Lets get our trigger id up front, we'll use it when\n\t \t** we create our spses.\n\t\t*/\n\t\tUUID tmpTriggerId = dd.getUUIDFactory().createUUID();\n\n\t\tactionSPSId = (actionSPSId == null) ? \n\t\t\tdd.getUUIDFactory().createUUID() : actionSPSId;\n \n\t\tDataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\n\t\t/*\n\t\t** Create the trigger descriptor first so the trigger action\n\t\t** compilation can pick up the relevant trigger especially in \n\t\t** the case of self triggering.\n\t\t*/\n\t\tTriggerDescriptor triggerd =\n\t\t\t\tddg.newTriggerDescriptor(\n\t\t\t\t\t\t\t\t\ttriggerSd,\n\t\t\t\t\t\t\t\t\ttmpTriggerId,\n\t\t\t\t\t\t\t\t\ttriggerName,\n\t\t\t\t\t\t\t\t\teventMask,\n\t\t\t\t\t\t\t\t\tisBefore,\n\t\t\t\t\t\t\t\t\tisRow,\n\t\t\t\t\t\t\t\t\tisEnabled,\n\t\t\t\t\t\t\t\t\ttriggerTable,\n\t\t\t\t\t\t\t\t\twhenspsd == null ? null : whenspsd.getUUID(),\n\t\t\t\t\t\t\t\t\tactionSPSId,\n\t\t\t\t\t\t\t\t\tcreationTimestamp == null ? new Timestamp(System.currentTimeMillis()) : creationTimestamp,\n\t\t\t\t\t\t\t\t\treferencedCols,\n\t\t\t\t\t\t\t\t\treferencedColsInTriggerAction,\n\t\t\t\t\t\t\t\t\toriginalActionText,\n\t\t\t\t\t\t\t\t\treferencingOld,\n\t\t\t\t\t\t\t\t\treferencingNew,\n\t\t\t\t\t\t\t\t\toldReferencingName,\n\t\t\t\t\t\t\t\t\tnewReferencingName);\n\n\n\t\tdd.addDescriptor(triggerd, triggerSd,\n\t\t\t\t\t\t\t\tDataDictionary.SYSTRIGGERS_CATALOG_NUM, false,\n\t\t\t\t\t\t\t\ttc);\n\n\n\t\t/*\t\n\t\t** If we have a WHEN action we create it now.\n\t\t*/\n\t\tif (whenText != null)\n\t\t{\n\t\t\twhenspsd = createSPS(lcc, ddg, dd, tc, tmpTriggerId, triggerSd,\n\t\t\t\t\t\twhenSPSId, spsCompSchemaId, whenText, true, triggerTable);\n\t\t}\n\n\t\t/*\n\t\t** Create the trigger action\n\t\t*/\n\t\tactionspsd = createSPS(lcc, ddg, dd, tc, tmpTriggerId, triggerSd,\n\t\t\t\t\t\tactionSPSId, spsCompSchemaId, actionText, false, triggerTable);\n\t\t\n\t\t/*\n\t\t** Make underlying spses dependent on the trigger.\n\t\t*/\n\t\tif (whenspsd != null)\n\t\t{\n\t\t\tdm.addDependency(triggerd, whenspsd, lcc.getContextManager());\n\t\t}\n\t\tdm.addDependency(triggerd, actionspsd, lcc.getContextManager());\n\t\tdm.addDependency(triggerd, triggerTable, lcc.getContextManager());\n\t\t//store trigger's dependency on various privileges in the dependeny system\n\t\tstoreViewTriggerDependenciesOnPrivileges(activation, triggerd);\t\t\n\t}"}
{"idx": 261, "target": 0, "func": "public Date getCurrentDate() {\n\t\tif (currentDate == null) {\n\t\t\tsetCurrentDatetime();\n\t\t\tcurrentDate = new Date(currentDatetime.getTime());\n\t\t}\n\t\treturn currentDate;\n\t}"}
{"idx": 262, "target": 0, "func": "public Timestamp getCurrentTimestamp() {\n\t\tif (currentTimestamp == null) {\n\t\t\tsetCurrentDatetime();\n\t\t\tcurrentTimestamp = new Timestamp(currentDatetime.getTime());\n\t\t}\n\t\treturn currentTimestamp;\n\t}"}
{"idx": 263, "target": 0, "func": "public ExecRow\tgetNextRowCore() throws StandardException {\n\n\t\tif ( isOpen ) {\n\t        if ( ! next ) {\n\t            next = true;\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t\tSanityManager.ASSERT(! cursor.isClosed(), \"cursor closed\");\n\n\t\t\t\tExecRow cursorRow = cursor.getCurrentRow();\n\n\t\t\t\t// requalify the current row\n\t\t\t\tif (cursorRow == null) {\n\t\t\t\t\tthrow StandardException.newException(SQLState.NO_CURRENT_ROW);\n\t\t\t\t}\n\t\t\t\t// we know it will be requested, may as well get it now.\n\t\t\t\trowLocation = cursor.getRowLocation();\n\n\t\t\t\t// get the row from the base table, which is the real result\n\t\t\t\t// row for the CurrentOfResultSet\n\t\t\t\tcurrentRow = target.getCurrentRow();\n\n\t\t\t\t// if the source result set is a ScrollInsensitiveResultSet, and\n\t\t\t\t// the current row has been deleted (while the cursor was \n\t\t\t\t// opened), the cursor result set (scroll insensitive) will \n\t\t\t\t// return the cached row, while the target result set will \n\t\t\t\t// return null (row has been deleted under owr feet).\n\t\t\t\tif (rowLocation == null  || \n\t\t\t\t\t\t(cursorRow != null && currentRow == null)) {\n\t\t\t\t\tactivation.addWarning(StandardException.\n\t\t\t\t\t\t\tnewWarning(SQLState.CURSOR_OPERATION_CONFLICT));\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\n\t\t\t\t/* beetle 3865: updateable cursor using index.  If underlying is a covering\n\t\t\t\t * index, target is a TableScanRS (instead of a IndexRow2BaseRowRS) for the\n\t\t\t\t * index scan.  But the problem is it returns a compact row in index key order.\n\t\t\t\t * However the ProjectRestrictRS above us that sets up the old and new column\n\t\t\t\t * values expects us to return a sparse row in heap order.  We have to do the\n\t\t\t\t * wiring here, since we don't have IndexRow2BaseRowRS to do this work.  This\n\t\t\t\t * problem was not exposed before, because we never used index scan for updateable\n\t\t\t\t * cursors.\n\t\t\t\t */\n\t\t\t\tif (target instanceof TableScanResultSet)\n\t\t\t\t{\n\t\t\t\t\tTableScanResultSet scan = (TableScanResultSet) target;\n\t\t\t\t\tif (scan.indexCols != null && currentRow != null)\n\t\t\t\t\t\tcurrentRow = getSparseRow(currentRow, scan.indexCols);\n\t\t\t\t}\n\n\t\t\t\t// REMIND: verify the row is still there\n\t\t\t\t// at present we get an ugly exception from the store,\n\t\t\t\t// Hopefully someday we can just do this:\n\t\t\t\t//\n\t\t\t\t// if (!rowLocation.rowExists())\n\t\t\t\t//     throw StandardException.newException(SQLState.LANG_NO_CURRENT_ROW, cursorName);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcurrentRow = null;\n\t\t\t\trowLocation = null;\n\t\t\t}\n\t    }\n\t\telse {\n\t\t\tcurrentRow = null;\n\t\t\trowLocation = null;\n\t\t}\n\t\tsetCurrentRow(currentRow);\n\t    return currentRow;\n\t}"}
{"idx": 264, "target": 1, "func": "private static PermissionsDescriptor findRoleUsage\n\t\t(Activation activation,\n\t\t StatementPermission statPerm) throws StandardException {\n\n\t\tLanguageConnectionContext lcc =\n\t\t\tactivation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tRoleGrantDescriptor rootGrant = null;\n\t\tString role = lcc.getCurrentRoleId(activation);\n\t\tString dbo = dd.getAuthorizationDatabaseOwner();\n        String currentUser = lcc.getCurrentUserId(activation);\n\t\tPermissionsDescriptor permDesc = null;\n\n\t\tif (SanityManager.DEBUG) {\n\t\t\tSanityManager.ASSERT(\n\t\t\t\trole != null,\n\t\t\t\t\"Unexpected: current role is not set\");\n\t\t}\n\n\t\t// determine how we got to be able use this role\n\t\trootGrant =\n            dd.getRoleGrantDescriptor(role, currentUser, dbo);\n\n\t\tif (rootGrant == null) {\n\t\t\trootGrant = dd.getRoleGrantDescriptor(\n\t\t\t\trole,\n\t\t\t\tAuthorizer.PUBLIC_AUTHORIZATION_ID,\n\t\t\t\tdbo);\n\t\t}\n\n\t\t// If not found in current role, get transitive\n\t\t// closure of roles granted to current role and\n\t\t// iterate over it to see if permission has\n\t\t// been granted to any of the roles the current\n\t\t// role inherits.\n\t\tRoleClosureIterator rci =\n\t\t\tdd.createRoleClosureIterator\n\t\t\t(activation.getTransactionController(),\n\t\t\t role, true /* inverse relation*/);\n\n\t\tString graphGrant;\n\t\twhile (permDesc == null &&\n\t\t\t   (graphGrant = rci.next()) != null) {\n\t\t\tpermDesc =\n\t\t\t\tstatPerm.getPermissionDescriptor\n\t\t\t\t(graphGrant, dd);\n\t\t}\n\n\t\tif (SanityManager.DEBUG) {\n\t\t\tSanityManager.ASSERT(\n\t\t\t\tpermDesc != null,\n\t\t\t\t\"Unexpected: Permission needs to be found via role\");\n\t\t}\n\n\t\treturn permDesc;\n\t}"}
{"idx": 265, "target": 1, "func": "protected void storeConstraintDependenciesOnPrivileges(\n\t\tActivation activation,\n\t\tDependent dependent,\n\t\tUUID refTableUUID,\n\t\tProviderInfo[] providers)\n\t\t\tthrows StandardException\n\t{\n\t\tLanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n\t\tDataDictionary dd = lcc.getDataDictionary();\n\t\tDependencyManager dm = dd.getDependencyManager();\n\t\tString dbo = dd.getAuthorizationDatabaseOwner();\n        String currentUser = lcc.getCurrentUserId(activation);\n\t\tSettableBoolean roleDepAdded = new SettableBoolean();\n\n\t\t//If the Database Owner is creating this constraint, then no need to \n\t\t//collect any privilege dependencies because the Database Owner can   \n\t\t//access any objects without any restrictions\n        if (! currentUser.equals( dd.getAuthorizationDatabaseOwner()) )\n\t\t{\n\t\t\tPermissionsDescriptor permDesc;\n\t\t\t// Now, it is time to add into dependency system the FOREIGN\n\t\t\t// constraint's dependency on REFERENCES privilege, or, if it is a\n\t\t\t// CHECK constraint, any EXECUTE or USAGE privileges. If the REFERENCES is\n\t\t\t// revoked from the constraint owner, the constraint will get\n\t\t\t// dropped automatically.\n\t\t\tList requiredPermissionsList = activation.getPreparedStatement().getRequiredPermissionsList();\n\n\t\t\tif (requiredPermissionsList != null && ! requiredPermissionsList.isEmpty())\n\t\t\t{\n\t\t\t\tfor(Iterator iter = requiredPermissionsList.iterator();iter.hasNext();)\n\t\t\t\t{\n\t\t\t\t\tStatementPermission statPerm = (StatementPermission) iter.next();\n\t\t\t\t\t//First check if we are dealing with a Table or \n\t\t\t\t\t//Column level privilege. All the other privileges\n\t\t\t\t\t//are not required for a foreign key constraint.\n\t\t\t\t\tif (statPerm instanceof StatementTablePermission)\n\t\t\t\t\t{//It is a table/column level privilege\n\t\t\t\t\t\tStatementTablePermission statementTablePermission = \n\t\t\t\t\t\t\t(StatementTablePermission) statPerm;\n\t\t\t\t\t\t//Check if we are dealing with REFERENCES privilege.\n\t\t\t\t\t\t//If not, move on to the next privilege in the\n\t\t\t\t\t\t//required privileges list\n\t\t\t\t\t\tif (statementTablePermission.getPrivType() != Authorizer.REFERENCES_PRIV)\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t//Next check is this REFERENCES privilege is \n\t\t\t\t\t\t//on the same table as referenced by the foreign\n\t\t\t\t\t\t//key constraint? If not, move on to the next\n\t\t\t\t\t\t//privilege in the required privileges list\n\t\t\t\t\t\tif (!statementTablePermission.getTableUUID().equals(refTableUUID))\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t} else if (statPerm instanceof StatementSchemaPermission\n\t\t\t\t\t\t    || statPerm instanceof StatementRolePermission\n                               || statPerm instanceof StatementGenericPermission ) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (SanityManager.DEBUG) {\n\t\t\t\t\t\t\tSanityManager.ASSERT(\n\t\t\t\t\t\t\t\tstatPerm instanceof StatementRoutinePermission,\n\t\t\t\t\t\t\t\t\"only StatementRoutinePermission expected\");\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// skip if this permission concerns a function not\n\t\t\t\t\t\t// referenced by this constraint\n\t\t\t\t\t\tStatementRoutinePermission rp =\n\t\t\t\t\t\t\t(StatementRoutinePermission)statPerm;\n\t\t\t\t\t\tif (!inProviderSet(providers, rp.getRoutineUUID())) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\n\t\t\t\t\t// We know that we are working with a REFERENCES, EXECUTE, or USAGE\n\t\t\t\t\t// privilege. Find all the PermissionDescriptors for this\n\t\t\t\t\t// privilege and make constraint depend on it through\n\t\t\t\t\t// dependency manager.  The REFERENCES privilege could be\n\t\t\t\t\t// defined at the table level or it could be defined at\n\t\t\t\t\t// individual column levels. In addition, individual column\n\t\t\t\t\t// REFERENCES privilege could be available at the user\n\t\t\t\t\t// level, PUBLIC or role level.  EXECUTE and USAGE privileges could be\n\t\t\t\t\t// available at the user level, PUBLIC or role level.\n                    permDesc = statPerm.getPermissionDescriptor(\n                        currentUser, dd);\n\n\t\t\t\t\tif (permDesc == null) \n\t\t\t\t\t{\n\t\t\t\t\t\t// No privilege exists for given user. The privilege\n\t\t\t\t\t\t// has to exist at at PUBLIC level....\n\n\t\t\t\t\t\tpermDesc = statPerm.getPermissionDescriptor(Authorizer.PUBLIC_AUTHORIZATION_ID, dd);\n\t\t\t\t\t\t// .... or at the role level. Additionally, for column\n\t\t\t\t\t\t// level privileges, even if *some* were available at\n\t\t\t\t\t\t// the PUBLIC level others may be still be missing,\n\t\t\t\t\t\t// hence the call in the test below to\n\t\t\t\t\t\t// allColumnsCoveredByUserOrPUBLIC.\n\t\t\t\t\t\tboolean roleUsed = false;\n\n\t\t\t\t\t\tif (permDesc == null ||\n\t\t\t\t\t\t\t((permDesc instanceof ColPermsDescriptor) &&\n                                 ! ((StatementColumnPermission)statPerm).\n                                   allColumnsCoveredByUserOrPUBLIC(\n                                       currentUser, dd))) {\n\t\t\t\t\t\t\troleUsed = true;\n\t\t\t\t\t\t\tpermDesc = findRoleUsage(activation, statPerm);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// If the user accessing the object is the owner of\n\t\t\t\t\t\t// that object, then no privilege tracking is needed\n\t\t\t\t\t\t// for the owner.\n                        if (! permDesc.checkOwner(currentUser) ) {\n\n                            dm.addDependency(dependent, permDesc,\n\t\t\t\t\t\t\t\t\t\t\t lcc.getContextManager());\n\n\t\t\t\t\t\t\tif (roleUsed) {\n\t\t\t\t\t\t\t\t// We had to rely on role, so track that\n\t\t\t\t\t\t\t\t// dependency, too.\n\t\t\t\t\t\t\t\ttrackRoleDependency\n\t\t\t\t\t\t\t\t\t(activation, dependent, roleDepAdded);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\t\t//if the object on which permission is required is owned by the\n\t\t\t\t\t\t//same user as the current user, then no need to keep that\n\t\t\t\t\t\t//object's privilege dependency in the dependency system\n                    if (! permDesc.checkOwner(currentUser))\n\t\t\t\t\t{\n\t\t\t\t\t\tdm.addDependency(dependent, permDesc, lcc.getContextManager());\n\t\t\t\t\t\tif (permDesc instanceof ColPermsDescriptor)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// The if statement above means we found a\n\t\t\t\t\t\t\t// REFERENCES privilege at column level for the\n\t\t\t\t\t\t\t// given authorizer. If this privilege doesn't\n\t\t\t\t\t\t\t// cover all the column , then there has to exisit\n\t\t\t\t\t\t\t// REFERENCES for the remaining columns at PUBLIC\n\t\t\t\t\t\t\t// level or at role level.  Get that permission\n\t\t\t\t\t\t\t// descriptor and save it in dependency system\n\t\t\t\t\t\t\tStatementColumnPermission\n\t\t\t\t\t\t\t\tstatementColumnPermission = (\n\t\t\t\t\t\t\t\t\tStatementColumnPermission)statPerm;\n\t\t\t\t\t\t\tpermDesc = statementColumnPermission.\n                                getPUBLIClevelColPermsDescriptor(\n                                    currentUser, dd);\n\t\t\t\t\t\t\t//Following if checks if some column level privileges\n\t\t\t\t\t\t\t//exist only at public level. If so, then the public\n\t\t\t\t\t\t\t//level column privilege dependency is added\n\t\t\t\t\t\t\t//into the dependency system\n\t\t\t\t\t\t\tif (permDesc != null &&\n\t\t\t\t\t\t\t\t\tpermDesc.getObjectID() != null) {\n\t\t\t\t\t\t\t\t// User did not have all required column\n\t\t\t\t\t\t\t\t// permissions and at least one column is\n\t\t\t\t\t\t\t\t// covered by PUBLIC.\n\t\t\t\t\t\t\t\tdm.addDependency(dependent, permDesc,\n\t\t\t\t\t\t\t\t\t\t\t\t lcc.getContextManager());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// Possibly, the current role has also been relied\n\t\t\t\t\t\t\t// upon.\n\t\t\t\t\t\t\tif (!statementColumnPermission.\n                                    allColumnsCoveredByUserOrPUBLIC(\n                                        currentUser, dd)) {\n\t\t\t\t\t\t\t\t// Role has been relied upon, so register a\n\t\t\t\t\t\t\t\t// dependency.\n\t\t\t\t\t\t\t\ttrackRoleDependency\n\t\t\t\t\t\t\t\t\t(activation, dependent, roleDepAdded);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!(statPerm instanceof StatementRoutinePermission)) {\n\t\t\t\t\t\t//We have found the REFERENCES privilege for all the\n\t\t\t\t\t\t//columns in foreign key constraint and we don't\n\t\t\t\t\t\t//need to go through the rest of the privileges\n\t\t\t\t\t\t//for this sql statement.\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For EXECUTE privilege there may be several functions\n\t\t\t\t\t\t// referenced in the constraint, so continue looking.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t}"}
{"idx": 266, "target": 0, "func": "private String printPosition(int searchOperator, ExecIndexRow positioner)\n\t{\n\t\tString idt = \"\";\n\t\tString output = \"\";\n\n\t\tString searchOp = null;\n\t\tswitch (searchOperator)\n\t\t{\n\t\t\tcase ScanController.GE:\n\t\t\t\tsearchOp = \">=\";\n\t\t\t\tbreak;\n\n\t\t\tcase ScanController.GT:\n\t\t\t\tsearchOp = \">\";\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"Unknown search operator \" +\n\t\t\t\t\t\t\t\t\t\t\t\tsearchOperator);\n\t\t\t\t}\n\n\t\t\t\t// NOTE: This does not have to be internationalized because\n\t\t\t\t// this code should never be reached.\n\t\t\t\tsearchOp = \"unknown value (\" + searchOperator + \")\";\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif(positioner !=null)\n\t\t{\n\t\t\toutput = output + \"\\t\" +\n\t\t\t\tMessageService.getTextMessage(\n\t\t\t\t\t\t\t\t\t\t  SQLState.LANG_POSITIONER,\n\t\t\t\t\t\t\t\t\t\t  searchOp,\n\t\t\t\t\t\t\t\t\t\t  String.valueOf(positioner.nColumns())) +\n\t\t\t\t\"\\n\";\n\n\t\t\toutput = output + \"\\t\" +\n\t\t\t\tMessageService.getTextMessage(\n\t\t\t\t\t\t\t\t\t\t\t  SQLState.LANG_ORDERED_NULL_SEMANTICS) +\n\t\t\t\t\"\\n\";\n\t\t\tboolean colSeen = false;\n\t\t\tfor (int position = 0; position < positioner.nColumns(); position++)\n\t\t\t{\n\t\t\t\tif (positioner.areNullsOrdered(position))\n\t\t\t\t{\n\t\t\t\t\toutput = output + position + \" \";\n\t\t\t\t\tcolSeen = true;\n\t\t\t\t}\n\n\t\t\t\tif (colSeen && position == positioner.nColumns() - 1) {\n\t\t\t\t\toutput = output +  \"\\n\";\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\t\treturn output;\n\t}"}
{"idx": 267, "target": 0, "func": "ExecAggregator getAggregatorInstance()\n\t\tthrows StandardException\n\t{\n\t\tExecAggregator aggregatorInstance;\n\t\tif (cachedAggregator == null)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\tClass aggregatorClass = cf.loadApplicationClass(aggInfo.getAggregatorClassName());\n\t\t\t\tObject agg = aggregatorClass.newInstance();\n\t\t\t\taggregatorInstance = (ExecAggregator)agg;\n\t\t\t\tcachedAggregator = aggregatorInstance;\n\n\t\t\t\taggregatorInstance.setup\n                    (\n                     cf,\n                     aggInfo.getAggregateName(),\n                     aggInfo.getResultDescription().getColumnInfo()[ 0 ].getType()\n                     );\n\n\t\t\t} catch (Exception e)\n\t\t\t{\n\t\t\t\tthrow StandardException.unexpectedUserException(e);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\taggregatorInstance = cachedAggregator.newAggregator();\n\t\t}\n\n\n\t\treturn aggregatorInstance;\n\t}"}
{"idx": 268, "target": 0, "func": "public void executeConstantAction(Activation activation)\n            throws StandardException {\n\n        LanguageConnectionContext lcc =\n            activation.getLanguageConnectionContext();\n        DataDictionary dd = lcc.getDataDictionary();\n        TransactionController tc = lcc.getTransactionExecute();\n        DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();\n\n        final String grantor = lcc.getCurrentUserId(activation);\n\n        dd.startWriting(lcc);\n\n        for (Iterator rIter = roleNames.iterator(); rIter.hasNext();) {\n            String role = (String)rIter.next();\n\n            if (role.equals(Authorizer.PUBLIC_AUTHORIZATION_ID)) {\n                throw StandardException.\n                    newException(SQLState.AUTH_PUBLIC_ILLEGAL_AUTHORIZATION_ID);\n            }\n\n            for (Iterator gIter = grantees.iterator(); gIter.hasNext();) {\n                String grantee = (String)gIter.next();\n\n                // check that role exists\n                RoleGrantDescriptor rdDef =\n                    dd.getRoleDefinitionDescriptor(role);\n\n                if (rdDef == null) {\n                    throw StandardException.\n                        newException(SQLState.ROLE_INVALID_SPECIFICATION, role);\n                }\n\n                // Check that role is granted to us (or PUBLIC) with\n                // WITH ADMIN option so we can grant it. For database\n                // owner, a role definition always fulfills this\n                // requirement.  If we implement granting with WITH ADMIN\n                // option later, we need to look for a grant to us (or\n                // PUBLIC) which has WITH ADMIN. The role definition\n                // descriptor will not suffice in that case, so we\n                // need something like:\n                //\n                // rdDef = dd.findRoleGrantWithAdminToRoleOrPublic(grantor)\n                // if (rdDef != null) {\n                //   :\n                if (grantor.equals(lcc.getDataDictionary().\n                                       getAuthorizationDatabaseOwner())) {\n                    // All ok, we are database owner\n                    if (SanityManager.DEBUG) {\n                        SanityManager.ASSERT(\n                            rdDef.getGrantee().equals(grantor),\n                            \"expected database owner in role grant descriptor\");\n                        SanityManager.ASSERT(\n                            rdDef.isWithAdminOption(),\n                            \"expected role definition to have ADMIN OPTION\");\n                    }\n                } else {\n                    throw StandardException.newException\n                        (SQLState.AUTH_ROLE_DBO_ONLY, \"GRANT role\");\n                }\n\n                // Has it already been granted?\n                RoleGrantDescriptor rgd =\n                    dd.getRoleGrantDescriptor(role, grantee, grantor);\n\n                if (rgd != null &&\n                        withAdminOption && !rgd.isWithAdminOption()) {\n\n                    // NOTE: Never called yet, withAdminOption not yet\n                    // implemented.\n\n                    // Remove old descriptor and add a new one with admin\n                    // option: cf. SQL 2003, section 12.5, general rule 3\n                    rgd.drop(lcc);\n                    rgd.setWithAdminOption(true);\n                    dd.addDescriptor(rgd,\n                                     null,  // parent\n                                     DataDictionary.SYSROLES_CATALOG_NUM,\n                                     false, // no duplicatesAllowed\n                                     tc);\n                } else if (rgd == null) {\n                    // Check if the grantee is a role (if not, it is a user)\n                    RoleGrantDescriptor granteeDef =\n                        dd.getRoleDefinitionDescriptor(grantee);\n\n                    if (granteeDef != null) {\n                        checkCircularity(role, grantee, grantor, tc, dd);\n                    }\n\n                    rgd = ddg.newRoleGrantDescriptor(\n                        dd.getUUIDFactory().createUUID(),\n                        role,\n                        grantee,\n                        grantor, // dbo for now\n                        withAdminOption,\n                        false);  // not definition\n                    dd.addDescriptor(\n                        rgd,\n                        null,  // parent\n                        DataDictionary.SYSROLES_CATALOG_NUM,\n                        false, // no duplicatesAllowed\n                        tc);\n                } // else exists already, no need to add\n            }\n        }\n    }"}
{"idx": 269, "target": 0, "func": "public void\topenCore() throws StandardException\n\t{\n\t    TransactionController tc;\n\n\t\tbeginTime = getCurrentTimeMillis();\n\t\tif (SanityManager.DEBUG)\n\t\t    SanityManager.ASSERT( ! isOpen, \"HashScanResultSet already open\");\n\n        // Get the current transaction controller\n        tc = activation.getTransactionController();\n\n\t\tinitIsolationLevel();\n\n\t\tif (startKeyGetter != null)\n\t\t{\n\t\t\tstartPosition = (ExecIndexRow) startKeyGetter.invoke(activation);\n\t\t\tif (sameStartStopPosition)\n\t\t\t{\n\t\t\t\tstopPosition = startPosition;\n\t\t\t}\n\t\t}\n\t\tif (stopKeyGetter != null)\n\t\t{\n\t\t\tstopPosition = (ExecIndexRow) stopKeyGetter.invoke(activation);\n\t\t}\n\n\t\t// Check whether there are any comparisons with unordered nulls\n\t\t// on either the start or stop position.  If there are, we can\n\t\t// (and must) skip the scan, because no rows can qualify\n\t\tif (skipScan(startPosition, stopPosition))\n\t\t{\n\t\t\t// Do nothing\n\t\t\t;\n\t\t}\n\t\telse if (! hashtableBuilt)\n\t\t{\n\t\t\tDataValueDescriptor[] startPositionRow = \n                startPosition == null ? null : startPosition.getRowArray();\n\t\t\tDataValueDescriptor[] stopPositionRow = \n                stopPosition == null ? null : stopPosition.getRowArray();\n\n            hashtable = \n                tc.createBackingStoreHashtableFromScan(\n                    conglomId,          // conglomerate to open\n                    (forUpdate ? TransactionController.OPENMODE_FORUPDATE : 0),\n                    lockMode,\n                    isolationLevel,\n                    accessedCols, \n                    startPositionRow,   \n                    startSearchOperator,\n                    scanQualifiers,\n                    stopPositionRow,   \n                    stopSearchOperator,\n                    -1,                 // no limit on total rows.\n                    keyColumns,      \n                    eliminateDuplicates,// remove duplicates?\n                    -1,                 // RESOLVE - is there a row estimate?\n                    maxCapacity,\n                    initialCapacity,    // in memory Hashtable initial capacity\n                    loadFactor,         // in memory Hashtable load factor\n                    runTimeStatisticsOn,\n\t\t\t\t\tskipNullKeyColumns,\n\t\t\t\t\tkeepAfterCommit);\n\n\n\t\t\tif (runTimeStatisticsOn)\n\t\t\t{\n\t\t\t\thashtableSize = hashtable.size();\n\n\t\t\t\tif (scanProperties == null)\n\t\t\t\t{\n\t\t\t\t\tscanProperties = new Properties();\n\t\t\t\t}\n\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tif (hashtable != null)\n\t\t\t\t\t{\n                        hashtable.getAllRuntimeStats(scanProperties);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch(StandardException se)\n\t\t\t\t{\n\t\t\t\t\t// ignore\n\t\t\t\t}\n\t\t\t}\n\n\n\t\t\t/* Remember that we created the hash table */\n\t\t\thashtableBuilt = true;\n\n\t\t\t/*\n\t\t\t** Tell the activation about the number of qualifying rows.\n\t\t\t** Do this only here, not in reopen, because we don't want\n\t\t\t** to do this costly operation too often.\n\t\t\t*/\n\t\t\tactivation.informOfRowCount(this, (long) hashtableSize);\n\t\t}\n\n\t    isOpen = true;\n\n\t\tresetProbeVariables();\n\n\t\tnumOpens++;\n\t\topenTime += getElapsedMillis(beginTime);\n\t}"}
{"idx": 270, "target": 0, "func": "private String printPosition(int searchOperator,\n\t\t\t\t\t\t\t\t GeneratedMethod positionGetter,\n\t\t\t\t\t\t\t\t ExecIndexRow eiRow)\n\t{\n\t\tString idt = \"\";\n\n\t\tString output = \"\";\n\t\tif (positionGetter == null)\n\t\t{\n\t\t\treturn \"\\t\" +\n\t\t\t\t\tMessageService.getTextMessage(SQLState.LANG_NONE) +\n\t\t\t\t\t\"\\n\";\n\t\t}\n\n\t\tExecIndexRow\tpositioner = null;\n\n\t\ttry\n\t\t{\n\t\t\tpositioner = (ExecIndexRow) positionGetter.invoke(activation);\n\t\t}\n\t\tcatch (StandardException e)\n\t\t{\n\n\t\t\tif (eiRow == null)\n\t\t\t{\n\t\t\t\treturn \"\\t\" + MessageService.getTextMessage(\n\t\t\t\t\t\t\t\t\t\t\tSQLState.LANG_POSITION_NOT_AVAIL);\n\t\t\t}\n\t\t\treturn \"\\t\" + MessageService.getTextMessage(\n\t\t\t\t\t\t\tSQLState.LANG_UNEXPECTED_EXC_GETTING_POSITIONER) +\n\t\t\t\t\t\t\t\"\\n\";\n\t\t}\n\n\t\tif (positioner == null)\n\t\t{\n\t\t\treturn \"\\t\" +\n\t\t\t\t\tMessageService.getTextMessage(SQLState.LANG_NONE) +\n\t\t\t\t\t\"\\n\";\n\t\t}\n\n\t\tString searchOp = null;\n\n\t\tswitch (searchOperator)\n\t\t{\n\t\t\tcase ScanController.GE:\n\t\t\t\tsearchOp = \">=\";\n\t\t\t\tbreak;\n\n\t\t\tcase ScanController.GT:\n\t\t\t\tsearchOp = \">\";\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t{\n\t\t\t\t\tSanityManager.THROWASSERT(\"Unknown search operator \" +\n\t\t\t\t\t\t\t\t\t\t\t\tsearchOperator);\n\t\t\t\t}\n\n\t\t\t\t// This is not internationalized because we should never\n\t\t\t\t// reach here.\n\t\t\t\tsearchOp = \"unknown value (\" + searchOperator + \")\";\n\t\t\t\tbreak;\n\t\t}\n\n\t\toutput += \"\\t\" + MessageService.getTextMessage(\n\t\t\t\t\t\t\t\t\t\tSQLState.LANG_POSITIONER,\n\t\t\t\t\t\t\t\t\t\tsearchOp,\n\t\t\t\t\t\t\t\t\t\tString.valueOf(positioner.nColumns()))\n\t\t\t\t\t\t\t\t\t\t+ \"\\n\";\n\t\t\t\n\t\toutput += \"\\t\" + MessageService.getTextMessage(\n\t\t\t\t\t\t\t\t\t\tSQLState.LANG_ORDERED_NULL_SEMANTICS) +\n\t\t\t\t\t\t\t\t\t\t\"\\n\";\n\t\tboolean colSeen = false;\n\t\tfor (int position = 0; position < positioner.nColumns(); position++)\n\t\t{\n\t\t\tif (positioner.areNullsOrdered(position))\n\t\t\t{\n\t\t\t\toutput = output + position + \" \";\n\t\t\t\tcolSeen = true;\n\t\t\t}\n\n\t\t\tif (colSeen && position == positioner.nColumns() - 1) {\n\t\t\t\toutput = output +  \"\\n\";\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn output;\n\t}"}
{"idx": 271, "target": 0, "func": "public ExecRow\tgetNextRowCore() throws StandardException {\n\t    ExecRow result = null;\n\t\tDataValueDescriptor[] columns = null;\n\n\t\tbeginTime = getCurrentTimeMillis();\n\t    if ( isOpen )\n\t    {\n\t\t\t/* We use a do/while loop to ensure that we continue down\n\t\t\t * the duplicate chain, if one exists, until we find a\n\t\t\t * row that matches on all probe predicates (or the\n\t\t\t * duplicate chain is exhausted.)\n\t\t\t */\n\t\t\tdo \n\t\t\t{\n\t\t\t\tif (firstNext)\n\t\t\t\t{\t\t\t  \n\t\t\t\t\tfirstNext = false;\n\n\t\t\t\t\t/* Hash key could be either a single column or multiple \n                     * columns.  If a single column, then it is the datavalue \n                     * wrapper, otherwise it is a KeyHasher.\n\t\t\t\t\t */\n\t\t\t\t\tObject hashEntry;\n\t\t\t\t\tif (keyColumns.length == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\thashEntry = ht.get(nextQualifiers[0][0].getOrderable());\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tKeyHasher mh = \n                            new KeyHasher(keyColumns.length);\n\n\t\t\t\t\t\tfor (int index = 0; index < keyColumns.length; index++)\n\t\t\t\t\t\t{\n                            // RESOLVE (mikem) - will need to change when we\n                            // support OR's in qualifiers.\n\t\t\t\t\t\t\tmh.setObject(\n                                index, nextQualifiers[0][index].getOrderable());\n\t\t\t\t\t\t}\n\t\t\t\t\t\thashEntry = ht.get(mh);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (hashEntry instanceof List)\n\t\t\t\t\t{\n\t\t\t\t\t\tentryVector = (List) hashEntry;\n\t\t\t\t\t\tentryVectorSize = entryVector.size();\n\t\t\t\t\t\tcolumns = \n                            (DataValueDescriptor[]) entryVector.get(0);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tentryVector = null;\n\t\t\t\t\t\tentryVectorSize = 0;\n\t\t\t\t\t\tcolumns = (DataValueDescriptor[]) hashEntry;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (numFetchedOnNext < entryVectorSize)\n\t\t\t\t{\n\t\t\t\t\t// We are walking a list and there are more rows left.\n\t\t\t\t\tcolumns = (DataValueDescriptor[]) \n                        entryVector.get(numFetchedOnNext);\n\t\t\t\t}\n\n\t\t\t\tif (columns != null)\n\t\t\t\t{\n\t\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\t\t{\n\t\t\t\t\t\t// Columns is really a Storable[]\n\t\t\t\t\t\tfor (int i = 0; i < columns.length; i++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (! (columns[0] instanceof Storable))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tSanityManager.THROWASSERT(\n\t\t\t\t\t\t\t\t\"columns[\" + i + \"] expected to be Storable, not \" +\n\t\t\t\t\t\t\t\tcolumns[i].getClass().getName());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// See if the entry satisfies all of the other qualifiers\n\t\t\t\t\tboolean qualifies = true;\n\n\t\t\t\t\t/* We've already \"evaluated\" the 1st keyColumns qualifiers \n                     * when we probed into the hash table, but we need to \n                     * evaluate them again here because of the behavior of \n                     * NULLs.  NULLs are treated as equal when building and \n                     * probing the hash table so that we only get a single \n                     * entry.  However, NULL does not equal NULL, so the \n                     * compare() method below will eliminate any row that\n\t\t\t\t\t * has a key column containing a NULL.\n\t\t\t\t\t */\n\n                    // RESOLVE (mikem) will have to change when qualifiers \n                    // support OR's.\n\n                    if (SanityManager.DEBUG)\n                    {\n                        // we don't support 2 d qualifiers yet.\n                        SanityManager.ASSERT(nextQualifiers.length == 1);\n                    }\n\t\t\t\t\tfor (int index = 0; index < nextQualifiers[0].length; index++)\n\t\t\t\t\t{\n                        Qualifier q = nextQualifiers[0][index];\n\n\t\t\t\t\t\tqualifies = \n                            columns[q.getColumnId()].compare(\n                                q.getOperator(),\n                                q.getOrderable(),\n                                q.getOrderedNulls(),\n                                q.getUnknownRV());\n\n\t\t\t\t\t\tif (q.negateCompareResult()) \n\t\t\t\t\t\t{ \n\t\t\t\t\t\t\tqualifies = !(qualifies);\n\t\t\t\t\t\t} \n\n\t\t\t\t\t\t// Stop if any predicate fails\n\t\t\t\t\t\tif (! qualifies)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (qualifies)\n\t\t\t\t\t{\n\n\t\t\t\t\t\tfor (int index = 0; index < columns.length; index++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tnextCandidate.setColumn(index + 1, columns[index]);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tresult = doProjection(nextCandidate);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tresult = null;\n\t\t\t\t\t}\n\n\t\t\t\t\tnumFetchedOnNext++;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tresult = null;\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (result == null && numFetchedOnNext < entryVectorSize);\n\t\t}\n\n\t\tsetCurrentRow(result);\n\n\t\tnextTime += getElapsedMillis(beginTime);\n\n\t\tif (runTimeStatsOn)\n\t\t{\n\t\t\tif (! isTopResultSet)\n\t\t\t{\n\t\t\t\t/* This is simply for RunTimeStats */\n\t\t\t\t/* We first need to get the subquery tracking array via the StatementContext */\n\t\t\t\tStatementContext sc = activation.getLanguageConnectionContext().getStatementContext();\n\t\t\t\tsubqueryTrackingArray = sc.getSubqueryTrackingArray();\n\t\t\t}\n\t\t\tnextTime += getElapsedMillis(beginTime);\n\t\t}\n    \treturn result;\n\t}"}
{"idx": 272, "target": 0, "func": "public void open(boolean[] fixOnUpdate)\n\t\t throws StandardException\n\t{\n\t\tif (SanityManager.DEBUG)\n\t\t    SanityManager.ASSERT( ! isOpen, \"IndexSetChanger already open\");\n\n\t\tthis.fixOnUpdate = fixOnUpdate;\n\t\tisOpen = true;\n\t}"}
{"idx": 273, "target": 0, "func": "public RowLocation[] getAutoincRowLocation()\n\t{\n\t\treturn autoincRowLocation;\n\t}"}
{"idx": 274, "target": 0, "func": "public DataValueDescriptor[] getRowArray() {\n\t\treturn column;\n\t}"}
{"idx": 275, "target": 0, "func": "public void setRowArray(DataValueDescriptor[] value)\n\t{\n\t\tcolumn = value;\n\t}"}
{"idx": 276, "target": 1, "func": "public Timestamp getEndCompilationTimestamp()\n\t{\n\t\treturn endCompilationTimestamp;\n\t}"}
{"idx": 277, "target": 1, "func": "public Timestamp getEndExecutionTimestamp()\n\t{\n\t\treturn endExecutionTimestamp;\n\t}"}
{"idx": 278, "target": 1, "func": "public Timestamp getBeginCompilationTimestamp()\n\t{\n\t\treturn beginCompilationTimestamp;\n\t}"}
{"idx": 279, "target": 1, "func": "public Timestamp getBeginExecutionTimestamp()\n\t{\n\t\treturn beginExecutionTimestamp;\n\t}"}
{"idx": 280, "target": 0, "func": "public XPLAINVisitor getXPLAINVisitor()\n        throws StandardException\n    {\n        try\n        {\n            LanguageConnectionContext lcc = ConnectionUtil.getCurrentLCC();\n            String schema = lcc.getXplainSchema();\n            if (schema != currentSchema)\n            {\n                currentSchema = schema;\n                if (currentSchema == null)\n                    currentVisitor = new XPLAINDefaultVisitor();\n                else\n                    currentVisitor = new XPLAINSystemTableVisitor();\n            }\n        }\n        catch (SQLException e)\n        {\n            throw StandardException.plainWrapException(e);\n        }\n        return currentVisitor;\n    }"}
{"idx": 281, "target": 0, "func": "private void addArraysToSystemCatalogs()\n        throws StandardException, SQLException\n    {\n        Iterator iter;\n        boolean statsSave = lcc.getRunTimeStatisticsMode();\n        lcc.setRunTimeStatisticsMode(false);\n        Connection conn = getDefaultConn();\n\n        PreparedStatement ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_RESULTSETS\"));\n        iter = rsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINResultSetDescriptor rset =\n                (XPLAINResultSetDescriptor)iter.next();\n            rset.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        // add the resultset timings descriptors, if timing is on\n        if(considerTimingInformation)\n        {\n            ps = conn.prepareStatement(\n                (String)lcc.getXplainStatement(\"SYSXPLAIN_RESULTSET_TIMINGS\"));\n            iter = rsetsTimings.iterator();\n            while (iter.hasNext())\n            {\n                XPLAINResultSetTimingsDescriptor rsetT =\n                    (XPLAINResultSetTimingsDescriptor)iter.next();\n                rsetT.setStatementParameters(ps);\n                ps.executeUpdate();\n            }\n            ps.close();\n        }\n        ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_SCAN_PROPS\"));\n        iter = scanrsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINScanPropsDescriptor scanProps =\n                (XPLAINScanPropsDescriptor)iter.next();\n            scanProps.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_SORT_PROPS\"));\n        iter = sortrsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINSortPropsDescriptor sortProps =\n                (XPLAINSortPropsDescriptor)iter.next();\n            sortProps.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        conn.close();\n        lcc.setRunTimeStatisticsMode(statsSave);\n    }"}
{"idx": 282, "target": 0, "func": "private void addStmtDescriptorsToSystemCatalog()\n        throws StandardException, SQLException\n    {\n        boolean statsSave = lcc.getRunTimeStatisticsMode();\n        lcc.setRunTimeStatisticsMode(false);\n        Connection conn = getDefaultConn();\n        PreparedStatement ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_STATEMENTS\"));\n        stmt.setStatementParameters(ps);\n        ps.executeUpdate();\n        ps.close();\n            \n        if(considerTimingInformation)\n        {\n            ps = conn.prepareStatement(\n                (String)lcc.getXplainStatement(\"SYSXPLAIN_STATEMENT_TIMINGS\"));\n            stmtTimings.setStatementParameters(ps);\n            ps.executeUpdate();\n            ps.close();\n        }\n        conn.close();\n        lcc.setRunTimeStatisticsMode(statsSave);\n    }"}
{"idx": 283, "target": 0, "func": "private void addArraysToSystemCatalogs()\n        throws StandardException, SQLException\n    {\n        Iterator iter;\n        boolean statsSave = lcc.getRunTimeStatisticsMode();\n        lcc.setRunTimeStatisticsMode(false);\n        Connection conn = getDefaultConn();\n\n        PreparedStatement ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_RESULTSETS\"));\n        iter = rsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINResultSetDescriptor rset =\n                (XPLAINResultSetDescriptor)iter.next();\n            rset.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        // add the resultset timings descriptors, if timing is on\n        if(considerTimingInformation)\n        {\n            ps = conn.prepareStatement(\n                (String)lcc.getXplainStatement(\"SYSXPLAIN_RESULTSET_TIMINGS\"));\n            iter = rsetsTimings.iterator();\n            while (iter.hasNext())\n            {\n                XPLAINResultSetTimingsDescriptor rsetT =\n                    (XPLAINResultSetTimingsDescriptor)iter.next();\n                rsetT.setStatementParameters(ps);\n                ps.executeUpdate();\n            }\n            ps.close();\n        }\n        ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_SCAN_PROPS\"));\n        iter = scanrsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINScanPropsDescriptor scanProps =\n                (XPLAINScanPropsDescriptor)iter.next();\n            scanProps.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_SORT_PROPS\"));\n        iter = sortrsets.iterator();\n        while (iter.hasNext())\n        {\n            XPLAINSortPropsDescriptor sortProps =\n                (XPLAINSortPropsDescriptor)iter.next();\n            sortProps.setStatementParameters(ps);\n            ps.executeUpdate();\n        }\n        ps.close();\n\n        conn.close();\n        lcc.setRunTimeStatisticsMode(statsSave);\n    }"}
{"idx": 284, "target": 0, "func": "private void addStmtDescriptorsToSystemCatalog()\n        throws StandardException, SQLException\n    {\n        boolean statsSave = lcc.getRunTimeStatisticsMode();\n        lcc.setRunTimeStatisticsMode(false);\n        Connection conn = getDefaultConn();\n        PreparedStatement ps = conn.prepareStatement(\n            (String)lcc.getXplainStatement(\"SYSXPLAIN_STATEMENTS\"));\n        stmt.setStatementParameters(ps);\n        ps.executeUpdate();\n        ps.close();\n            \n        if(considerTimingInformation)\n        {\n            ps = conn.prepareStatement(\n                (String)lcc.getXplainStatement(\"SYSXPLAIN_STATEMENT_TIMINGS\"));\n            stmtTimings.setStatementParameters(ps);\n            ps.executeUpdate();\n            ps.close();\n        }\n        conn.close();\n        lcc.setRunTimeStatisticsMode(statsSave);\n    }"}
{"idx": 285, "target": 0, "func": "public static String getLockGranularityCode(String lockString){\n         lockString = lockString.toUpperCase();\n         if(lockString.endsWith(\"TABLE\")){\n             return LOCK_GRANULARITY_TABLE;\n         } else {\n             return LOCK_GRANULARITY_ROW;\n         }\n     }"}
{"idx": 286, "target": 0, "func": "public static String getLockModeCode(String lockString){\n         lockString = lockString.toUpperCase();\n         if(lockString.startsWith(\"EXCLUSIVE\")){\n             return LOCK_MODE_EXCLUSIVE;\n         } else\n         if(lockString.startsWith(\"SHARE\")){\n             return LOCK_MODE_SHARE;\n         } else\n         if(lockString.startsWith(\"INSTANTANEOUS\")){\n             int start = \"INSTANTANEOUS\".length();\n             int length = lockString.length();\n             String sub = lockString.substring(start+1, length);\n             if (sub.startsWith(\"EXCLUSIVE\")){\n                 return LOCK_MODE_INSTANTENOUS_EXCLUSIVE;\n             } else \n             if (sub.startsWith(\"SHARE\")){\n                 return LOCK_MODE_INSTANTENOUS_SHARE;\n             } else \n             return null;\n         } else\n         return null;\n     }"}
{"idx": 287, "target": 0, "func": "public static String getStatementType(String SQLText){\n         String type = \"\";\n         String text = SQLText.toUpperCase().trim();\n         if (text.startsWith(\"CALL\")){\n             type = CALL_STMT_TYPE;\n         } else \n         if (text.startsWith(\"SELECT\")){\n             if (text.indexOf(\"~\")>-1){\n                 type = SELECT_APPROXIMATE_STMT_TYPE;\n             } else {\n                 type = SELECT_STMT_TYPE;\n             }\n         } else\n         if (text.startsWith(\"DELETE\")){\n             type = DELETE_STMT_TYPE;\n         } else\n         if (text.startsWith(\"INSERT\")){\n             type = INSERT_STMT_TYPE;\n         } else\n         if (text.startsWith(\"UPDATE\")){\n             type = UPDATE_STMT_TYPE;\n         } else\n         if (text.startsWith(\"CREATE\") ||\n             text.startsWith(\"ALTER\")  ||\n             text.startsWith(\"DROP\")     ){\n             type = DDL_STMT_TYPE;\n         }\n         return type;\n     }"}
{"idx": 288, "target": 0, "func": "public static String getHashKeyColumnNumberString(int[] hashKeyColumns){\n        // original derby encoding\n        String hashKeyColumnString;\n        if (hashKeyColumns.length == 1)\n        {\n            hashKeyColumnString = MessageService.getTextMessage(\n                                                        SQLState.RTS_HASH_KEY) +\n                                    \" \" + hashKeyColumns[0];\n        }\n        else\n        {\n            hashKeyColumnString = MessageService.getTextMessage(\n                                                    SQLState.RTS_HASH_KEYS) +\n                                    \" (\" + hashKeyColumns[0];\n            for (int index = 1; index < hashKeyColumns.length; index++)\n            {\n                hashKeyColumnString = hashKeyColumnString + \",\" + hashKeyColumns[index];\n            }\n            hashKeyColumnString = hashKeyColumnString + \")\";\n        }\n         return hashKeyColumnString;\n     }"}
{"idx": 289, "target": 0, "func": "public void checkConsistency()\n\t\tthrows StandardException\n    {\n\t\tControlRow root = null;\n\n        try\n        {\n            if (this.container == null)\n            {\n                throw(StandardException.newException(\n                        SQLState.BTREE_IS_CLOSED, new Long(err_containerid)));\n            }\n\n            if (SanityManager.DEBUG)\n                SanityManager.ASSERT(this.init_conglomerate.format_ids != null);\n\n            root = ControlRow.get(this, BTree.ROOTPAGEID);\n\n            int actualpages = root.checkConsistency(this, null, true);\n\n            // RESOLVE (mikem) - anything useful to assert about number of pages\n            // in the tree?\n        }\n        finally\n        {\n            if (root != null)\n                root.release();\n        }\n    }"}
{"idx": 290, "target": 1, "func": "protected boolean _lockScanRow(\n    OpenBTree               open_btree,\n    BTree                   btree,\n    BTreeRowPosition        pos,\n    boolean                 request_row_lock,\n    FetchDescriptor         lock_fetch_desc,\n    DataValueDescriptor[]   lock_template,\n    RowLocation             lock_row_loc,\n    boolean                 previous_key_lock,\n    boolean                 forUpdate,\n    int                     lock_operation)\n\t\tthrows StandardException\n    {\n        boolean latch_released = false;\n        B2I     b2i            = (B2I) btree;\n\n        if (request_row_lock)\n        {\n            // In order to implement a serialized scan based on previous\n            // key locking, this method acquires a row lock on\n            // the base table's row from the index row at [startpage/startslot].\n            // This will be the 'previous key'.\n\n            if (pos.current_slot == 0)\n            {\n                // this call will take care of searching left in the btree\n                // to find the previous row to lock, 0 is the control row and\n                // not a valid thing to lock as a previous key.\n\n                // it is ok to call the non-scan as this is just a special\n                // case of a previous key lock call.  The only scan code that\n                // will call this routine with slot == 0 will retry if this\n                // routine returns that a latch was released.\n\n                latch_released = \n                    !lockNonScanPreviousRow(\n                        btree,\n                        pos.current_leaf,\n                        1 /* lock row previous to row at slot 1 */, \n                        lock_fetch_desc,\n                        lock_template,\n                        lock_row_loc,\n                        open_btree, \n                        lock_operation,\n                        TransactionManager.LOCK_COMMIT_DURATION);\n\n                // special test to see if latch release code works\n                if (SanityManager.DEBUG)\n                {\n                    latch_released = \n                        OpenBTree.test_errors(\n                            open_btree,\n                            \"B2iRowLocking3_1_lockScanRow\",\n                            null, // Don't save position since the operation\n                                  // will be retried if the latch was released.\n                                  // See also comment above call to\n                                  // lockNonScanPreviousRow().\n                            this, pos.current_leaf, latch_released);\n                }\n            }\n            else\n            {\n                // Just lock the row at \"slot\"\n\n                latch_released = \n                    !lockRowOnPage(\n                        btree,\n                        pos.current_leaf, \n                        (LeafControlRow) null /* no other latch currently */,\n                        pos.current_slot, \n                        pos,\n                        lock_fetch_desc,\n                        lock_template,\n                        lock_row_loc,\n                        lock_operation,\n                        TransactionManager.LOCK_COMMIT_DURATION);\n\n                // special test to see if latch release code works\n                if (SanityManager.DEBUG)\n                {\n                    latch_released = \n                        OpenBTree.test_errors(\n                            open_btree,\n                            \"B2iRowLocking3_2_lockScanRow\", pos,\n                            this, pos.current_leaf, latch_released);\n                }\n            }\n        }\n\n        return(!latch_released);\n    }"}
{"idx": 291, "target": 0, "func": "public byte[] getData() {\n\t\treturn data;\n\t}"}
{"idx": 292, "target": 0, "func": "public byte[] getBranchQualifier()\n    {\n        return(branch_id);\n    }"}
{"idx": 293, "target": 0, "func": "public byte[] getGlobalTransactionId()\n    {\n        return(global_id);\n    }"}
{"idx": 294, "target": 0, "func": "public static void main(String[] args) {\n    if (args.length > 0) {\n      //Get the first argument passed in.\n      URLCheck aCheck = new URLCheck(args[0]);\n    }\n  }"}
{"idx": 295, "target": 1, "func": "public int[] getColumnWidthList() { return columnWidths; }"}
{"idx": 296, "target": 1, "func": "public int[] getColumnDisplayList() { return displayColumns; }"}
{"idx": 297, "target": 1, "func": "public int[] getColumnWidthList() { return columnWidths; }"}
{"idx": 298, "target": 1, "func": "public int[] getColumnDisplayList() { return displayColumns; }"}
{"idx": 299, "target": 0, "func": "private int runScriptGuts() {\n\n        int scriptErrorCount = 0;\n\t\t\n\t\tboolean done = false;\n\t\tString command = null;\n\t\twhile (!ijParser.exit && !done) {\n\t\t\ttry{\n\t\t\t\tijParser.setConnection(connEnv[currCE], (numConnections > 1));\n\t\t\t} catch(Throwable t){\n\t\t\t\t//do nothing\n\t\t\t\t}\n\n\t\t\tconnEnv[currCE].doPrompt(true, out);\n   \t\t\ttry {\n   \t\t\t\tcommand = null;\n\t\t\t\tout.flush();\n\t\t\t\tcommand = commandGrabber[currCE].nextStatement();\n\n\t\t\t\t// if there is no next statement,\n\t\t\t\t// pop back to the top saved grabber.\n\t\t\t\twhile (command == null && ! oldGrabbers.empty()) {\n\t\t\t\t\t// close the old input file if not System.in\n\t\t\t\t\tif (fileInput) commandGrabber[currCE].close();\n\t\t\t\t\tcommandGrabber[currCE] = (StatementFinder)oldGrabbers.pop();\n\t\t\t\t\tif (oldGrabbers.empty())\n\t\t\t\t\t\tfileInput = initialFileInput;\n\t\t\t\t\tcommand = commandGrabber[currCE].nextStatement();\n\t\t\t\t}\n\n\t\t\t\t// if there are no grabbers left,\n\t\t\t\t// we are done.\n\t\t\t\tif (command == null && oldGrabbers.empty()) {\n\t\t\t\t\tdone = true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tboolean\telapsedTimeOn = ijParser.getElapsedTimeState();\n\t\t\t\t\tlong\tbeginTime = 0;\n\t\t\t\t\tlong\tendTime;\n\n\t\t\t\t\tif (fileInput) {\n\t\t\t\t\t\tout.println(command+\";\");\n\t\t\t\t\t\tout.flush();\n\t\t\t\t\t}\n\n\t\t\t\t\tcharStream.ReInit(new StringReader(command), 1, 1);\n\t\t\t\t\tijTokMgr.ReInit(charStream);\n\t\t\t\t\tijParser.ReInit(ijTokMgr);\n\n\t\t\t\t\tif (elapsedTimeOn) {\n\t\t\t\t\t\tbeginTime = System.currentTimeMillis();\n\t\t\t\t\t}\n\n\t\t\t\t\tijResult result = ijParser.ijStatement();\n\t\t\t\t\tdisplayResult(out,result,connEnv[currCE].getConnection());\n\n\t\t\t\t\t// if something went wrong, an SQLException or ijException was thrown.\n\t\t\t\t\t// we can keep going to the next statement on those (see catches below).\n\t\t\t\t\t// ijParseException means we try the SQL parser.\n\n\t\t\t\t\t/* Print the elapsed time if appropriate */\n\t\t\t\t\tif (elapsedTimeOn) {\n\t\t\t\t\t\tendTime = System.currentTimeMillis();\n\t\t\t\t\t\tout.println(langUtil.getTextMessage(\"IJ_ElapTime0Mil\", \n\t\t\t\t\t\tlangUtil.getNumberAsString(endTime - beginTime)));\n\t\t\t\t\t}\n\n\t\t\t\t\t// would like when it completes a statement\n\t\t\t\t\t// to see if there is stuff after the ;\n\t\t\t\t\t// and before the <EOL> that we will IGNORE\n\t\t\t\t\t// (with a warning to that effect)\n\t\t\t\t}\n\n    \t\t\t} catch (ParseException e) {\n \t\t\t\t\tif (command != null)\n                        scriptErrorCount += doCatch(command) ? 0 : 1;\n\t\t\t\t} catch (TokenMgrError e) {\n \t\t\t\t\tif (command != null)\n                        scriptErrorCount += doCatch(command) ? 0 : 1;\n    \t\t\t} catch (SQLException e) {\n                    scriptErrorCount++;\n\t\t\t\t\t// SQL exception occurred in ij's actions; print and continue\n\t\t\t\t\t// unless it is considered fatal.\n\t\t\t\t\thandleSQLException(out,e);\n    \t\t\t} catch (ijException e) {\n                    scriptErrorCount++;\n\t\t\t\t\t// exception occurred in ij's actions; print and continue\n    \t\t\t  \tout.println(langUtil.getTextMessage(\"IJ_IjErro0\",e.getMessage()));\n\t\t\t\t\tdoTrace(e);\n    \t\t\t} catch (Throwable e) {\n                    scriptErrorCount++;\n    \t\t\t  \tout.println(langUtil.getTextMessage(\"IJ_JavaErro0\",e.toString()));\n\t\t\t\t\tdoTrace(e);\n\t\t\t\t}\n\n\t\t\t/* Go to the next connection/user, if there is one */\n\t\t\tcurrCE = ++currCE % connEnv.length;\n\t\t}\n        \n        return scriptErrorCount;\n\t}"}
{"idx": 300, "target": 1, "func": "public TreeNode[] getData() {\n        return data;\n    }"}
{"idx": 301, "target": 0, "func": "private void createXMLData(String qry, int x) throws SQLException{\n\n        PreparedStatement ps = conn.prepareStatement(qry);\n        ps.setString(1, getQuery());\n\n        ResultSet results = ps.executeQuery();\n\n        int i=0;\n        while(results.next())\n        {\n            String text= results.getString(1);\n\n            if(text != null){\n\n                /*Removing possible occurrences of special XML characters\n                 * from XML node attributes in XML representation.*/\n                text = escapeInAttribute(text);\n\n                switch(x){\n                case ID:\n                    data[i].setId(text+\" \");\n                    break;\n                case P_ID:\n                    data[i].setParent(text);\n                    break;\n                case NODE_TYPE:\n                    data[i].setNodeType(text+\" \");\n                    break;\n                case NO_OF_OPENS:\n                    data[i].setNoOfOpens(text+\" \");\n                    break;\n                case INPUT_ROWS:\n                    data[i].setInputRows(text+\" \");\n                    break;\n                case RETURNED_ROWS:\n                    data[i].setReturnedRows(text+\" \");\n                    break;\n                case VISITED_PAGES:\n                    data[i].setVisitedPages(text+\" \");\n                    break;\n                case SCAN_QUALIFIERS:\n                    data[i].setScanQualifiers(text+\" \");\n                    break;\n                case NEXT_QUALIFIERS:\n                    data[i].setNextQualifiers(text+\" \");\n                    break;\n                case SCANNED_OBJECT:\n                    data[i].setScannedObject(text+\" \");\n                    break;\n                case SCAN_TYPE:\n                    data[i].setScanType(text+\" \");\n                    break;\n                case SORT_TYPE:\n                    data[i].setSortType(text+\" \");\n                    break;\n                case NO_OF_OUTPUT_ROWS_BY_SORTER:\n                    data[i].setSorterOutput(text+\" \");\n                    break;\n                }\n            }\n            else{\n                /*Other attributes are omitted from the xml document\n                 * if they're null.\n                 * P_ID can be null at the root.\n                 * */\n                switch(x){\n                case P_ID:\n                    data[i].setParent(text+\"\");\n                    break;\n                }\n            }\n            i++;\n        }\n        results.close();\n        ps.close();\n    }"}
{"idx": 302, "target": 0, "func": "public byte[] getBytes(int columnIndex) throws SQLException\n    {\n        String  columnValue = getString( columnIndex );\n\n        if ( columnValue == null ) { return null; }\n        else\n        {\n            try {\n                return columnValue.getBytes( \"UTF-8\" );\n            } catch (Throwable t) { throw new SQLException( t.getMessage() ); }\n        }\n    }"}
{"idx": 303, "target": 0, "func": "public static void main( String[] arg)\n    {\n        String[] classAndInterfaceList = {\"org.apache.derby.iapi.types.DataValueDescriptor\"};\n        if(arg.length > 0)\n            classAndInterfaceList = arg;\n        Class[] interfaceList = new Class[classAndInterfaceList.length];\n        int interfaceCount = 0;\n        Class[] classList = new Class[classAndInterfaceList.length];\n        int classCount = 0;\n\n        Class classSizeClass = ClassSize.class; // Make sure that the garbage collector does not unload it\n        ClassSize.setDummyCatalog();\n        /* Most of the classes we will catalog invoke ClassSize.estimateBaseFromCatalog in\n         * their static initializer. This dummy the catalog out so that this will not generate\n         * errors. We will not actually use the classes, just examine their fields.\n         */\n\n        for( int i = 0; i < classAndInterfaceList.length; i++)\n        {\n            Class cls = null;\n            try\n            {\n                cls = Class.forName( classAndInterfaceList[i]);\n            }\n            catch( ClassNotFoundException cnfe)\n            {\n                System.err.println( \"*** Could not find class \" + classAndInterfaceList[i]);\n                System.exit(1);\n            }\n            if( cls.isInterface())\n                interfaceList[ interfaceCount++] = cls;\n            else\n                classList[ classCount++] = cls;\n        }\n\n        String WS = System.getProperty( \"WS\");\n        if( WS == null)\n        {\n            System.err.println( \"*** WS is not set.\");\n            System.exit(1);\n        }\n\n        StringBuffer baseDir = new StringBuffer( System.getProperty( \"classDir\", \"\"));\n        if( baseDir.length() == 0)\n        {\n            baseDir.append( WS);\n            baseDir.append( '/');\n            baseDir.append( \"classes\");\n        }\n        int baseDirLength = baseDir.length();\n\n        StringBuffer packagePrefix = new StringBuffer( );\n\n        Hashtable<String, int[]> classSizes = new Hashtable<String, int[]>();\n\n        ClassSizeCrawler crawler = new ClassSizeCrawler(interfaceList, interfaceCount, classSizes);\n\n        if( interfaceCount > 0)\n        {\n            boolean gotPrefix = false;\n            // Crawl through the class hierarchies for classes implementing the interfaces\n            for( Enumeration e = System.getProperties().propertyNames();\n                 e.hasMoreElements();)\n            {\n                String propertyName = (String) e.nextElement();\n                if( propertyName.equals( \"prefix\") || propertyName.startsWith( \"prefix.\"))\n                {\n                    gotPrefix = true;\n                    packagePrefix.setLength( 0);\n                    packagePrefix.append( System.getProperty( propertyName));\n                    baseDir.setLength( baseDirLength);\n                    if( packagePrefix.length() > 0)\n                    {\n                        baseDir.append( '/');\n                        for( int offset = 0; offset < packagePrefix.length(); offset++)\n                        {\n                            char c = packagePrefix.charAt( offset);\n                            if( c == '.')\n                                baseDir.append( '/');\n                            else\n                                baseDir.append( c);\n                        }\n                    }\n                    crawler.crawl( new File( baseDir.toString()), packagePrefix);\n                }\n            }\n            if( ! gotPrefix)\n            {\n                System.err.println( \"*** Could not search the class hierarchy because no starting\");\n                System.err.println( \"    prefixes where specified.\");\n                System.exit(1);\n            }\n        }\n        for( int i = 0; i < classCount; i++)\n            crawler.addClass( classList[i]);\n\n        baseDir.setLength( baseDirLength);\n        String outputFileName =\n          System.getProperty( \"out\", WS + \"/java/org.apache.derby.iapi.services.cache.ClassSizeCatalog.java\");\n        try\n        {\n            PrintWriter out = new PrintWriter( new FileWriter( outputFileName));\n            out.print( \"/*\\n\\n\" +\n\n                       \"   Licensed to the Apache Software Foundation (ASF) under one or more\\n\" +\n                       \"   contributor license agreements.  See the NOTICE file distributed with\\n\" +\n                       \"   this work for additional information regarding copyright ownership.\\n\" +\n                       \"   The ASF licenses this file to You under the Apache License, Version 2.0\\n\" +\n                       \"   (the \\\"License\\\"); you may not use this file except in compliance with\\n\" +\n                       \"   the License.  You may obtain a copy of the License at\\n\" +\n                       \"\\n\" +\n                       \"      http://www.apache.org/licenses/LICENSE-2.0\\n\" +\n                       \"\\n\" +\n                       \"   Unless required by applicable law or agreed to in writing, software\\n\" +\n                       \"   distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n\" +\n                       \"   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n\" +\n                       \"   See the License for the specific language governing permissions and\\n\" +\n                       \"   limitations under the License.\\n\" +\n                       \" */\\n\");\n            out.print( \"package org.apache.derby.iapi.services.cache;\\n\" +\n                       \"import java.util.Hashtable;\\n\" +\n                       \"class ClassSizeCatalog extends java.util.Hashtable\\n\" +\n                       \"{\\n\" +\n                       \"    ClassSizeCatalog()\\n\" +\n                       \"    {\\n\");\n            for( Enumeration e = classSizes.keys();\n                 e.hasMoreElements();)\n            {\n                String className = (String) e.nextElement();\n                int[] coeff = (int[]) classSizes.get( className);\n                out.print( \"        put( \\\"\" + className + \"\\\", new int[]{\" + coeff[0] + \",\" + coeff[1] + \"});\\n\");\n            }\n            out.print(\"    }\\n\" +\n                      \"}\\n\");\n            out.flush();\n            out.close();\n        }\n        catch( IOException ioe)\n        {\n            System.err.println( \"*** Cannot write to \" + outputFileName);\n            System.err.println( \"   \" + ioe.getMessage());\n            System.exit(1);\n        }\n    }"}
{"idx": 304, "target": 1, "func": "@Override\n    public AssertionResult getResult(SampleResult response) {\n        // no error as default\n        AssertionResult result = new AssertionResult(getName());\n        byte[] responseData = response.getResponseData();\n        if (responseData.length == 0) {\n            return result.setResultForNull();\n        }\n        result.setFailure(false);\n\n        // the result data\n        String resultData = new String(getResultBody(responseData)); // TODO - charset?\n\n        SAXBuilder builder = myBuilder.get();\n\n        try {\n            builder.build(new StringReader(resultData));\n        } catch (JDOMException e) {\n            log.debug(\"Cannot parse result content\", e); // may well happen\n            result.setFailure(true);\n            result.setFailureMessage(e.getMessage());\n        } catch (IOException e) {\n            log.error(\"Cannot read result content\", e); // should never happen\n            result.setError(true);\n            result.setFailureMessage(e.getMessage());\n        }\n\n        return result;\n    }"}
{"idx": 305, "target": 1, "func": "@Override\n    public String getDataEncodingWithDefault() {\n        if (getDataEncodingNoDefault() == null && getContentType().startsWith(\"text/html\")){ // $NON-NLS-1$\n            byte[] bytes=getResponseData();\n            // get the start of the file\n            // TODO - charset?\n            String prefix = new String(bytes,0,Math.min(bytes.length, 2000)).toLowerCase(java.util.Locale.ENGLISH);\n            // Extract the content-type if present\n            final String METATAG = \"<meta http-equiv=\\\"content-type\\\" content=\\\"\"; // $NON-NLS-1$\n            int tagstart=prefix.indexOf(METATAG);\n            if (tagstart!=-1){\n                tagstart += METATAG.length();\n                int tagend = prefix.indexOf('\\\"', tagstart); // $NON-NLS-1$\n                if (tagend!=-1){\n                    // TODO use fixed charset:\n                    final String ct = new String(bytes,tagstart,tagend-tagstart); // TODO - charset?\n                    setEncodingAndType(ct);// Update the dataEncoding\n                }\n            }\n        }\n        return super.getDataEncodingWithDefault(DEFAULT_HTTP_ENCODING);\n    }"}
{"idx": 306, "target": 0, "func": "protected HTTPSampleResult resultProcessing(boolean areFollowingRedirect, int frameDepth, HTTPSampleResult res) {\n        boolean wasRedirected = false;\n        if (!areFollowingRedirect) {\n            if (res.isRedirect()) {\n                log.debug(\"Location set to - \" + res.getRedirectLocation());\n\n                if (getFollowRedirects()) {\n                    res = followRedirects(res, frameDepth);\n                    areFollowingRedirect = true;\n                    wasRedirected = true;\n                }\n            }\n        }\n        if (isImageParser() && (SampleResult.TEXT).equals(res.getDataType()) && res.isSuccessful()) {\n            if (frameDepth > MAX_FRAME_DEPTH) {\n                res.addSubResult(errorResult(new Exception(\"Maximum frame/iframe nesting depth exceeded.\"), new HTTPSampleResult(res)));\n            } else {\n                // Only download page resources if we were not redirected.\n                // If we were redirected, the page resources have already been\n                // downloaded for the sample made for the redirected url\n                // otherwise, use null so the container is created if necessary unless\n                // the flag is false, in which case revert to broken 2.1 behaviour \n                // Bug 51939 -  https://issues.apache.org/bugzilla/show_bug.cgi?id=51939\n                if(!wasRedirected) {\n                    HTTPSampleResult container = (HTTPSampleResult) (\n                            areFollowingRedirect ? res.getParent() : SEPARATE_CONTAINER ? null : res);\n                    res = downloadPageResources(res, container, frameDepth);\n                }\n            }\n        }\n        return res;\n    }"}
{"idx": 307, "target": 0, "func": "protected HTTPSampleResult errorResult(Throwable e, HTTPSampleResult res) {\n        res.setSampleLabel(\"Error: \" + res.getSampleLabel());\n        res.setDataType(SampleResult.TEXT);\n        ByteArrayOutputStream text = new ByteArrayOutputStream(200);\n        e.printStackTrace(new PrintStream(text));\n        res.setResponseData(text.toByteArray());\n        res.setResponseCode(NON_HTTP_RESPONSE_CODE+\": \"+e.getClass().getName());\n        res.setResponseMessage(NON_HTTP_RESPONSE_MESSAGE+\": \"+e.getMessage());\n        res.setSuccessful(false);\n        res.setMonitor(this.isMonitor());\n        return res;\n    }"}
{"idx": 308, "target": 1, "func": "@Override\n    public int compareTo(SegmentInfoAndLevel other) {\n      if (level < other.level) {\n        return 1;\n      } else if (level > other.level) {\n        return -1;\n      } else {\n        return 0;\n      }\n    }"}
{"idx": 309, "target": 0, "func": "@Override\n    public int compareTo(SegmentInfoAndLevel other) {\n      if (level < other.level) {\n        return 1;\n      } else if (level > other.level) {\n        return -1;\n      } else {\n        return 0;\n      }\n    }"}
{"idx": 310, "target": 0, "func": "public <T> Class<? extends T> findClass(String cname, Class<T> expectedType, String... subpackages) {\n    if (subpackages == null || subpackages.length == 0 || subpackages == packages) {\n      subpackages = packages;\n      String  c = classNameCache.get(cname);\n      if(c != null) {\n        try {\n          return Class.forName(c, true, classLoader).asSubclass(expectedType);\n        } catch (ClassNotFoundException e) {\n          //this is unlikely\n          log.error(\"Unable to load cached class-name :  \"+ c +\" for shortname : \"+cname + e);\n        }\n\n      }\n    }\n    Class<? extends T> clazz = null;\n    \n    // first try legacy analysis patterns, now replaced by Lucene's Analysis package:\n    final Matcher m = legacyAnalysisPattern.matcher(cname);\n    if (m.matches()) {\n      final String name = m.group(4);\n      log.trace(\"Trying to load class from analysis SPI using name='{}'\", name);\n      try {\n        if (CharFilterFactory.class.isAssignableFrom(expectedType)) {\n          return clazz = CharFilterFactory.lookupClass(name).asSubclass(expectedType);\n        } else if (TokenizerFactory.class.isAssignableFrom(expectedType)) {\n          return clazz = TokenizerFactory.lookupClass(name).asSubclass(expectedType);\n        } else if (TokenFilterFactory.class.isAssignableFrom(expectedType)) {\n          return clazz = TokenFilterFactory.lookupClass(name).asSubclass(expectedType);\n        } else {\n          log.warn(\"'{}' looks like an analysis factory, but caller requested different class type: {}\", cname, expectedType.getName());\n        }\n      } catch (IllegalArgumentException ex) { \n        // ok, we fall back to legacy loading\n      }\n    }\n    \n    // first try cname == full name\n    try {\n      return Class.forName(cname, true, classLoader).asSubclass(expectedType);\n    } catch (ClassNotFoundException e) {\n      String newName=cname;\n      if (newName.startsWith(project)) {\n        newName = cname.substring(project.length()+1);\n      }\n      for (String subpackage : subpackages) {\n        try {\n          String name = base + '.' + subpackage + newName;\n          log.trace(\"Trying class name \" + name);\n          return clazz = Class.forName(name,true,classLoader).asSubclass(expectedType);\n        } catch (ClassNotFoundException e1) {\n          // ignore... assume first exception is best.\n        }\n      }\n  \n      throw new SolrException( SolrException.ErrorCode.SERVER_ERROR, \"Error loading class '\" + cname + \"'\", e);\n    }finally{\n      //cache the shortname vs FQN if it is loaded by the webapp classloader  and it is loaded\n      // using a shortname\n      if ( clazz != null &&\n              clazz.getClassLoader() == SolrResourceLoader.class.getClassLoader() &&\n              !cname.equals(clazz.getName()) &&\n              (subpackages.length == 0 || subpackages == packages)) {\n        //store in the cache\n        classNameCache.put(cname, clazz.getName());\n      }\n    }\n  }"}
{"idx": 311, "target": 1, "func": "@Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    super.init(schema, args);\n    if (this.isMultiValued()) { \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              \"CurrencyField types can not be multiValued: \" + \n                              this.typeName);\n    }\n    this.schema = schema;\n    this.exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);\n    this.defaultCurrency = args.get(PARAM_DEFAULT_CURRENCY);\n\n    if (this.defaultCurrency == null) {\n      this.defaultCurrency = DEFAULT_DEFAULT_CURRENCY;\n    }\n    \n    if (this.exchangeRateProviderClass == null) {\n      this.exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;\n    }\n\n    if (java.util.Currency.getInstance(this.defaultCurrency) == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Invalid currency code \" + this.defaultCurrency);\n    }\n\n    String precisionStepString = args.get(PARAM_PRECISION_STEP);\n    if (precisionStepString == null) {\n      precisionStepString = DEFAULT_PRECISION_STEP;\n    }\n\n    // Initialize field type for amount\n    fieldTypeAmountRaw = new TrieLongField();\n    fieldTypeAmountRaw.setTypeName(\"amount_raw_type_tlong\");\n    Map<String,String> map = new HashMap<String,String>(1);\n    map.put(\"precisionStep\", precisionStepString);\n    fieldTypeAmountRaw.init(schema, map);\n    \n    // Initialize field type for currency string\n    fieldTypeCurrency = new StrField();\n    fieldTypeCurrency.setTypeName(\"currency_type_string\");\n    fieldTypeCurrency.init(schema, new HashMap<String,String>());\n    \n    args.remove(PARAM_RATE_PROVIDER_CLASS);\n    args.remove(PARAM_DEFAULT_CURRENCY);\n    args.remove(PARAM_PRECISION_STEP);\n\n    try {\n      Class<? extends ExchangeRateProvider> c = schema.getResourceLoader().findClass(exchangeRateProviderClass, ExchangeRateProvider.class);\n      provider = c.newInstance();\n      provider.init(args);\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Error instansiating exhange rate provider \"+exchangeRateProviderClass+\". Please check your FieldType configuration\", e);\n    }\n  }"}
{"idx": 312, "target": 0, "func": "@Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    super.init(schema, args);\n    if (this.isMultiValued()) { \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              \"CurrencyField types can not be multiValued: \" + \n                              this.typeName);\n    }\n    this.schema = schema;\n    this.exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);\n    this.defaultCurrency = args.get(PARAM_DEFAULT_CURRENCY);\n\n    if (this.defaultCurrency == null) {\n      this.defaultCurrency = DEFAULT_DEFAULT_CURRENCY;\n    }\n    \n    if (this.exchangeRateProviderClass == null) {\n      this.exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;\n    }\n\n    if (java.util.Currency.getInstance(this.defaultCurrency) == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Invalid currency code \" + this.defaultCurrency);\n    }\n\n    String precisionStepString = args.get(PARAM_PRECISION_STEP);\n    if (precisionStepString == null) {\n      precisionStepString = DEFAULT_PRECISION_STEP;\n    }\n\n    // Initialize field type for amount\n    fieldTypeAmountRaw = new TrieLongField();\n    fieldTypeAmountRaw.setTypeName(\"amount_raw_type_tlong\");\n    Map<String,String> map = new HashMap<String,String>(1);\n    map.put(\"precisionStep\", precisionStepString);\n    fieldTypeAmountRaw.init(schema, map);\n    \n    // Initialize field type for currency string\n    fieldTypeCurrency = new StrField();\n    fieldTypeCurrency.setTypeName(\"currency_type_string\");\n    fieldTypeCurrency.init(schema, new HashMap<String,String>());\n    \n    args.remove(PARAM_RATE_PROVIDER_CLASS);\n    args.remove(PARAM_DEFAULT_CURRENCY);\n    args.remove(PARAM_PRECISION_STEP);\n\n    try {\n      Class<? extends ExchangeRateProvider> c = schema.getResourceLoader().findClass(exchangeRateProviderClass, ExchangeRateProvider.class);\n      provider = c.newInstance();\n      provider.init(args);\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Error instansiating exhange rate provider \"+exchangeRateProviderClass+\". Please check your FieldType configuration\", e);\n    }\n  }"}
{"idx": 313, "target": 1, "func": "@Override\n  public double getExchangeRate(String sourceCurrencyCode, String targetCurrencyCode) {\n    if (rates == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Rates not initialized.\");\n    }\n      \n    if (sourceCurrencyCode == null || targetCurrencyCode == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot get exchange rate; currency was null.\");\n    }\n    \n    if (rates.getTimestamp() + refreshInterval*60*1000 > System.currentTimeMillis()) {\n      log.debug(\"Refresh interval has expired. Refreshing exchange rates.\");\n      reload();\n    }\n    \n    Double source = (Double) rates.getRates().get(sourceCurrencyCode);\n    Double target = (Double) rates.getRates().get(targetCurrencyCode);\n\n    if (source == null || target == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \n          \"No available conversion rate from \" + sourceCurrencyCode + \" to \" + targetCurrencyCode + \". \"\n          + \"Available rates are \"+listAvailableCurrencies());\n    }\n    \n    return target / source;  \n  }"}
{"idx": 314, "target": 0, "func": "@Override\n  public boolean reload() throws SolrException {\n    InputStream ratesJsonStream = null;\n    try {\n      log.info(\"Reloading exchange rates from \"+ratesFileLocation);\n      try {\n        ratesJsonStream = (new URL(ratesFileLocation)).openStream();\n      } catch (Exception e) {\n        ratesJsonStream = resourceLoader.openResource(ratesFileLocation);\n      }\n        \n      rates = new OpenExchangeRates(ratesJsonStream);\n      return true;\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Error reloading exchange rates\", e);\n    } finally {\n      if (ratesJsonStream != null) try {\n        ratesJsonStream.close();\n      } catch (IOException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error closing stream\", e);\n      }\n    }\n  }"}
{"idx": 315, "target": 1, "func": "public static String[] getLogList(File directory) {\n    final String prefix = TLOG_NAME+'.';\n    String[] names = directory.list(new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return name.startsWith(prefix);\n      }\n    });\n    Arrays.sort(names);\n    return names;\n  }"}
{"idx": 316, "target": 0, "func": "@Override\n  public void init(PluginInfo info) {\n    dataDir = (String)info.initArgs.get(\"dir\");\n    defaultSyncLevel = SyncLevel.getSyncLevel((String)info.initArgs.get(\"syncLevel\"));\n  }"}
{"idx": 317, "target": 1, "func": "@Override\n  public void inform(final SolrCore core) {\n    \n    final IndexSchema schema = core.getSchema();\n\n    srcSelector = \n      FieldMutatingUpdateProcessor.createFieldNameSelector\n      (core.getResourceLoader(),\n       core.getSchema(),\n       srcInclusions.fieldName,\n       srcInclusions.typeName,\n       srcInclusions.typeClass,\n       srcInclusions.fieldRegex,\n       FieldMutatingUpdateProcessor.SELECT_NO_FIELDS);\n\n    for (SelectorParams exc : srcExclusions) {\n      srcSelector = FieldMutatingUpdateProcessor.wrap\n        (srcSelector,\n         FieldMutatingUpdateProcessor.createFieldNameSelector\n         (core.getResourceLoader(),\n          core.getSchema(),\n          exc.fieldName,\n          exc.typeName,\n          exc.typeClass,\n          exc.fieldRegex,\n          FieldMutatingUpdateProcessor.SELECT_NO_FIELDS));\n    }\n  }"}
{"idx": 318, "target": 0, "func": "public void setCompressionMimeTypes(String[] mimeTypes) {\n        if (debug > 1) {\n            System.out.println(\"setCompressionMimeTypes to \" +\n                    Arrays.toString(mimeTypes));\n        }\n        this.compressionMimeTypes = mimeTypes;\n    }"}
{"idx": 319, "target": 0, "func": "protected void initServletContext() {\n        try {\n            context =new JspCServletContext\n                (new PrintWriter(System.out),\n                 new URL(\"file:\" + uriRoot.replace('\\\\','/') + '/'));\n            tldLocationsCache = TldLocationsCache.getInstance(context);\n        } catch (MalformedURLException me) {\n            System.out.println(\"**\" + me);\n        }\n        rctxt = new JspRuntimeContext(context, this);\n        jspConfig = new JspConfig(context);\n        tagPluginManager = new TagPluginManager(context);\n    }"}
{"idx": 320, "target": 1, "func": "public void setValidateXml( boolean b ) {\n        org.apache.jasper.xmlparser.ParserUtils.validating=b;\n    }"}
{"idx": 321, "target": 0, "func": "public ClassLoader getJspLoader() {\n        if( jspLoader == null ) {\n            jspLoader = new JasperLoader\n            (new URL[] {baseUrl},\n                    getClassLoader(),\n                    rctxt.getPermissionCollection());\n        }\n        return jspLoader;\n    }"}
{"idx": 322, "target": 1, "func": "private void convert( File from, File to )\n        throws IOException\n    {\n        // Open files:\n        BufferedReader in = new BufferedReader( new FileReader( from ) );\n        PrintWriter out = new PrintWriter( new FileWriter( to ) );\n\n        // Output header:\n        out.println( \"<html><body><pre>\" );\n\n        // Convert, line-by-line:\n        String line;\n        while( (line = in.readLine()) != null ) {\n            StringBuilder result = new StringBuilder();\n            int len = line.length();\n            for( int i = 0; i < len; i++ ) {\n                char c = line.charAt( i );\n                switch( c ) {\n                    case '&':\n                        result.append( \"&amp;\" );\n                        break;\n                    case '<':\n                        result.append( \"&lt;\" );\n                        break;\n                    default:\n                        result.append( c );\n                }\n            }\n            out.println( result.toString() );\n        }\n\n        // Output footer:\n        out.println( \"</pre></body></html>\" );\n\n        // Close streams:\n        out.close();\n        in.close();\n    }"}
{"idx": 323, "target": 0, "func": "@Override\n    public void execute()\n        throws BuildException\n    {\n        int count = 0;\n\n        // Step through each file and convert.\n        Iterator<FileSet> iter = filesets.iterator();\n        while( iter.hasNext() ) {\n            FileSet fs = iter.next();\n            DirectoryScanner ds = fs.getDirectoryScanner(getProject());\n            File basedir = ds.getBasedir();\n            String[] files = ds.getIncludedFiles();\n            for( int i = 0; i < files.length; i++ ) {\n                File from = new File( basedir, files[i] );\n                File to = new File( todir, files[i] + \".html\" );\n                if( !to.exists() ||\n                    (from.lastModified() > to.lastModified()) )\n                {\n                    log( \"Converting file '\" + from.getAbsolutePath() +\n                        \"' to '\" + to.getAbsolutePath(), Project.MSG_VERBOSE );\n                    try {\n                        convert( from, to );\n                    }\n                    catch( IOException e ) {\n                        throw new BuildException( \"Could not convert '\" +\n                            from.getAbsolutePath() + \"' to '\" +\n                            to.getAbsolutePath() + \"'\", e );\n                    }\n                    count++;\n                }\n            }\n            if( count > 0 ) {\n                log( \"Converted \" + count + \" file\" + (count > 1 ? \"s\" : \"\") +\n                    \" to \" + todir.getAbsolutePath() );\n            }\n        }\n    }"}
{"idx": 324, "target": 1, "func": "protected static CompositeType getCompositeType() {\n        if (SLOW_QUERY_TYPE==null) {\n            try {\n                SLOW_QUERY_TYPE = new CompositeType(\n                        SlowQueryReportJmx.class.getName(),\n                        \"Composite data type for query statistics\",\n                        QueryStats.getFieldNames(),\n                        QueryStats.getFieldDescriptions(),\n                        QueryStats.getFieldTypes());\n            }catch (OpenDataException x) {\n                log.warn(\"Unable to initialize composite data type for JMX stats and notifications.\",x);\n            }\n        }\n        return SLOW_QUERY_TYPE;\n    }"}
{"idx": 325, "target": 1, "func": "protected FileItemHeaders getParsedHeaders(String headerPart) {\n        final int len = headerPart.length();\n        FileItemHeadersImpl headers = newFileItemHeaders();\n        int start = 0;\n        for (;;) {\n            int end = parseEndOfLine(headerPart, start);\n            if (start == end) {\n                break;\n            }\n            String header = headerPart.substring(start, end);\n            start = end + 2;\n            while (start < len) {\n                int nonWs = start;\n                while (nonWs < len) {\n                    char c = headerPart.charAt(nonWs);\n                    if (c != ' '  &&  c != '\\t') {\n                        break;\n                    }\n                    ++nonWs;\n                }\n                if (nonWs == start) {\n                    break;\n                }\n                // Continuation line found\n                end = parseEndOfLine(headerPart, nonWs);\n                header += \" \" + headerPart.substring(nonWs, end);\n                start = end + 2;\n            }\n            parseHeaderLine(headers, header);\n        }\n        return headers;\n    }"}
{"idx": 326, "target": 0, "func": "public String readHeaders()\n    throws MalformedStreamException {\n        int i = 0;\n        byte b;\n        // to support multi-byte characters\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        int size = 0;\n        while (i < HEADER_SEPARATOR.length) {\n            try {\n                b = readByte();\n            } catch (IOException e) {\n                throw new MalformedStreamException(\"Stream ended unexpectedly\");\n            }\n            if (++size > HEADER_PART_SIZE_MAX) {\n                throw new MalformedStreamException(\n                        \"Header section has more than \" + HEADER_PART_SIZE_MAX\n                        + \" bytes (maybe it is not properly terminated)\");\n            }\n            if (b == HEADER_SEPARATOR[i]) {\n                i++;\n            } else {\n                i = 0;\n            }\n            baos.write(b);\n        }\n\n        String headers = null;\n        if (headerEncoding != null) {\n            try {\n                headers = baos.toString(headerEncoding);\n            } catch (UnsupportedEncodingException e) {\n                // Fall back to platform default if specified encoding is not\n                // supported.\n                headers = baos.toString();\n            }\n        } else {\n            headers = baos.toString();\n        }\n\n        return headers;\n    }"}
